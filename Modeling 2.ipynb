{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Game Prediction Modeling\n",
    "by Gary Schwaeber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sport betting becoming increasingly popular and mainstream I believe that data science can be used to make superior decisions over gut intuitions. In this notebook I will attempt to train logistic regression, ada boost, and gradient boosting models in an attempt to make the best possible game prediction model. I will train my models and tune model hyperparemetres using game results from seasons '2017-2018', '2018-2019', '2019-2020'. Then I will predict on held out games from the current 2021 season and evaluate my model. There are currently a handful of public models whose log loss on the current season's games is being [tracked](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/) on which I can compare the quality of my model to. The score I will look to optimize is log loss, however, I will also review accuracy scores due to their interpretability.\n",
    "\n",
    "Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value (0 or 1 in case of binary classification). The more the predicted probability diverges from the actual value, the higher is the log-loss value. [Source](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T18:13:33.579685Z",
     "start_time": "2021-05-09T18:13:33.533178Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import hockey_scraper\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#for the Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:48:44.859949Z",
     "start_time": "2021-05-07T19:48:44.723497Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_games_multirolling_SVA_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:02.802611Z",
     "start_time": "2021-05-07T19:49:02.798659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4447, 155)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:59:36.967400Z",
     "start_time": "2021-05-07T19:59:36.957271Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature columns for different rolling intervals\n",
    "\n",
    "common = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', \n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']\n",
    "\n",
    "r3 = ['home_last_3_FF%_5v5',\n",
    " 'home_last_3_GF%_5v5',\n",
    " 'home_last_3_xGF%_5v5',\n",
    " 'home_last_3_SH%',\n",
    " 'home_last3_xGF_per_min_pp',\n",
    " 'home_last3_GF_per_min_pp',\n",
    " 'home_last3_xGA_per_min_pk',\n",
    " 'home_last3_GA_per_min_pk',\n",
    " 'away_last_3_FF%_5v5',\n",
    " 'away_last_3_GF%_5v5',\n",
    " 'away_last_3_xGF%_5v5',\n",
    " 'away_last_3_SH%',\n",
    " 'away_last3_xGF_per_min_pp',\n",
    " 'away_last3_GF_per_min_pp',\n",
    " 'away_last3_xGA_per_min_pk',\n",
    " 'away_last3_GA_per_min_pk'] + common\n",
    "\n",
    "r5 =['home_last_5_FF%_5v5',\n",
    " 'home_last_5_GF%_5v5',\n",
    " 'home_last_5_xGF%_5v5',\n",
    " 'home_last_5_SH%',\n",
    "\n",
    " 'home_last5_xGF_per_min_pp',\n",
    " 'home_last5_GF_per_min_pp',\n",
    "\n",
    " 'home_last5_xGA_per_min_pk',\n",
    " 'home_last5_GA_per_min_pk',\n",
    " 'away_last_5_FF%_5v5',\n",
    " 'away_last_5_GF%_5v5',\n",
    " 'away_last_5_xGF%_5v5',\n",
    " 'away_last_5_SH%',\n",
    " 'away_last5_xGF_per_min_pp',\n",
    " 'away_last5_GF_per_min_pp',\n",
    " 'away_last5_xGA_per_min_pk',\n",
    " 'away_last5_GA_per_min_pk'] + common\n",
    "\n",
    "r10 =['home_last_10_FF%_5v5',\n",
    " 'home_last_10_GF%_5v5',\n",
    " 'home_last_10_xGF%_5v5',\n",
    " 'home_last_10_SH%',\n",
    " 'home_last10_xGF_per_min_pp',\n",
    " 'home_last10_GF_per_min_pp',\n",
    " 'home_last10_xGA_per_min_pk',\n",
    " 'home_last10_GA_per_min_pk',\n",
    "  'away_last_10_FF%_5v5',\n",
    " 'away_last_10_GF%_5v5',\n",
    " 'away_last_10_xGF%_5v5',\n",
    " 'away_last_10_SH%',\n",
    " 'away_last10_xGF_per_min_pp',\n",
    " 'away_last10_GF_per_min_pp',\n",
    " 'away_last10_xGA_per_min_pk',\n",
    " 'away_last10_GA_per_min_pk',]\n",
    "\n",
    "\n",
    "r20 = ['home_last_20_FF%_5v5',\n",
    " 'home_last_20_GF%_5v5',\n",
    " 'home_last_20_xGF%_5v5',\n",
    " 'home_last_20_SH%',\n",
    "\n",
    " 'home_last20_xGF_per_min_pp',\n",
    " 'home_last20_GF_per_min_pp',\n",
    "\n",
    " 'home_last20_xGA_per_min_pk',\n",
    " 'home_last20_GA_per_min_pk',\n",
    " 'away_last_20_FF%_5v5',\n",
    " 'away_last_20_GF%_5v5',\n",
    " 'away_last_20_xGF%_5v5',\n",
    " 'away_last_20_SH%',\n",
    "\n",
    " 'away_last20_xGF_per_min_pp',\n",
    " 'away_last20_GF_per_min_pp',\n",
    "\n",
    " 'away_last20_xGA_per_min_pk',\n",
    " 'away_last20_GA_per_min_pk']\n",
    "\n",
    "r30 = ['home_last_30_FF%_5v5',\n",
    " 'home_last_30_GF%_5v5',\n",
    " 'home_last_30_xGF%_5v5',\n",
    " 'home_last_30_SH%',\n",
    " 'home_last30_xGF_per_min_pp',\n",
    " 'home_last30_GF_per_min_pp',\n",
    " 'home_last30_xGA_per_min_pk',\n",
    " 'home_last30_GA_per_min_pk',\n",
    " 'away_last_30_FF%_5v5',\n",
    " 'away_last_30_GF%_5v5',\n",
    " 'away_last_30_xGF%_5v5',\n",
    " 'away_last_30_SH%',\n",
    " 'away_last30_xGF_per_min_pp',\n",
    " 'away_last30_GF_per_min_pp',\n",
    " 'away_last30_xGA_per_min_pk',\n",
    " 'away_last30_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "r40 = ['home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk',\n",
    " 'away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "all_r = list(set(r3+r5+r10+r20+r30+r40))\n",
    "\n",
    "r3_30 =list(set(r3+r30))\n",
    "r5_30 = list(set(r5+r30))\n",
    "r10_30 = list(set(r10+r30))\n",
    "r_3_5_30 = list(set(r3+r5+r30))\n",
    "r_5_20 = list(set(r5+r20))\n",
    "r_5_40 = list(set(r5+r40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model will predict that every home team wins their game and that the probability of that is the ratio of games the home team has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:09.214501Z",
     "start_time": "2021-05-07T19:49:09.014908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.541714\n",
       "0    0.458286\n",
       "Name: Home_Team_Won, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Home_Team_Won'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:10.476331Z",
     "start_time": "2021-05-07T19:49:10.468915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417135147290308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = np.ones(df.shape[0])\n",
    "accuracy_score(df['Home_Team_Won'],baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:11.547357Z",
     "start_time": "2021-05-07T19:49:11.536477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896630977766495"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_probs = np.repeat(df['Home_Team_Won'].value_counts(normalize=True)[1], df.shape[0])\n",
    "\n",
    "log_loss(df['Home_Team_Won'], baseline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need to beat an accuracy score of 54.17% and a log loss of .6897, otherwise they are no better than just predicting the home team will win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling 5 and 40 game features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first set of models I will attempt using 5 and 40 game rolling features. These seemed like a good set based on the feature selection notebook. 40 games is currently the longest rolling runway I have currently for the team statistics. The 40 games stats intuitively provide the most smoothing of team data over the course of the season, while the 5 game stats may provide some insight on any streakiness or may cover recent developments that would affect short term team performances such as player injuries, trades coaching changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T15:05:47.455155Z",
     "start_time": "2021-05-09T15:05:47.303495Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T15:37:01.054519Z",
     "start_time": "2021-05-07T15:37:01.049641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
       "       'home_last5_pp_TOI_per_game', 'home_last_40_GF%_5v5',\n",
       "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
       "       'home_last_40_SH%', 'home_last5_pk_TOI_per_game',\n",
       "       'away_last40_pp_TOI_per_game', 'home_Goalie_GSAx/60',\n",
       "       'away_last40_pk_TOI_per_game', 'away_Goalie_GSAx/60',\n",
       "       'away_last_5_GF%_5v5', 'home_last40_pk_TOI_per_game', 'B2B_Status',\n",
       "       'home_last_40_xGF%_5v5', 'away_last5_pp_TOI_per_game',\n",
       "       'away_last5_pk_TOI_per_game', 'home_last5_GF_per_min_pp',\n",
       "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
       "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
       "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
       "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
       "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
       "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
       "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
       "       'home_last40_pp_TOI_per_game', 'away_last5_GF_per_min_pp',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
       "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
       "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
       "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
       "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
       "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:38.914528Z",
     "start_time": "2021-05-07T19:49:38.909752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 49)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:55:44.747167Z",
     "start_time": "2021-05-07T19:55:44.741690Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
    "       'home_last_40_GF%_5v5',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_40_SH%', \n",
    "       'home_Goalie_GSAx/60',\n",
    "        'away_Goalie_GSAx/60',\n",
    "       'away_last_5_GF%_5v5', \n",
    "       'home_last_40_xGF%_5v5', \n",
    "     'home_last5_GF_per_min_pp',\n",
    "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
    "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
    "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
    "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
    "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
    "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
    "     'away_last5_GF_per_min_pp',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
    "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
    "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
    "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
    "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:50:17.173759Z",
     "start_time": "2021-05-07T19:50:17.139897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>home_last5_pp_TOI_per_game</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_last5_pk_TOI_per_game</th>\n",
       "      <th>away_last40_pp_TOI_per_game</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>away_last40_pk_TOI_per_game</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>home_last40_pk_TOI_per_game</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>away_last5_pp_TOI_per_game</th>\n",
       "      <th>away_last5_pk_TOI_per_game</th>\n",
       "      <th>home_last5_GF_per_min_pp</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_last5_GA_per_min_pk</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GA_per_min_pk</th>\n",
       "      <th>home_last40_pp_TOI_per_game</th>\n",
       "      <th>away_last5_GF_per_min_pp</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112699</td>\n",
       "      <td>48.770492</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>50.127801</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>9.025236</td>\n",
       "      <td>3.693333</td>\n",
       "      <td>4.646667</td>\n",
       "      <td>-0.202922</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>0.082345</td>\n",
       "      <td>45.937500</td>\n",
       "      <td>4.923333</td>\n",
       "      <td>48.992719</td>\n",
       "      <td>5.893333</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>57.080799</td>\n",
       "      <td>52.399869</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.195440</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>1500.66</td>\n",
       "      <td>51.663405</td>\n",
       "      <td>6.967375</td>\n",
       "      <td>1495.03</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>49.339386</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>5.328333</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>51.399425</td>\n",
       "      <td>8.124451</td>\n",
       "      <td>52.562502</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>9.426112</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>48.803377</td>\n",
       "      <td>0.942516</td>\n",
       "      <td>49.991679</td>\n",
       "      <td>0.117297</td>\n",
       "      <td>0.121145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124909</td>\n",
       "      <td>51.204482</td>\n",
       "      <td>3.336667</td>\n",
       "      <td>56.868932</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>9.060588</td>\n",
       "      <td>3.546667</td>\n",
       "      <td>4.315417</td>\n",
       "      <td>0.169541</td>\n",
       "      <td>4.928750</td>\n",
       "      <td>-0.239655</td>\n",
       "      <td>49.927641</td>\n",
       "      <td>4.774167</td>\n",
       "      <td>51.954595</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>59.064609</td>\n",
       "      <td>42.564205</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1535.17</td>\n",
       "      <td>46.860987</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>1577.10</td>\n",
       "      <td>0.143856</td>\n",
       "      <td>52.486645</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>4.705417</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>58.184556</td>\n",
       "      <td>8.420932</td>\n",
       "      <td>46.882217</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>12.093988</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>50.828439</td>\n",
       "      <td>0.941294</td>\n",
       "      <td>50.633643</td>\n",
       "      <td>0.138139</td>\n",
       "      <td>0.086229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132248</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>6.283333</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>4.921667</td>\n",
       "      <td>0.302087</td>\n",
       "      <td>5.185417</td>\n",
       "      <td>-0.097423</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>4.233750</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>5.853333</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.112194</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.116830</td>\n",
       "      <td>1496.85</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>1522.11</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>4.682500</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>0.938246</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.149493</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105738</td>\n",
       "      <td>49.941995</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>53.260259</td>\n",
       "      <td>0.120913</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>7.970138</td>\n",
       "      <td>4.763333</td>\n",
       "      <td>5.571250</td>\n",
       "      <td>-0.164139</td>\n",
       "      <td>5.305000</td>\n",
       "      <td>-0.080476</td>\n",
       "      <td>56.272661</td>\n",
       "      <td>4.379167</td>\n",
       "      <td>52.809227</td>\n",
       "      <td>5.173333</td>\n",
       "      <td>5.963333</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>57.771883</td>\n",
       "      <td>54.316401</td>\n",
       "      <td>0.137242</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0.869266</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.103208</td>\n",
       "      <td>1496.86</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>6.524847</td>\n",
       "      <td>1525.37</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>50.855171</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>4.778333</td>\n",
       "      <td>0.115979</td>\n",
       "      <td>45.246898</td>\n",
       "      <td>5.932286</td>\n",
       "      <td>51.909534</td>\n",
       "      <td>0.934447</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.093779</td>\n",
       "      <td>9.804628</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>52.890654</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>51.197815</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.131951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129293</td>\n",
       "      <td>43.637300</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>48.882718</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>7.303942</td>\n",
       "      <td>5.446667</td>\n",
       "      <td>4.720833</td>\n",
       "      <td>-0.310233</td>\n",
       "      <td>4.475833</td>\n",
       "      <td>-0.346771</td>\n",
       "      <td>52.130045</td>\n",
       "      <td>5.193333</td>\n",
       "      <td>54.871795</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>48.959081</td>\n",
       "      <td>52.400715</td>\n",
       "      <td>0.142088</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121801</td>\n",
       "      <td>1545.81</td>\n",
       "      <td>50.929752</td>\n",
       "      <td>7.311321</td>\n",
       "      <td>1521.29</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>50.381002</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>4.482083</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>52.122642</td>\n",
       "      <td>7.885816</td>\n",
       "      <td>47.102597</td>\n",
       "      <td>0.933383</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>5.518246</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>55.762037</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>51.309591</td>\n",
       "      <td>0.189644</td>\n",
       "      <td>0.128468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_last40_xGF_per_min_pp  away_last_5_xGF%_5v5  \\\n",
       "0                    0.112699             48.770492   \n",
       "1                    0.124909             51.204482   \n",
       "2                    0.132248             40.305523   \n",
       "3                    0.105738             49.941995   \n",
       "4                    0.129293             43.637300   \n",
       "\n",
       "   home_last5_pp_TOI_per_game  home_last_40_GF%_5v5  \\\n",
       "0                    4.190000             50.127801   \n",
       "1                    3.336667             56.868932   \n",
       "2                    6.283333             56.575634   \n",
       "3                    4.620000             53.260259   \n",
       "4                    2.690000             48.882718   \n",
       "\n",
       "   home_last40_xGA_per_min_pk  home_last5_xGA_per_min_pk  home_last_40_SH%  \\\n",
       "0                    0.104858                   0.098556          9.025236   \n",
       "1                    0.129028                   0.153383          9.060588   \n",
       "2                    0.116445                   0.131278          9.025460   \n",
       "3                    0.120913                   0.137299          7.970138   \n",
       "4                    0.084868                   0.067197          7.303942   \n",
       "\n",
       "   home_last5_pk_TOI_per_game  away_last40_pp_TOI_per_game  \\\n",
       "0                    3.693333                     4.646667   \n",
       "1                    3.546667                     4.315417   \n",
       "2                    4.540000                     4.921667   \n",
       "3                    4.763333                     5.571250   \n",
       "4                    5.446667                     4.720833   \n",
       "\n",
       "   home_Goalie_GSAx/60  away_last40_pk_TOI_per_game  away_Goalie_GSAx/60  \\\n",
       "0            -0.202922                     4.540000             0.082345   \n",
       "1             0.169541                     4.928750            -0.239655   \n",
       "2             0.302087                     5.185417            -0.097423   \n",
       "3            -0.164139                     5.305000            -0.080476   \n",
       "4            -0.310233                     4.475833            -0.346771   \n",
       "\n",
       "   away_last_5_GF%_5v5  home_last40_pk_TOI_per_game  home_last_40_xGF%_5v5  \\\n",
       "0            45.937500                     4.923333              48.992719   \n",
       "1            49.927641                     4.774167              51.954595   \n",
       "2            45.427286                     4.233750              49.851785   \n",
       "3            56.272661                     4.379167              52.809227   \n",
       "4            52.130045                     5.193333              54.871795   \n",
       "\n",
       "   away_last5_pp_TOI_per_game  away_last5_pk_TOI_per_game  \\\n",
       "0                    5.893333                    3.070000   \n",
       "1                    6.000000                    4.966667   \n",
       "2                    4.816667                    5.853333   \n",
       "3                    5.173333                    5.963333   \n",
       "4                    6.066667                    3.630000   \n",
       "\n",
       "   home_last5_GF_per_min_pp  home_last_5_GF%_5v5  home_last_5_FF%_5v5  \\\n",
       "0                  0.095465            57.080799            52.399869   \n",
       "1                  0.299700            59.064609            42.564205   \n",
       "2                  0.190981            58.385392            60.511924   \n",
       "3                  0.043290            57.771883            54.316401   \n",
       "4                  0.297398            48.959081            52.400715   \n",
       "\n",
       "   away_last5_xGF_per_min_pp  away_last40_xGF_per_min_pp  \\\n",
       "0                   0.069910                    0.122400   \n",
       "1                   0.096000                    0.102018   \n",
       "2                   0.153218                    0.120843   \n",
       "3                   0.137242                    0.143998   \n",
       "4                   0.142088                    0.087855   \n",
       "\n",
       "   home_last40_GA_per_min_pk  home_Goalie_HDCSV%  away_last5_GA_per_min_pk  \\\n",
       "0                   0.137102            0.858462                  0.195440   \n",
       "1                   0.104730            0.877358                  0.040268   \n",
       "2                   0.112194            0.897778                  0.068337   \n",
       "3                   0.125595            0.869266                  0.100615   \n",
       "4                   0.101091            0.830721                  0.000000   \n",
       "\n",
       "   away_last40_GF_per_min_pp  away_Rating.A.Pre  home_last_5_xGF%_5v5  \\\n",
       "0                   0.139885            1500.66             51.663405   \n",
       "1                   0.115864            1535.17             46.860987   \n",
       "2                   0.116830            1496.85             60.180542   \n",
       "3                   0.103208            1496.86             52.571429   \n",
       "4                   0.121801            1545.81             50.929752   \n",
       "\n",
       "   away_last_5_SH%  home_Rating.A.Pre  home_last5_xGF_per_min_pp  \\\n",
       "0         6.967375            1495.03                   0.079714   \n",
       "1        11.358025            1577.10                   0.143856   \n",
       "2         9.286882            1522.11                   0.113316   \n",
       "3         6.524847            1525.37                   0.118615   \n",
       "4         7.311321            1521.29                   0.098885   \n",
       "\n",
       "   away_last_40_xGF%_5v5  home_last5_GA_per_min_pk  \\\n",
       "0              49.339386                  0.054152   \n",
       "1              52.486645                  0.225564   \n",
       "2              49.136336                  0.132159   \n",
       "3              50.855171                  0.125962   \n",
       "4              50.381002                  0.036720   \n",
       "\n",
       "   home_last40_pp_TOI_per_game  away_last5_GF_per_min_pp  \\\n",
       "0                     5.328333                  0.101810   \n",
       "1                     4.705417                  0.100000   \n",
       "2                     4.682500                  0.166090   \n",
       "3                     4.778333                  0.115979   \n",
       "4                     4.482083                  0.065934   \n",
       "\n",
       "   away_last_40_GF%_5v5  away_last_40_SH%  away_last_5_FF%_5v5  \\\n",
       "0             51.399425          8.124451            52.562502   \n",
       "1             58.184556          8.420932            46.882217   \n",
       "2             50.499508          7.879167            43.520998   \n",
       "3             45.246898          5.932286            51.909534   \n",
       "4             52.122642          7.885816            47.102597   \n",
       "\n",
       "   home_Goalie_FenwickSV%  away_Goalie_HDCSV%  away_last40_xGA_per_min_pk  \\\n",
       "0                0.937294            0.873171                    0.133976   \n",
       "1                0.941904            0.864516                    0.097844   \n",
       "2                0.942492            0.878613                    0.107127   \n",
       "3                0.934447            0.848000                    0.093779   \n",
       "4                0.933383            0.839117                    0.102718   \n",
       "\n",
       "   home_last_5_SH%  away_last5_xGA_per_min_pk  home_last_40_FF%_5v5  \\\n",
       "0         9.426112                   0.074267             48.803377   \n",
       "1        12.093988                   0.109128             50.828439   \n",
       "2         8.478124                   0.112415             50.407241   \n",
       "3         9.804628                   0.086864             52.890654   \n",
       "4         5.518246                   0.107438             55.762037   \n",
       "\n",
       "   away_Goalie_FenwickSV%  away_last_40_FF%_5v5  home_last40_GF_per_min_pp  \\\n",
       "0                0.942516             49.991679                   0.117297   \n",
       "1                0.941294             50.633643                   0.138139   \n",
       "2                0.938246             50.595552                   0.149493   \n",
       "3                0.938305             51.197815                   0.099407   \n",
       "4                0.939698             51.309591                   0.189644   \n",
       "\n",
       "   away_last40_GA_per_min_pk  \n",
       "0                   0.121145  \n",
       "1                   0.086229  \n",
       "2                   0.106067  \n",
       "3                   0.131951  \n",
       "4                   0.128468  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numeric_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:50:18.261930Z",
     "start_time": "2021-05-07T19:50:18.258992Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['neg_log_loss', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:55:48.368793Z",
     "start_time": "2021-05-07T19:55:48.363567Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:39.885499Z",
     "start_time": "2021-05-07T20:01:39.880819Z"
    }
   },
   "outputs": [],
   "source": [
    "log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.00001, .0001, .001, .01, .05, 0.1],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv = GridSearchCV(log_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:44.530594Z",
     "start_time": "2021-05-07T20:01:40.634523Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                   0.05, 0.1],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:47.614964Z",
     "start_time": "2021-05-07T20:01:47.610337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6754370089204439"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:48.860448Z",
     "start_time": "2021-05-07T20:01:48.834622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671673</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673921</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019093</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673923</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678653</td>\n",
       "      <td>-0.672743</td>\n",
       "      <td>-0.678873</td>\n",
       "      <td>-0.676277</td>\n",
       "      <td>-0.675154</td>\n",
       "      <td>-0.676340</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.619247</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.587378</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677641</td>\n",
       "      <td>-0.668417</td>\n",
       "      <td>-0.680201</td>\n",
       "      <td>-0.678592</td>\n",
       "      <td>-0.676997</td>\n",
       "      <td>-0.676369</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677863</td>\n",
       "      <td>-0.668443</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679093</td>\n",
       "      <td>-0.676975</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677864</td>\n",
       "      <td>-0.668444</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679094</td>\n",
       "      <td>-0.676973</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.678655</td>\n",
       "      <td>-0.671507</td>\n",
       "      <td>-0.677800</td>\n",
       "      <td>-0.679098</td>\n",
       "      <td>-0.675913</td>\n",
       "      <td>-0.676595</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677719</td>\n",
       "      <td>-0.669147</td>\n",
       "      <td>-0.678903</td>\n",
       "      <td>-0.679826</td>\n",
       "      <td>-0.677732</td>\n",
       "      <td>-0.676665</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.573696</td>\n",
       "      <td>0.015507</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677728</td>\n",
       "      <td>-0.669121</td>\n",
       "      <td>-0.681685</td>\n",
       "      <td>-0.681348</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.677963</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.599721</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575648</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677767</td>\n",
       "      <td>-0.669153</td>\n",
       "      <td>-0.681584</td>\n",
       "      <td>-0.681528</td>\n",
       "      <td>-0.679915</td>\n",
       "      <td>-0.677990</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       0.012287      0.000163         0.007713        0.000084   \n",
       "17       0.019093      0.000621         0.007772        0.000036   \n",
       "15       0.014589      0.000732         0.008238        0.000482   \n",
       "21       0.017617      0.000735         0.007767        0.000023   \n",
       "23       0.025454      0.001999         0.008297        0.000467   \n",
       "22       0.016674      0.000611         0.007799        0.000178   \n",
       "24       0.017753      0.000853         0.007911        0.000061   \n",
       "30       0.025024      0.004794         0.009411        0.000891   \n",
       "27       0.024262      0.001168         0.008714        0.000813   \n",
       "28       0.022607      0.000736         0.008461        0.000296   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "16                       0.001                                   None   \n",
       "17                       0.001                                   None   \n",
       "15                       0.001                                   None   \n",
       "21                        0.01                                   None   \n",
       "23                        0.01                                   None   \n",
       "22                        0.01                                   None   \n",
       "24                        0.05                                   None   \n",
       "30                         0.1                                   None   \n",
       "27                        0.05                                   None   \n",
       "28                        0.05                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "16                                l2                            lbfgs   \n",
       "17                                l2                        newton-cg   \n",
       "15                                l2                        liblinear   \n",
       "21                                l2                        liblinear   \n",
       "23                                l2                        newton-cg   \n",
       "22                                l2                            lbfgs   \n",
       "24                                l1                        liblinear   \n",
       "30                                l1                        liblinear   \n",
       "27                                l2                        liblinear   \n",
       "28                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "16  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "17  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "15  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "21  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "23  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "22  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "24  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "30  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "27  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "28  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "16                 -0.678374                 -0.671673   \n",
       "17                 -0.678374                 -0.671674   \n",
       "15                 -0.678653                 -0.672743   \n",
       "21                 -0.677641                 -0.668417   \n",
       "23                 -0.677863                 -0.668443   \n",
       "22                 -0.677864                 -0.668444   \n",
       "24                 -0.678655                 -0.671507   \n",
       "30                 -0.677719                 -0.669147   \n",
       "27                 -0.677728                 -0.669121   \n",
       "28                 -0.677767                 -0.669153   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "16                 -0.677392                 -0.675825   \n",
       "17                 -0.677392                 -0.675825   \n",
       "15                 -0.678873                 -0.676277   \n",
       "21                 -0.680201                 -0.678592   \n",
       "23                 -0.679819                 -0.679093   \n",
       "22                 -0.679819                 -0.679094   \n",
       "24                 -0.677800                 -0.679098   \n",
       "30                 -0.678903                 -0.679826   \n",
       "27                 -0.681685                 -0.681348   \n",
       "28                 -0.681584                 -0.681528   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "16                 -0.673921               -0.675437               0.002411   \n",
       "17                 -0.673923               -0.675437               0.002410   \n",
       "15                 -0.675154               -0.676340               0.002285   \n",
       "21                 -0.676997               -0.676369               0.004120   \n",
       "23                 -0.676975               -0.676439               0.004116   \n",
       "22                 -0.676973               -0.676439               0.004116   \n",
       "24                 -0.675913               -0.676595               0.002768   \n",
       "30                 -0.677732               -0.676665               0.003841   \n",
       "27                 -0.679935               -0.677963               0.004635   \n",
       "28                 -0.679915               -0.677990               0.004632   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "16                       1              0.566248              0.592748   \n",
       "17                       2              0.566248              0.592748   \n",
       "15                       3              0.567643              0.619247   \n",
       "21                       4              0.584379              0.598326   \n",
       "23                       5              0.585774              0.594142   \n",
       "22                       6              0.585774              0.594142   \n",
       "24                       7              0.567643              0.588563   \n",
       "30                       8              0.570432              0.596932   \n",
       "27                       9              0.581590              0.599721   \n",
       "28                      10              0.577406              0.598326   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "16              0.594972              0.571229              0.578212   \n",
       "17              0.594972              0.571229              0.578212   \n",
       "15              0.594972              0.585196              0.569832   \n",
       "21              0.587989              0.565642              0.565642   \n",
       "23              0.587989              0.557263              0.569832   \n",
       "22              0.587989              0.557263              0.569832   \n",
       "24              0.596369              0.561453              0.575419   \n",
       "30              0.585196              0.561453              0.554469   \n",
       "27              0.579609              0.561453              0.555866   \n",
       "28              0.581006              0.562849              0.555866   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "16            0.580682           0.011433                   2  \n",
       "17            0.580682           0.011433                   2  \n",
       "15            0.587378           0.018843                   1  \n",
       "21            0.580396           0.012887                   4  \n",
       "23            0.579000           0.013510                   6  \n",
       "22            0.579000           0.013510                   6  \n",
       "24            0.577889           0.012936                   8  \n",
       "30            0.573696           0.015507                  13  \n",
       "27            0.575648           0.015642                  10  \n",
       "28            0.575091           0.014830                  11  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results = pd.DataFrame(log_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T15:05:58.379932Z",
     "start_time": "2021-05-09T15:05:58.357227Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>home_Rating.A.Pre</td>\n",
       "      <td>-0.057949</td>\n",
       "      <td>0.057949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_5_GF%_5v5</td>\n",
       "      <td>0.056853</td>\n",
       "      <td>0.056853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>away_Goalie_HDCSV%</td>\n",
       "      <td>-0.048104</td>\n",
       "      <td>0.048104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.047458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.045442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>-0.039534</td>\n",
       "      <td>0.039534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>0.036940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>away_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.036372</td>\n",
       "      <td>0.036372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>home_last40_GF_per_min_pp</td>\n",
       "      <td>0.036092</td>\n",
       "      <td>0.036092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>away_last_5_GF%_5v5</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>-0.027892</td>\n",
       "      <td>0.027892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home_last5_GF_per_min_pp</td>\n",
       "      <td>-0.027105</td>\n",
       "      <td>0.027105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>away_last40_GA_per_min_pk</td>\n",
       "      <td>-0.025317</td>\n",
       "      <td>0.025317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>away_last5_GA_per_min_pk</td>\n",
       "      <td>-0.025067</td>\n",
       "      <td>0.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>away_last_40_GF%_5v5</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>0.024895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>home_Goalie_GSAx/60</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.024562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home_last_5_xGF%_5v5</td>\n",
       "      <td>-0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B2B_Status</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>0.020716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>home_last5_xGF_per_min_pp</td>\n",
       "      <td>-0.019800</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>away_last_5_xGF%_5v5</td>\n",
       "      <td>-0.018728</td>\n",
       "      <td>0.018728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_last_5_SH%</td>\n",
       "      <td>-0.016923</td>\n",
       "      <td>0.016923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>home_last_5_FF%_5v5</td>\n",
       "      <td>-0.015822</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_last5_xGA_per_min_pk</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.015449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>-0.014134</td>\n",
       "      <td>0.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>away_last40_GF_per_min_pp</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.013513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.013225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>0.011099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away_last5_xGA_per_min_pk</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.008087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.007119</td>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last40_GA_per_min_pk</td>\n",
       "      <td>-0.007003</td>\n",
       "      <td>0.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>-0.006758</td>\n",
       "      <td>0.006758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>away_last_5_FF%_5v5</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>0.005485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>away_last5_xGF_per_min_pp</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>0.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_last_5_SH%</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.003575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home_last5_GA_per_min_pk</td>\n",
       "      <td>-0.001876</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>away_last5_GF_per_min_pp</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>away_Rating.A.Pre</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature      Coef  Coef_abs\n",
       "19           home_Rating.A.Pre -0.057949  0.057949\n",
       "22         home_last_5_GF%_5v5  0.056853  0.056853\n",
       "37          away_Goalie_HDCSV% -0.048104  0.048104\n",
       "35      away_Goalie_FenwickSV%  0.047458  0.047458\n",
       "9         home_last_40_GF%_5v5  0.045442  0.045442\n",
       "24            home_last_40_SH% -0.039534  0.039534\n",
       "27  home_last40_xGF_per_min_pp -0.036940  0.036940\n",
       "15  away_last40_xGA_per_min_pk -0.036372  0.036372\n",
       "30   home_last40_GF_per_min_pp  0.036092  0.036092\n",
       "38         away_last_5_GF%_5v5  0.032656  0.032656\n",
       "31            away_last_40_SH% -0.027892  0.027892\n",
       "18    home_last5_GF_per_min_pp -0.027105  0.027105\n",
       "28   away_last40_GA_per_min_pk -0.025317  0.025317\n",
       "21    away_last5_GA_per_min_pk -0.025067  0.025067\n",
       "7         away_last_40_GF%_5v5 -0.024895  0.024895\n",
       "40         home_Goalie_GSAx/60  0.024562  0.024562\n",
       "17        home_last_5_xGF%_5v5 -0.022679  0.022679\n",
       "14                  B2B_Status -0.020716  0.020716\n",
       "36   home_last5_xGF_per_min_pp -0.019800  0.019800\n",
       "29        away_last_5_xGF%_5v5 -0.018728  0.018728\n",
       "12        home_last_40_FF%_5v5  0.017911  0.017911\n",
       "4              home_last_5_SH% -0.016923  0.016923\n",
       "33         home_last_5_FF%_5v5 -0.015822  0.015822\n",
       "6    home_last5_xGA_per_min_pk  0.015449  0.015449\n",
       "11          home_Goalie_HDCSV% -0.014134  0.014134\n",
       "0    away_last40_GF_per_min_pp  0.013513  0.013513\n",
       "32  away_last40_xGF_per_min_pp  0.013225  0.013225\n",
       "23         away_Goalie_GSAx/60 -0.011099  0.011099\n",
       "2    away_last5_xGA_per_min_pk  0.008087  0.008087\n",
       "13  home_last40_xGA_per_min_pk -0.007119  0.007119\n",
       "16   home_last40_GA_per_min_pk -0.007003  0.007003\n",
       "25       away_last_40_xGF%_5v5 -0.006758  0.006758\n",
       "10         away_last_5_FF%_5v5 -0.005485  0.005485\n",
       "8    away_last5_xGF_per_min_pp -0.004725  0.004725\n",
       "20             away_last_5_SH%  0.003585  0.003585\n",
       "1         away_last_40_FF%_5v5  0.003575  0.003575\n",
       "26       home_last_40_xGF%_5v5  0.002811  0.002811\n",
       "3       home_Goalie_FenwickSV% -0.001906  0.001906\n",
       "5     home_last5_GA_per_min_pk -0.001876  0.001876\n",
       "34    away_last5_GF_per_min_pp  0.001713  0.001713\n",
       "39           away_Rating.A.Pre -0.001619  0.001619"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_coef = pd.DataFrame(list(zip(X_train.columns, log_cv.best_estimator_[1].coef_[0])), columns = ['Feature', 'Coef'] )\n",
    "log_coef['Coef_abs'] = abs(log_coef['Coef'])\n",
    "log_coef.sort_values('Coef_abs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:41:45.519776Z",
     "start_time": "2021-05-07T20:41:45.509666Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25, 50],\n",
    "         'ada__learning_rate': [.1, 1, 10, 20],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv = GridSearchCV(ada_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:28.422107Z",
     "start_time": "2021-05-07T20:41:46.318203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.1, 1, 10, 20],\n",
       "                         'ada__n_estimators': [25, 50]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:49.571527Z",
     "start_time": "2021-05-07T21:39:49.568150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6799359662807147"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:28.797531Z",
     "start_time": "2021-05-07T21:24:28.766354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.529209</td>\n",
       "      <td>0.277327</td>\n",
       "      <td>2.543278</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683305</td>\n",
       "      <td>-0.674921</td>\n",
       "      <td>-0.681226</td>\n",
       "      <td>-0.681435</td>\n",
       "      <td>-0.678793</td>\n",
       "      <td>-0.679936</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.341996</td>\n",
       "      <td>0.235797</td>\n",
       "      <td>2.495557</td>\n",
       "      <td>0.040371</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682869</td>\n",
       "      <td>-0.679884</td>\n",
       "      <td>-0.681938</td>\n",
       "      <td>-0.681413</td>\n",
       "      <td>-0.681377</td>\n",
       "      <td>-0.681496</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.559740</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.132445</td>\n",
       "      <td>1.405995</td>\n",
       "      <td>5.013317</td>\n",
       "      <td>0.237507</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684522</td>\n",
       "      <td>-0.676831</td>\n",
       "      <td>-0.682880</td>\n",
       "      <td>-0.684050</td>\n",
       "      <td>-0.680332</td>\n",
       "      <td>-0.681723</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.571187</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.064554</td>\n",
       "      <td>1.219384</td>\n",
       "      <td>2.431893</td>\n",
       "      <td>0.203562</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684800</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>-0.682937</td>\n",
       "      <td>-0.684372</td>\n",
       "      <td>-0.680497</td>\n",
       "      <td>-0.682232</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.565324</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684109</td>\n",
       "      <td>-0.681523</td>\n",
       "      <td>-0.684027</td>\n",
       "      <td>-0.682690</td>\n",
       "      <td>-0.682635</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.938708</td>\n",
       "      <td>0.095818</td>\n",
       "      <td>4.740888</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685502</td>\n",
       "      <td>-0.683732</td>\n",
       "      <td>-0.684680</td>\n",
       "      <td>-0.685002</td>\n",
       "      <td>-0.684744</td>\n",
       "      <td>-0.684732</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.542155</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73.917730</td>\n",
       "      <td>4.193198</td>\n",
       "      <td>3.965984</td>\n",
       "      <td>0.348138</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.686802</td>\n",
       "      <td>-0.683494</td>\n",
       "      <td>-0.685372</td>\n",
       "      <td>-0.686456</td>\n",
       "      <td>-0.683155</td>\n",
       "      <td>-0.685056</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.546902</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.229651</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.022538</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.686993</td>\n",
       "      <td>-0.685253</td>\n",
       "      <td>-0.687152</td>\n",
       "      <td>-0.686154</td>\n",
       "      <td>-0.686353</td>\n",
       "      <td>-0.686381</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.582634</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.319119</td>\n",
       "      <td>0.179226</td>\n",
       "      <td>2.073445</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688066</td>\n",
       "      <td>-0.688023</td>\n",
       "      <td>-0.687880</td>\n",
       "      <td>-0.688809</td>\n",
       "      <td>-0.687754</td>\n",
       "      <td>-0.688106</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>9</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.084216</td>\n",
       "      <td>0.296903</td>\n",
       "      <td>4.008086</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688713</td>\n",
       "      <td>-0.688734</td>\n",
       "      <td>-0.688831</td>\n",
       "      <td>-0.688501</td>\n",
       "      <td>-0.688628</td>\n",
       "      <td>-0.688681</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      42.529209      0.277327         2.543278        0.006013   \n",
       "0      43.341996      0.235797         2.495557        0.040371   \n",
       "5      83.132445      1.405995         5.013317        0.237507   \n",
       "6      41.064554      1.219384         2.431893        0.203562   \n",
       "8       0.122800      0.002372         0.015609        0.000248   \n",
       "1      81.938708      0.095818         4.740888        0.009278   \n",
       "7      73.917730      4.193198         3.965984        0.348138   \n",
       "9       0.229651      0.005856         0.022538        0.000169   \n",
       "2      35.319119      0.179226         2.073445        0.010988   \n",
       "3      68.084216      0.296903         4.008086        0.018197   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "4  SVC(kernel='linear', probability=True)                       10   \n",
       "0  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5  SVC(kernel='linear', probability=True)                       10   \n",
       "6  SVC(kernel='linear', probability=True)                       20   \n",
       "8                    LogisticRegression()                      0.1   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "7  SVC(kernel='linear', probability=True)                       20   \n",
       "9                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "3  SVC(kernel='linear', probability=True)                        1   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "4                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "8                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "1                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "7                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "9                      50  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "3                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.683305                 -0.674921   \n",
       "0                 -0.682869                 -0.679884   \n",
       "5                 -0.684522                 -0.676831   \n",
       "6                 -0.684800                 -0.678553   \n",
       "8                 -0.684109                 -0.681523   \n",
       "1                 -0.685502                 -0.683732   \n",
       "7                 -0.686802                 -0.683494   \n",
       "9                 -0.686993                 -0.685253   \n",
       "2                 -0.688066                 -0.688023   \n",
       "3                 -0.688713                 -0.688734   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.681226                 -0.681435   \n",
       "0                 -0.681938                 -0.681413   \n",
       "5                 -0.682880                 -0.684050   \n",
       "6                 -0.682937                 -0.684372   \n",
       "8                 -0.684027                 -0.682690   \n",
       "1                 -0.684680                 -0.685002   \n",
       "7                 -0.685372                 -0.686456   \n",
       "9                 -0.687152                 -0.686154   \n",
       "2                 -0.687880                 -0.688809   \n",
       "3                 -0.688831                 -0.688501   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.678793               -0.679936               0.002889   \n",
       "0                 -0.681377               -0.681496               0.000969   \n",
       "5                 -0.680332               -0.681723               0.002844   \n",
       "6                 -0.680497               -0.682232               0.002375   \n",
       "8                 -0.682635               -0.682997               0.000969   \n",
       "1                 -0.684744               -0.684732               0.000578   \n",
       "7                 -0.683155               -0.685056               0.001494   \n",
       "9                 -0.686353               -0.686381               0.000677   \n",
       "2                 -0.687754               -0.688106               0.000368   \n",
       "3                 -0.688628               -0.688681               0.000111   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.553696              0.596932   \n",
       "0                       2              0.560669              0.569038   \n",
       "5                       3              0.557880              0.591353   \n",
       "6                       4              0.545328              0.594142   \n",
       "8                       5              0.564854              0.594142   \n",
       "1                       6              0.543933              0.542538   \n",
       "7                       7              0.543933              0.545328   \n",
       "9                       8              0.569038              0.602510   \n",
       "2                       9              0.543933              0.543933   \n",
       "3                      10              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.583799              0.561453              0.569832   \n",
       "0              0.564246              0.551676              0.553073   \n",
       "5              0.585196              0.554469              0.567039   \n",
       "6              0.571229              0.546089              0.569832   \n",
       "8              0.597765              0.569832              0.581006   \n",
       "1              0.537709              0.540503              0.546089   \n",
       "7              0.540503              0.543296              0.561453   \n",
       "9              0.597765              0.572626              0.571229   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "3              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.573142           0.015526                   4  \n",
       "0            0.559740           0.006589                   8  \n",
       "5            0.571187           0.014674                   6  \n",
       "6            0.565324           0.018196                   7  \n",
       "8            0.581520           0.012945                   2  \n",
       "1            0.542155           0.002873                  12  \n",
       "7            0.546902           0.007443                   9  \n",
       "9            0.582634           0.014416                   1  \n",
       "2            0.543830           0.000517                  10  \n",
       "3            0.543830           0.000517                  10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(ada_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:29.172013Z",
     "start_time": "2021-05-07T21:24:29.167686Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "gb_params = {'gb__n_estimators': [200, 300, 400],\n",
    "         'gb__learning_rate': [.001,.01, .1],\n",
    "         'gb__max_depth' : [3,5]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipeline, param_grid=gb_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:48.284336Z",
     "start_time": "2021-05-07T21:24:29.598260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last5_GF_per_min_pp',\n",
       "                                                                          'away_last_40_GF%_5v5',\n",
       "                                                                          'away_last_40_SH%',\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('gb', GradientBoostingClassifier())]),\n",
       "             param_grid={'gb__learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'gb__max_depth': [3, 5],\n",
       "                         'gb__n_estimators': [200, 300, 400]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:48.700152Z",
     "start_time": "2021-05-07T21:39:48.696870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6813351464598496"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:49.128256Z",
     "start_time": "2021-05-07T21:39:49.105537Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.060808</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.013046</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682658</td>\n",
       "      <td>-0.679488</td>\n",
       "      <td>-0.684309</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.679678</td>\n",
       "      <td>-0.681335</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.574265</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.613778</td>\n",
       "      <td>0.132845</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682625</td>\n",
       "      <td>-0.679836</td>\n",
       "      <td>-0.685340</td>\n",
       "      <td>-0.681250</td>\n",
       "      <td>-0.680842</td>\n",
       "      <td>-0.681979</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.091404</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682338</td>\n",
       "      <td>-0.681422</td>\n",
       "      <td>-0.686645</td>\n",
       "      <td>-0.682562</td>\n",
       "      <td>-0.682085</td>\n",
       "      <td>-0.683010</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.066107</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683842</td>\n",
       "      <td>-0.681349</td>\n",
       "      <td>-0.688062</td>\n",
       "      <td>-0.682242</td>\n",
       "      <td>-0.684823</td>\n",
       "      <td>-0.684064</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.568958</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.050758</td>\n",
       "      <td>0.085446</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685737</td>\n",
       "      <td>-0.683565</td>\n",
       "      <td>-0.686076</td>\n",
       "      <td>-0.685384</td>\n",
       "      <td>-0.684671</td>\n",
       "      <td>-0.685087</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>5</td>\n",
       "      <td>0.538354</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.995703</td>\n",
       "      <td>0.058481</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685431</td>\n",
       "      <td>-0.682782</td>\n",
       "      <td>-0.689631</td>\n",
       "      <td>-0.685636</td>\n",
       "      <td>-0.684904</td>\n",
       "      <td>-0.685677</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>6</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.986876</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686009</td>\n",
       "      <td>-0.683521</td>\n",
       "      <td>-0.688014</td>\n",
       "      <td>-0.686682</td>\n",
       "      <td>-0.685319</td>\n",
       "      <td>-0.685909</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>7</td>\n",
       "      <td>0.531381</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.542153</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.521795</td>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.015967</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686319</td>\n",
       "      <td>-0.684856</td>\n",
       "      <td>-0.686472</td>\n",
       "      <td>-0.686419</td>\n",
       "      <td>-0.685634</td>\n",
       "      <td>-0.685940</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.542713</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.228661</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683065</td>\n",
       "      <td>-0.684688</td>\n",
       "      <td>-0.690831</td>\n",
       "      <td>-0.686171</td>\n",
       "      <td>-0.688825</td>\n",
       "      <td>-0.686716</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>9</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.566724</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.987818</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.016568</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686886</td>\n",
       "      <td>-0.685194</td>\n",
       "      <td>-0.688012</td>\n",
       "      <td>-0.688228</td>\n",
       "      <td>-0.685266</td>\n",
       "      <td>-0.686717</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>10</td>\n",
       "      <td>0.535565</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.550279</td>\n",
       "      <td>0.541876</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        5.060808      0.005743         0.013046        0.000360   \n",
       "7        7.613778      0.132845         0.014969        0.000935   \n",
       "8       10.091404      0.022878         0.015978        0.000220   \n",
       "9        8.066107      0.019059         0.016398        0.000273   \n",
       "2       10.050758      0.085446         0.018590        0.000354   \n",
       "5       15.995703      0.058481         0.026158        0.001207   \n",
       "4       11.986876      0.043948         0.021257        0.000472   \n",
       "1        7.521795      0.034738         0.015967        0.000136   \n",
       "10      12.228661      0.028340         0.019323        0.000183   \n",
       "3        7.987818      0.031277         0.016568        0.000518   \n",
       "\n",
       "   param_gb__learning_rate param_gb__max_depth param_gb__n_estimators  \\\n",
       "6                     0.01                   3                    200   \n",
       "7                     0.01                   3                    300   \n",
       "8                     0.01                   3                    400   \n",
       "9                     0.01                   5                    200   \n",
       "2                    0.001                   3                    400   \n",
       "5                    0.001                   5                    400   \n",
       "4                    0.001                   5                    300   \n",
       "1                    0.001                   3                    300   \n",
       "10                    0.01                   5                    300   \n",
       "3                    0.001                   5                    200   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "7   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "8   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "9   {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "2   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "5   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "4   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "1   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "10  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "3   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.682658                 -0.679488   \n",
       "7                  -0.682625                 -0.679836   \n",
       "8                  -0.682338                 -0.681422   \n",
       "9                  -0.683842                 -0.681349   \n",
       "2                  -0.685737                 -0.683565   \n",
       "5                  -0.685431                 -0.682782   \n",
       "4                  -0.686009                 -0.683521   \n",
       "1                  -0.686319                 -0.684856   \n",
       "10                 -0.683065                 -0.684688   \n",
       "3                  -0.686886                 -0.685194   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.684309                 -0.680543   \n",
       "7                  -0.685340                 -0.681250   \n",
       "8                  -0.686645                 -0.682562   \n",
       "9                  -0.688062                 -0.682242   \n",
       "2                  -0.686076                 -0.685384   \n",
       "5                  -0.689631                 -0.685636   \n",
       "4                  -0.688014                 -0.686682   \n",
       "1                  -0.686472                 -0.686419   \n",
       "10                 -0.690831                 -0.686171   \n",
       "3                  -0.688012                 -0.688228   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.679678               -0.681335               0.001864   \n",
       "7                  -0.680842               -0.681979               0.001904   \n",
       "8                  -0.682085               -0.683010               0.001857   \n",
       "9                  -0.684823               -0.684064               0.002336   \n",
       "2                  -0.684671               -0.685087               0.000892   \n",
       "5                  -0.684904               -0.685677               0.002221   \n",
       "4                  -0.685319               -0.685909               0.001489   \n",
       "1                  -0.685634               -0.685940               0.000621   \n",
       "10                 -0.688825               -0.686716               0.002797   \n",
       "3                  -0.685266               -0.686717               0.001297   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.559275              0.570432   \n",
       "7                        2              0.550907              0.557880   \n",
       "8                        3              0.549512              0.559275   \n",
       "9                        4              0.559275              0.570432   \n",
       "2                        5              0.538354              0.548117   \n",
       "5                        6              0.536960              0.560669   \n",
       "4                        7              0.531381              0.560669   \n",
       "1                        8              0.542538              0.545328   \n",
       "10                       9              0.566248              0.560669   \n",
       "3                       10              0.535565              0.546722   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.590782              0.568436              0.582402   \n",
       "7               0.586592              0.565642              0.579609   \n",
       "8               0.585196              0.572626              0.574022   \n",
       "9               0.571229              0.581006              0.562849   \n",
       "2               0.539106              0.551676              0.541899   \n",
       "5               0.526536              0.544693              0.547486   \n",
       "4               0.533520              0.537709              0.547486   \n",
       "1               0.539106              0.543296              0.543296   \n",
       "10              0.567039              0.575419              0.564246   \n",
       "3               0.536313              0.540503              0.550279   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.574265           0.011067                   1  \n",
       "7             0.568126           0.013270                   3  \n",
       "8             0.568126           0.012419                   3  \n",
       "9             0.568958           0.007531                   2  \n",
       "2             0.543831           0.005215                  13  \n",
       "5             0.543269           0.011335                  14  \n",
       "4             0.542153           0.010785                  16  \n",
       "1             0.542713           0.002028                  15  \n",
       "10            0.566724           0.004873                   6  \n",
       "3             0.541876           0.005775                  17  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.DataFrame(gb_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "gb_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not seem that gradient boosting is producing good results for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T18:13:40.072986Z",
     "start_time": "2021-05-09T18:13:40.067201Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='relu', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=44, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:17:21.074710Z",
     "start_time": "2021-05-09T20:17:21.066087Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 12, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['sigmoid', 'hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 18, 24, 30, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3, 5],\n",
    "             'nn__dropout_rate' : [0.0,  0.3, 0.6, 0.9]}\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_cv = GridSearchCV(estimator=nn_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:01:23.976270Z",
     "start_time": "2021-05-09T23:01:23.937431Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>0.683245</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.104092</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.667990</td>\n",
       "      <td>-0.671304</td>\n",
       "      <td>-0.681146</td>\n",
       "      <td>-0.673480</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0.921380</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.104325</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671125</td>\n",
       "      <td>-0.671530</td>\n",
       "      <td>-0.678915</td>\n",
       "      <td>-0.673857</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.570352</td>\n",
       "      <td>0.585706</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0.678168</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.103484</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669233</td>\n",
       "      <td>-0.672437</td>\n",
       "      <td>-0.680127</td>\n",
       "      <td>-0.673932</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.593802</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.582635</td>\n",
       "      <td>0.018831</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>0.749562</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669233</td>\n",
       "      <td>-0.672677</td>\n",
       "      <td>-0.679914</td>\n",
       "      <td>-0.673941</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591290</td>\n",
       "      <td>0.589615</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.576494</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.874522</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.670200</td>\n",
       "      <td>-0.672712</td>\n",
       "      <td>-0.678995</td>\n",
       "      <td>-0.673969</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>5</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.572027</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1.246649</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.114459</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670564</td>\n",
       "      <td>-0.672294</td>\n",
       "      <td>-0.679264</td>\n",
       "      <td>-0.674041</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1.408697</td>\n",
       "      <td>0.335738</td>\n",
       "      <td>0.113080</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.671396</td>\n",
       "      <td>-0.671077</td>\n",
       "      <td>-0.679764</td>\n",
       "      <td>-0.674079</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>7</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.558626</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.939249</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.103511</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669046</td>\n",
       "      <td>-0.672297</td>\n",
       "      <td>-0.680904</td>\n",
       "      <td>-0.674082</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.106048</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670960</td>\n",
       "      <td>-0.671626</td>\n",
       "      <td>-0.680003</td>\n",
       "      <td>-0.674196</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>9</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.558626</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>0.871623</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.104613</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671955</td>\n",
       "      <td>-0.671238</td>\n",
       "      <td>-0.679398</td>\n",
       "      <td>-0.674197</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>10</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0.921179</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670706</td>\n",
       "      <td>-0.672330</td>\n",
       "      <td>-0.679629</td>\n",
       "      <td>-0.674222</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>11</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.589615</td>\n",
       "      <td>0.567002</td>\n",
       "      <td>0.579844</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>1.023331</td>\n",
       "      <td>0.320061</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.671041</td>\n",
       "      <td>-0.671874</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.674283</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>12</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1.178353</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.113529</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.672623</td>\n",
       "      <td>-0.671722</td>\n",
       "      <td>-0.678596</td>\n",
       "      <td>-0.674313</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.600503</td>\n",
       "      <td>0.554439</td>\n",
       "      <td>0.578448</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1.074261</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.110129</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670762</td>\n",
       "      <td>-0.672479</td>\n",
       "      <td>-0.679802</td>\n",
       "      <td>-0.674348</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>14</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1.212478</td>\n",
       "      <td>0.089578</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>-0.673103</td>\n",
       "      <td>-0.677960</td>\n",
       "      <td>-0.674359</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>15</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.556951</td>\n",
       "      <td>0.580960</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1.085747</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.671666</td>\n",
       "      <td>-0.679904</td>\n",
       "      <td>-0.674415</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.912594</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.125086</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.669985</td>\n",
       "      <td>-0.671224</td>\n",
       "      <td>-0.682035</td>\n",
       "      <td>-0.674415</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>17</td>\n",
       "      <td>0.593802</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.570352</td>\n",
       "      <td>0.586823</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>0.969764</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.104657</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670421</td>\n",
       "      <td>-0.672993</td>\n",
       "      <td>-0.679859</td>\n",
       "      <td>-0.674424</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>18</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.848925</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'sigmoid', 'nn__dropout_rat...</td>\n",
       "      <td>-0.670706</td>\n",
       "      <td>-0.671857</td>\n",
       "      <td>-0.680712</td>\n",
       "      <td>-0.674425</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>19</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.569514</td>\n",
       "      <td>0.582356</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1.126699</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.110831</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.670583</td>\n",
       "      <td>-0.671629</td>\n",
       "      <td>-0.681087</td>\n",
       "      <td>-0.674433</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>20</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.584869</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1648       0.683245      0.006266         0.104092        0.001678   \n",
       "1732       0.921380      0.005455         0.104325        0.000706   \n",
       "1828       0.678168      0.001133         0.103484        0.001109   \n",
       "1683       0.749562      0.003505         0.103456        0.001720   \n",
       "1147       0.874522      0.008508         0.112667        0.000833   \n",
       "1967       1.246649      0.069900         0.114459        0.003921   \n",
       "1249       1.408697      0.335738         0.113080        0.001698   \n",
       "1757       0.939249      0.004742         0.103511        0.000758   \n",
       "1916       0.996610      0.017258         0.106048        0.002964   \n",
       "1873       0.871623      0.010311         0.104613        0.000707   \n",
       "1733       0.921179      0.003043         0.103079        0.000449   \n",
       "932        1.023331      0.320061         0.112998        0.002264   \n",
       "1965       1.178353      0.028323         0.113529        0.008736   \n",
       "1934       1.074261      0.022438         0.110129        0.001621   \n",
       "1958       1.212478      0.089578         0.120485        0.016126   \n",
       "1977       1.085747      0.011293         0.104824        0.001167   \n",
       "790        0.912594      0.043003         0.125086        0.012163   \n",
       "1728       0.969764      0.006170         0.104657        0.001410   \n",
       "26         0.848925      0.012358         0.117771        0.003938   \n",
       "1247       1.126699      0.007119         0.110831        0.001022   \n",
       "\n",
       "     param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "1648               linear                    0.3                8   \n",
       "1732               linear                    0.3               15   \n",
       "1828               linear                    0.6                8   \n",
       "1683               linear                    0.3               10   \n",
       "1147         hard_sigmoid                    0.6               10   \n",
       "1967               linear                    0.6               18   \n",
       "1249         hard_sigmoid                    0.6               18   \n",
       "1757               linear                    0.3               15   \n",
       "1916               linear                    0.6               15   \n",
       "1873               linear                    0.6               12   \n",
       "1733               linear                    0.3               15   \n",
       "932          hard_sigmoid                    0.3                8   \n",
       "1965               linear                    0.6               18   \n",
       "1934               linear                    0.6               15   \n",
       "1958               linear                    0.6               18   \n",
       "1977               linear                    0.6               18   \n",
       "790          hard_sigmoid                      0               10   \n",
       "1728               linear                    0.3               15   \n",
       "26                sigmoid                      0                8   \n",
       "1247         hard_sigmoid                    0.6               18   \n",
       "\n",
       "     param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "1648                36                Adam                           3   \n",
       "1732                12                Adam                           3   \n",
       "1828                36                Adam                           3   \n",
       "1683                36                Adam                           1   \n",
       "1147                40             RMSprop                           3   \n",
       "1967                30                Adam                           5   \n",
       "1249                36             RMSprop                           3   \n",
       "1757                36                Adam                           5   \n",
       "1916                18             RMSprop                           5   \n",
       "1873                12             RMSprop                           3   \n",
       "1733                12                Adam                           5   \n",
       "932                 40             RMSprop                           5   \n",
       "1965                30                Adam                           1   \n",
       "1934                36             RMSprop                           5   \n",
       "1958                24             RMSprop                           5   \n",
       "1977                40                Adam                           1   \n",
       "790                 40                Adam                           3   \n",
       "1728                12             RMSprop                           1   \n",
       "26                  36             RMSprop                           5   \n",
       "1247                30                Adam                           5   \n",
       "\n",
       "                                                 params  \\\n",
       "1648  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1732  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1828  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1683  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1147  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1967  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1249  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1757  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1916  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1873  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1733  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "932   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1965  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1934  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1958  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1977  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "790   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1728  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "26    {'nn__activation': 'sigmoid', 'nn__dropout_rat...   \n",
       "1247  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "\n",
       "      split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1648                 -0.667990                 -0.671304   \n",
       "1732                 -0.671125                 -0.671530   \n",
       "1828                 -0.669233                 -0.672437   \n",
       "1683                 -0.669233                 -0.672677   \n",
       "1147                 -0.670200                 -0.672712   \n",
       "1967                 -0.670564                 -0.672294   \n",
       "1249                 -0.671396                 -0.671077   \n",
       "1757                 -0.669046                 -0.672297   \n",
       "1916                 -0.670960                 -0.671626   \n",
       "1873                 -0.671955                 -0.671238   \n",
       "1733                 -0.670706                 -0.672330   \n",
       "932                  -0.671041                 -0.671874   \n",
       "1965                 -0.672623                 -0.671722   \n",
       "1934                 -0.670762                 -0.672479   \n",
       "1958                 -0.672012                 -0.673103   \n",
       "1977                 -0.671674                 -0.671666   \n",
       "790                  -0.669985                 -0.671224   \n",
       "1728                 -0.670421                 -0.672993   \n",
       "26                   -0.670706                 -0.671857   \n",
       "1247                 -0.670583                 -0.671629   \n",
       "\n",
       "      split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1648                 -0.681146               -0.673480               0.005587   \n",
       "1732                 -0.678915               -0.673857               0.003580   \n",
       "1828                 -0.680127               -0.673932               0.004571   \n",
       "1683                 -0.679914               -0.673941               0.004451   \n",
       "1147                 -0.678995               -0.673969               0.003699   \n",
       "1967                 -0.679264               -0.674041               0.003760   \n",
       "1249                 -0.679764               -0.674079               0.004022   \n",
       "1757                 -0.680904               -0.674082               0.005003   \n",
       "1916                 -0.680003               -0.674196               0.004115   \n",
       "1873                 -0.679398               -0.674197               0.003689   \n",
       "1733                 -0.679629               -0.674222               0.003881   \n",
       "932                  -0.679935               -0.674283               0.004011   \n",
       "1965                 -0.678596               -0.674313               0.003050   \n",
       "1934                 -0.679802               -0.674348               0.003920   \n",
       "1958                 -0.677960               -0.674359               0.002586   \n",
       "1977                 -0.679904               -0.674415               0.003882   \n",
       "790                  -0.682035               -0.674415               0.005412   \n",
       "1728                 -0.679859               -0.674424               0.003984   \n",
       "26                   -0.680712               -0.674425               0.004470   \n",
       "1247                 -0.681087               -0.674433               0.004724   \n",
       "\n",
       "      rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1648                       1              0.592965              0.582077   \n",
       "1732                       2              0.587940              0.598827   \n",
       "1828                       3              0.597990              0.593802   \n",
       "1683                       4              0.591290              0.589615   \n",
       "1147                       5              0.588777              0.592965   \n",
       "1967                       6              0.578727              0.586265   \n",
       "1249                       7              0.583752              0.601340   \n",
       "1757                       8              0.596315              0.597152   \n",
       "1916                       9              0.598827              0.598827   \n",
       "1873                      10              0.582915              0.599665   \n",
       "1733                      11              0.582915              0.589615   \n",
       "932                       12              0.587102              0.596315   \n",
       "1965                      13              0.580402              0.600503   \n",
       "1934                      14              0.596315              0.601340   \n",
       "1958                      15              0.584590              0.601340   \n",
       "1977                      16              0.587940              0.599665   \n",
       "790                       17              0.593802              0.596315   \n",
       "1728                      18              0.588777              0.595477   \n",
       "26                        19              0.580402              0.597152   \n",
       "1247                      20              0.587102              0.603015   \n",
       "\n",
       "      split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "1648              0.568677            0.581240           0.009933   \n",
       "1732              0.570352            0.585706           0.011732   \n",
       "1828              0.556114            0.582635           0.018831   \n",
       "1683              0.548576            0.576494           0.019752   \n",
       "1147              0.572027            0.584590           0.009046   \n",
       "1967              0.560302            0.575098           0.010906   \n",
       "1249              0.558626            0.581240           0.017528   \n",
       "1757              0.555276            0.582915           0.019546   \n",
       "1916              0.558626            0.585427           0.018951   \n",
       "1873              0.557789            0.580123           0.017209   \n",
       "1733              0.567002            0.579844           0.009484   \n",
       "932               0.562814            0.582077           0.014131   \n",
       "1965              0.554439            0.578448           0.018856   \n",
       "1934              0.556114            0.584590           0.020240   \n",
       "1958              0.556951            0.580960           0.018302   \n",
       "1977              0.557789            0.581798           0.017639   \n",
       "790               0.570352            0.586823           0.011692   \n",
       "1728              0.560302            0.581519           0.015250   \n",
       "26                0.569514            0.582356           0.011368   \n",
       "1247              0.564489            0.584869           0.015807   \n",
       "\n",
       "      rank_test_accuracy  \n",
       "1648                 572  \n",
       "1732                  48  \n",
       "1828                 333  \n",
       "1683                1258  \n",
       "1147                 112  \n",
       "1967                1375  \n",
       "1249                 549  \n",
       "1757                 292  \n",
       "1916                  66  \n",
       "1873                 738  \n",
       "1733                 780  \n",
       "932                  451  \n",
       "1965                1011  \n",
       "1934                 112  \n",
       "1958                 591  \n",
       "1977                 472  \n",
       "790                   19  \n",
       "1728                 514  \n",
       "26                   389  \n",
       "1247                  96  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results = pd.DataFrame(nn_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T15:13:11.512761Z",
     "start_time": "2021-05-09T15:13:11.483795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>home_last5_GA_per_min_pk</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>B2B_Status</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>home_last5_GF_per_min_pp</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>away_last5_GA_per_min_pk</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_GF_per_min_pp</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>0.143045</td>\n",
       "      <td>49.490424</td>\n",
       "      <td>0.099403</td>\n",
       "      <td>0.936798</td>\n",
       "      <td>11.116202</td>\n",
       "      <td>0.125852</td>\n",
       "      <td>0.085579</td>\n",
       "      <td>49.414366</td>\n",
       "      <td>0.099288</td>\n",
       "      <td>55.248131</td>\n",
       "      <td>52.420611</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>51.037671</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.112016</td>\n",
       "      <td>49.383378</td>\n",
       "      <td>0.135211</td>\n",
       "      <td>1531.48</td>\n",
       "      <td>12.303834</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>70.852804</td>\n",
       "      <td>-0.291447</td>\n",
       "      <td>10.024139</td>\n",
       "      <td>49.580182</td>\n",
       "      <td>50.833631</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.111851</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>0.134196</td>\n",
       "      <td>8.701463</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>45.981465</td>\n",
       "      <td>0.100545</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.184563</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>51.402501</td>\n",
       "      <td>1514.01</td>\n",
       "      <td>-0.097290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>0.090023</td>\n",
       "      <td>54.275967</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.936070</td>\n",
       "      <td>4.301552</td>\n",
       "      <td>0.041580</td>\n",
       "      <td>0.121414</td>\n",
       "      <td>49.447384</td>\n",
       "      <td>0.127152</td>\n",
       "      <td>51.613248</td>\n",
       "      <td>52.992021</td>\n",
       "      <td>0.866051</td>\n",
       "      <td>50.926333</td>\n",
       "      <td>0.095972</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0.115594</td>\n",
       "      <td>0.117612</td>\n",
       "      <td>50.132908</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>1516.52</td>\n",
       "      <td>7.762699</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>38.219070</td>\n",
       "      <td>-0.444146</td>\n",
       "      <td>9.385230</td>\n",
       "      <td>54.826724</td>\n",
       "      <td>52.907871</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>0.112607</td>\n",
       "      <td>51.670507</td>\n",
       "      <td>0.161440</td>\n",
       "      <td>6.807514</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>49.602278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930668</td>\n",
       "      <td>0.109118</td>\n",
       "      <td>0.862233</td>\n",
       "      <td>45.479328</td>\n",
       "      <td>1497.57</td>\n",
       "      <td>-0.305563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>0.084120</td>\n",
       "      <td>49.003131</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>0.941531</td>\n",
       "      <td>9.037111</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.126279</td>\n",
       "      <td>51.252598</td>\n",
       "      <td>0.079574</td>\n",
       "      <td>60.496256</td>\n",
       "      <td>54.862177</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>53.085863</td>\n",
       "      <td>0.101065</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.106525</td>\n",
       "      <td>45.294475</td>\n",
       "      <td>0.107978</td>\n",
       "      <td>1584.31</td>\n",
       "      <td>10.027155</td>\n",
       "      <td>0.103627</td>\n",
       "      <td>60.267559</td>\n",
       "      <td>-0.589420</td>\n",
       "      <td>9.975409</td>\n",
       "      <td>47.514358</td>\n",
       "      <td>55.396941</td>\n",
       "      <td>0.095347</td>\n",
       "      <td>0.089670</td>\n",
       "      <td>53.023663</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>9.212376</td>\n",
       "      <td>0.107010</td>\n",
       "      <td>45.077430</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.923432</td>\n",
       "      <td>0.070186</td>\n",
       "      <td>0.857809</td>\n",
       "      <td>61.850921</td>\n",
       "      <td>1492.13</td>\n",
       "      <td>-0.023160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>0.128256</td>\n",
       "      <td>47.274508</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.938316</td>\n",
       "      <td>8.090750</td>\n",
       "      <td>0.093604</td>\n",
       "      <td>0.177847</td>\n",
       "      <td>48.647099</td>\n",
       "      <td>0.108124</td>\n",
       "      <td>47.474864</td>\n",
       "      <td>50.476839</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>48.540721</td>\n",
       "      <td>0.114551</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.103250</td>\n",
       "      <td>40.077257</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1490.93</td>\n",
       "      <td>9.177190</td>\n",
       "      <td>0.134933</td>\n",
       "      <td>54.709532</td>\n",
       "      <td>-0.408527</td>\n",
       "      <td>8.348491</td>\n",
       "      <td>46.039131</td>\n",
       "      <td>48.384948</td>\n",
       "      <td>0.111322</td>\n",
       "      <td>0.116931</td>\n",
       "      <td>46.782178</td>\n",
       "      <td>0.154044</td>\n",
       "      <td>8.973817</td>\n",
       "      <td>0.098805</td>\n",
       "      <td>42.512283</td>\n",
       "      <td>0.132939</td>\n",
       "      <td>0.927771</td>\n",
       "      <td>0.097037</td>\n",
       "      <td>0.852194</td>\n",
       "      <td>46.931408</td>\n",
       "      <td>1510.30</td>\n",
       "      <td>-0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>0.161435</td>\n",
       "      <td>53.469034</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.938738</td>\n",
       "      <td>7.875987</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>58.414704</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>55.777256</td>\n",
       "      <td>51.059929</td>\n",
       "      <td>0.852300</td>\n",
       "      <td>54.173584</td>\n",
       "      <td>0.115045</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0.124851</td>\n",
       "      <td>0.091751</td>\n",
       "      <td>56.002144</td>\n",
       "      <td>0.220913</td>\n",
       "      <td>1549.43</td>\n",
       "      <td>4.253558</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>38.859857</td>\n",
       "      <td>-0.058439</td>\n",
       "      <td>8.037510</td>\n",
       "      <td>53.596844</td>\n",
       "      <td>54.433969</td>\n",
       "      <td>0.107819</td>\n",
       "      <td>0.142055</td>\n",
       "      <td>49.845393</td>\n",
       "      <td>0.118953</td>\n",
       "      <td>8.848351</td>\n",
       "      <td>0.128311</td>\n",
       "      <td>53.025519</td>\n",
       "      <td>0.155440</td>\n",
       "      <td>0.936047</td>\n",
       "      <td>0.090133</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>51.400000</td>\n",
       "      <td>1526.11</td>\n",
       "      <td>-0.054610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      away_last40_GF_per_min_pp  away_last_40_FF%_5v5  \\\n",
       "3626                   0.143045             49.490424   \n",
       "3627                   0.090023             54.275967   \n",
       "3628                   0.084120             49.003131   \n",
       "3629                   0.128256             47.274508   \n",
       "3630                   0.161435             53.469034   \n",
       "\n",
       "      away_last5_xGA_per_min_pk  home_Goalie_FenwickSV%  home_last_5_SH%  \\\n",
       "3626                   0.099403                0.936798        11.116202   \n",
       "3627                   0.084000                0.936070         4.301552   \n",
       "3628                   0.108808                0.941531         9.037111   \n",
       "3629                   0.148426                0.938316         8.090750   \n",
       "3630                   0.100000                0.938738         7.875987   \n",
       "\n",
       "      home_last5_GA_per_min_pk  home_last5_xGA_per_min_pk  \\\n",
       "3626                  0.125852                   0.085579   \n",
       "3627                  0.041580                   0.121414   \n",
       "3628                  0.139535                   0.126279   \n",
       "3629                  0.093604                   0.177847   \n",
       "3630                  0.074488                   0.094972   \n",
       "\n",
       "      away_last_40_GF%_5v5  away_last5_xGF_per_min_pp  home_last_40_GF%_5v5  \\\n",
       "3626             49.414366                   0.099288             55.248131   \n",
       "3627             49.447384                   0.127152             51.613248   \n",
       "3628             51.252598                   0.079574             60.496256   \n",
       "3629             48.647099                   0.108124             47.474864   \n",
       "3630             58.414704                   0.117617             55.777256   \n",
       "\n",
       "      away_last_5_FF%_5v5  home_Goalie_HDCSV%  home_last_40_FF%_5v5  \\\n",
       "3626            52.420611            0.869565             51.037671   \n",
       "3627            52.992021            0.866051             50.926333   \n",
       "3628            54.862177            0.876847             53.085863   \n",
       "3629            50.476839            0.867299             48.540721   \n",
       "3630            51.059929            0.852300             54.173584   \n",
       "\n",
       "      home_last40_xGA_per_min_pk B2B_Status  away_last40_xGA_per_min_pk  \\\n",
       "3626                    0.088716    Neither                    0.094008   \n",
       "3627                    0.095972    Neither                    0.115594   \n",
       "3628                    0.101065    Neither                    0.103226   \n",
       "3629                    0.114551    Neither                    0.110110   \n",
       "3630                    0.115045    Neither                    0.124851   \n",
       "\n",
       "      home_last40_GA_per_min_pk  home_last_5_xGF%_5v5  \\\n",
       "3626                   0.112016             49.383378   \n",
       "3627                   0.117612             50.132908   \n",
       "3628                   0.106525             45.294475   \n",
       "3629                   0.103250             40.077257   \n",
       "3630                   0.091751             56.002144   \n",
       "\n",
       "      home_last5_GF_per_min_pp  home_Rating.A.Pre  away_last_5_SH%  \\\n",
       "3626                  0.135211            1531.48        12.303834   \n",
       "3627                  0.059465            1516.52         7.762699   \n",
       "3628                  0.107978            1584.31        10.027155   \n",
       "3629                  0.148148            1490.93         9.177190   \n",
       "3630                  0.220913            1549.43         4.253558   \n",
       "\n",
       "      away_last5_GA_per_min_pk  home_last_5_GF%_5v5  away_Goalie_GSAx/60  \\\n",
       "3626                  0.089552            70.852804            -0.291447   \n",
       "3627                  0.112500            38.219070            -0.444146   \n",
       "3628                  0.103627            60.267559            -0.589420   \n",
       "3629                  0.134933            54.709532            -0.408527   \n",
       "3630                  0.102564            38.859857            -0.058439   \n",
       "\n",
       "      home_last_40_SH%  away_last_40_xGF%_5v5  home_last_40_xGF%_5v5  \\\n",
       "3626         10.024139              49.580182              50.833631   \n",
       "3627          9.385230              54.826724              52.907871   \n",
       "3628          9.975409              47.514358              55.396941   \n",
       "3629          8.348491              46.039131              48.384948   \n",
       "3630          8.037510              53.596844              54.433969   \n",
       "\n",
       "      home_last40_xGF_per_min_pp  away_last40_GA_per_min_pk  \\\n",
       "3626                    0.104625                   0.111851   \n",
       "3627                    0.102876                   0.112607   \n",
       "3628                    0.095347                   0.089670   \n",
       "3629                    0.111322                   0.116931   \n",
       "3630                    0.107819                   0.142055   \n",
       "\n",
       "      away_last_5_xGF%_5v5  home_last40_GF_per_min_pp  away_last_40_SH%  \\\n",
       "3626             50.666667                   0.134196          8.701463   \n",
       "3627             51.670507                   0.161440          6.807514   \n",
       "3628             53.023663                   0.098296          9.212376   \n",
       "3629             46.782178                   0.154044          8.973817   \n",
       "3630             49.845393                   0.118953          8.848351   \n",
       "\n",
       "      away_last40_xGF_per_min_pp  home_last_5_FF%_5v5  \\\n",
       "3626                    0.122230            45.981465   \n",
       "3627                    0.093567            49.602278   \n",
       "3628                    0.107010            45.077430   \n",
       "3629                    0.098805            42.512283   \n",
       "3630                    0.128311            53.025519   \n",
       "\n",
       "      away_last5_GF_per_min_pp  away_Goalie_FenwickSV%  \\\n",
       "3626                  0.100545                0.937063   \n",
       "3627                  0.000000                0.930668   \n",
       "3628                  0.085106                0.923432   \n",
       "3629                  0.132939                0.927771   \n",
       "3630                  0.155440                0.936047   \n",
       "\n",
       "      home_last5_xGF_per_min_pp  away_Goalie_HDCSV%  away_last_5_GF%_5v5  \\\n",
       "3626                   0.184563            0.834711            51.402501   \n",
       "3627                   0.109118            0.862233            45.479328   \n",
       "3628                   0.070186            0.857809            61.850921   \n",
       "3629                   0.097037            0.852194            46.931408   \n",
       "3630                   0.090133            0.891566            51.400000   \n",
       "\n",
       "      away_Rating.A.Pre  home_Goalie_GSAx/60  \n",
       "3626            1514.01            -0.097290  \n",
       "3627            1497.57            -0.305563  \n",
       "3628            1492.13            -0.023160  \n",
       "3629            1510.30            -0.009204  \n",
       "3630            1526.11            -0.054610  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:05:53.260568Z",
     "start_time": "2021-05-09T23:05:53.221736Z"
    }
   },
   "outputs": [],
   "source": [
    "X_nn_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_nn_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_nn_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_nn_test = df[df['Season'] == '2020-2021']['Home_Team_Won']\n",
    "\n",
    "X_nn_pure_train, X_nn_val, y_nn_pure_train,  y_nn_val = train_test_split(X_nn_train, y_nn_train, random_state=2021, test_size=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:05:55.434839Z",
     "start_time": "2021-05-09T23:05:55.430118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2865,)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_nn_pure_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:05:56.894220Z",
     "start_time": "2021-05-09T23:05:56.891120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717,)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_nn_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:06:03.800420Z",
     "start_time": "2021-05-09T23:06:03.792975Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
    "       'home_last_40_GF%_5v5',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_40_SH%', \n",
    "       'home_Goalie_GSAx/60',\n",
    "        'away_Goalie_GSAx/60',\n",
    "       'away_last_5_GF%_5v5', \n",
    "       'home_last_40_xGF%_5v5', \n",
    "     'home_last5_GF_per_min_pp',\n",
    "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
    "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
    "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
    "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
    "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
    "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
    "     'away_last5_GF_per_min_pp',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
    "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
    "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
    "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
    "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "tp = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:06:05.263677Z",
     "start_time": "2021-05-09T23:06:05.234672Z"
    }
   },
   "outputs": [],
   "source": [
    "X_nn_pure_train_scaled = tp.fit_transform(X_nn_pure_train)\n",
    "X_nn_val_scaled = tp.transform(X_nn_val)\n",
    "X_nn_test_scaled = tp.transform(X_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:14:50.969349Z",
     "start_time": "2021-05-09T23:14:50.935152Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, activation='linear', input_dim=44, kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(4, activation='linear'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Game Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run some models using only the rolling 40 game team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:15:36.439416Z",
     "start_time": "2021-05-09T23:15:36.406028Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:15:37.795210Z",
     "start_time": "2021-05-09T23:15:37.792018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
       "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
       "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
       "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
       "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
       "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
       "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
       "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
       "       'home_Rating.A.Pre', 'away_Rating.A.Pre', 'B2B_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:15:44.759517Z",
     "start_time": "2021-05-09T23:15:44.755270Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features =['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
    "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
    "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
    "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
    "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
    "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
    "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
    "       'home_Rating.A.Pre', 'away_Rating.A.Pre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.004644Z",
     "start_time": "2021-05-07T22:20:04.999111Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.572777Z",
     "start_time": "2021-05-07T22:20:05.569772Z"
    }
   },
   "outputs": [],
   "source": [
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 1, 10],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv_40 = GridSearchCV(log_40_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:09.679038Z",
     "start_time": "2021-05-07T22:20:06.429450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:16.590632Z",
     "start_time": "2021-05-05T14:55:16.557290Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672521</td>\n",
       "      <td>-0.678186</td>\n",
       "      <td>-0.674674</td>\n",
       "      <td>-0.669348</td>\n",
       "      <td>-0.674081</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672520</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>-0.674673</td>\n",
       "      <td>-0.669355</td>\n",
       "      <td>-0.674082</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675375</td>\n",
       "      <td>-0.672548</td>\n",
       "      <td>-0.678078</td>\n",
       "      <td>-0.674946</td>\n",
       "      <td>-0.669716</td>\n",
       "      <td>-0.674133</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>3</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674011</td>\n",
       "      <td>-0.672891</td>\n",
       "      <td>-0.678995</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.671304</td>\n",
       "      <td>-0.674360</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>4</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674061</td>\n",
       "      <td>-0.672896</td>\n",
       "      <td>-0.679035</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.671252</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674062</td>\n",
       "      <td>-0.672900</td>\n",
       "      <td>-0.679034</td>\n",
       "      <td>-0.674562</td>\n",
       "      <td>-0.671250</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673682</td>\n",
       "      <td>-0.672968</td>\n",
       "      <td>-0.679327</td>\n",
       "      <td>-0.674495</td>\n",
       "      <td>-0.671486</td>\n",
       "      <td>-0.674391</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>7</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673574</td>\n",
       "      <td>-0.673067</td>\n",
       "      <td>-0.679649</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.672060</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>8</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.021284</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673579</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679654</td>\n",
       "      <td>-0.674596</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>9</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673578</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679656</td>\n",
       "      <td>-0.674598</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674591</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>10</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4        0.014693      0.001130         0.007716        0.000719   \n",
       "5        0.017283      0.000292         0.006951        0.000118   \n",
       "3        0.014061      0.000746         0.008523        0.001029   \n",
       "9        0.014426      0.000387         0.006950        0.000158   \n",
       "11       0.020913      0.000814         0.007221        0.000453   \n",
       "10       0.015567      0.000349         0.007100        0.000190   \n",
       "12       0.022668      0.001238         0.007185        0.000171   \n",
       "15       0.015133      0.000416         0.007112        0.000265   \n",
       "17       0.021284      0.000212         0.007193        0.000235   \n",
       "16       0.016655      0.000304         0.006913        0.000190   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "9                          0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "12                           1                                   None   \n",
       "15                           1                                   None   \n",
       "17                           1                                   None   \n",
       "16                           1                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "11                                l2                        newton-cg   \n",
       "10                                l2                            lbfgs   \n",
       "12                                l1                        liblinear   \n",
       "15                                l2                        liblinear   \n",
       "17                                l2                        newton-cg   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                  -0.675677                 -0.672521   \n",
       "5                  -0.675677                 -0.672520   \n",
       "3                  -0.675375                 -0.672548   \n",
       "9                  -0.674011                 -0.672891   \n",
       "11                 -0.674061                 -0.672896   \n",
       "10                 -0.674062                 -0.672900   \n",
       "12                 -0.673682                 -0.672968   \n",
       "15                 -0.673574                 -0.673067   \n",
       "17                 -0.673579                 -0.673068   \n",
       "16                 -0.673578                 -0.673068   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                  -0.678186                 -0.674674   \n",
       "5                  -0.678187                 -0.674673   \n",
       "3                  -0.678078                 -0.674946   \n",
       "9                  -0.678995                 -0.674600   \n",
       "11                 -0.679035                 -0.674563   \n",
       "10                 -0.679034                 -0.674562   \n",
       "12                 -0.679327                 -0.674495   \n",
       "15                 -0.679649                 -0.674600   \n",
       "17                 -0.679654                 -0.674596   \n",
       "16                 -0.679656                 -0.674598   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                  -0.669348               -0.674081               0.002986   \n",
       "5                  -0.669355               -0.674082               0.002984   \n",
       "3                  -0.669716               -0.674133               0.002821   \n",
       "9                  -0.671304               -0.674360               0.002575   \n",
       "11                 -0.671252               -0.674362               0.002600   \n",
       "10                 -0.671250               -0.674362               0.002599   \n",
       "12                 -0.671486               -0.674391               0.002659   \n",
       "15                 -0.672060               -0.674590               0.002659   \n",
       "17                 -0.672055               -0.674590               0.002661   \n",
       "16                 -0.672055               -0.674591               0.002662   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                        1              0.570667              0.593333   \n",
       "5                        2              0.570667              0.593333   \n",
       "3                        3              0.568000              0.596000   \n",
       "9                        4              0.570667              0.584000   \n",
       "11                       5              0.568000              0.582667   \n",
       "10                       6              0.568000              0.582667   \n",
       "12                       7              0.572000              0.580000   \n",
       "15                       8              0.573333              0.582667   \n",
       "17                       9              0.573333              0.582667   \n",
       "16                      10              0.573333              0.582667   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4               0.592000              0.569333              0.581333   \n",
       "5               0.592000              0.569333              0.581333   \n",
       "3               0.592000              0.573333              0.584000   \n",
       "9               0.593333              0.578667              0.576000   \n",
       "11              0.593333              0.581333              0.577333   \n",
       "10              0.593333              0.581333              0.577333   \n",
       "12              0.590667              0.577333              0.576000   \n",
       "15              0.585333              0.574667              0.572000   \n",
       "17              0.585333              0.574667              0.572000   \n",
       "16              0.585333              0.574667              0.572000   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4             0.581333           0.010154                   3  \n",
       "5             0.581333           0.010154                   3  \n",
       "3             0.582667           0.010667                   2  \n",
       "9             0.580533           0.007710                   5  \n",
       "11            0.580533           0.008202                   5  \n",
       "10            0.580533           0.008202                   5  \n",
       "12            0.579200           0.006288                   9  \n",
       "15            0.577600           0.005360                  10  \n",
       "17            0.577600           0.005360                  10  \n",
       "16            0.577600           0.005360                  10  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_results = pd.DataFrame(log_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:30.131508Z",
     "start_time": "2021-05-07T22:20:30.124084Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "ada_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [.01, .1, 1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv_40 = GridSearchCV(ada_40_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:18.508263Z",
     "start_time": "2021-05-07T22:20:30.956755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                          'home_Rating.A.Pre',\n",
       "                                                                          'away_Rating.A.Pre']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.01, 0.1, 1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.103033Z",
     "start_time": "2021-05-07T22:34:19.075177Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.925709</td>\n",
       "      <td>0.638357</td>\n",
       "      <td>2.145070</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.678507</td>\n",
       "      <td>-0.672283</td>\n",
       "      <td>-0.677155</td>\n",
       "      <td>-0.678249</td>\n",
       "      <td>-0.672888</td>\n",
       "      <td>-0.675816</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.599162</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.573707</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.680541</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-0.678631</td>\n",
       "      <td>-0.675985</td>\n",
       "      <td>-0.678217</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.575654</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.559270</td>\n",
       "      <td>0.155653</td>\n",
       "      <td>2.273125</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.681224</td>\n",
       "      <td>-0.674573</td>\n",
       "      <td>-0.677922</td>\n",
       "      <td>-0.680711</td>\n",
       "      <td>-0.676703</td>\n",
       "      <td>-0.678227</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.204704</td>\n",
       "      <td>0.113358</td>\n",
       "      <td>2.208953</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682440</td>\n",
       "      <td>-0.679579</td>\n",
       "      <td>-0.682155</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.679784</td>\n",
       "      <td>-0.681057</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.574616</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.567559</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.681519</td>\n",
       "      <td>-0.684073</td>\n",
       "      <td>-0.683125</td>\n",
       "      <td>-0.681574</td>\n",
       "      <td>-0.682894</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.579847</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.212874</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>1.813163</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688093</td>\n",
       "      <td>-0.687867</td>\n",
       "      <td>-0.688317</td>\n",
       "      <td>-0.688659</td>\n",
       "      <td>-0.686559</td>\n",
       "      <td>-0.687899</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.057093</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691571</td>\n",
       "      <td>-0.691189</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>-0.691591</td>\n",
       "      <td>-0.691297</td>\n",
       "      <td>-0.691459</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.575376</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691897</td>\n",
       "      <td>-0.691110</td>\n",
       "      <td>-0.702624</td>\n",
       "      <td>-0.690811</td>\n",
       "      <td>-0.691471</td>\n",
       "      <td>-0.693583</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>8</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      37.925709      0.638357         2.145070        0.033783   \n",
       "4       0.112370      0.003209         0.015125        0.000329   \n",
       "3      37.559270      0.155653         2.273125        0.004889   \n",
       "1      38.204704      0.113358         2.208953        0.011606   \n",
       "5       0.114122      0.000884         0.014839        0.000070   \n",
       "2      31.212874      0.111837         1.813163        0.012767   \n",
       "6       0.122421      0.057093         0.015021        0.000210   \n",
       "7       0.232039      0.006414         0.015102        0.000146   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0  SVC(kernel='linear', probability=True)                     0.01   \n",
       "4                    LogisticRegression()                     0.01   \n",
       "3  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "6                    LogisticRegression()                        1   \n",
       "7                    LogisticRegression()                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "4                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "3                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "7                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.678507                 -0.672283   \n",
       "4                 -0.680541                 -0.676259   \n",
       "3                 -0.681224                 -0.674573   \n",
       "1                 -0.682440                 -0.679579   \n",
       "5                 -0.684177                 -0.681519   \n",
       "2                 -0.688093                 -0.687867   \n",
       "6                 -0.691571                 -0.691189   \n",
       "7                 -0.691897                 -0.691110   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.677155                 -0.678249   \n",
       "4                 -0.679670                 -0.678631   \n",
       "3                 -0.677922                 -0.680711   \n",
       "1                 -0.682155                 -0.681328   \n",
       "5                 -0.684073                 -0.683125   \n",
       "2                 -0.688317                 -0.688659   \n",
       "6                 -0.691649                 -0.691591   \n",
       "7                 -0.702624                 -0.690811   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.672888               -0.675816               0.002684   \n",
       "4                 -0.675985               -0.678217               0.001817   \n",
       "3                 -0.676703               -0.678227               0.002487   \n",
       "1                 -0.679784               -0.681057               0.001183   \n",
       "5                 -0.681574               -0.682894               0.001160   \n",
       "2                 -0.686559               -0.687899               0.000719   \n",
       "6                 -0.691297               -0.691459               0.000182   \n",
       "7                 -0.691471               -0.693583               0.004535   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.550907              0.577406   \n",
       "4                       2              0.569038              0.588563   \n",
       "3                       3              0.567643              0.595537   \n",
       "1                       4              0.564854              0.574616   \n",
       "5                       5              0.560669              0.588563   \n",
       "2                       6              0.543933              0.543933   \n",
       "6                       7              0.559275              0.594142   \n",
       "7                       8              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.599162              0.561453              0.579609   \n",
       "4              0.569832              0.567039              0.583799   \n",
       "3              0.608939              0.571229              0.572626   \n",
       "1              0.564246              0.568436              0.565642   \n",
       "5              0.597765              0.569832              0.582402   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "6              0.589385              0.564246              0.569832   \n",
       "7              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.573707           0.016532                   5  \n",
       "4            0.575654           0.008774                   3  \n",
       "3            0.583195           0.016198                   1  \n",
       "1            0.567559           0.003809                   6  \n",
       "5            0.579847           0.013203                   2  \n",
       "2            0.543830           0.000517                   7  \n",
       "6            0.575376           0.013873                   4  \n",
       "7            0.543830           0.000517                   7  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_40_results = pd.DataFrame(ada_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:18:56.039191Z",
     "start_time": "2021-05-09T23:18:56.029168Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='relu', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=28, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_40_cv = GridSearchCV(estimator=nn_40_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:32:08.418829Z",
     "start_time": "2021-05-09T23:18:57.501826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd1f51841c0>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['RMSprop', 'Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:39:46.329785Z",
     "start_time": "2021-05-09T23:39:46.300871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.026956</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.313454</td>\n",
       "      <td>0.299331</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670244</td>\n",
       "      <td>-0.670506</td>\n",
       "      <td>-0.677651</td>\n",
       "      <td>-0.672800</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.594640</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.714656</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669582</td>\n",
       "      <td>-0.671819</td>\n",
       "      <td>-0.677286</td>\n",
       "      <td>-0.672896</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>2</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.602178</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.017466</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.036484</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.110218</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.669712</td>\n",
       "      <td>-0.670576</td>\n",
       "      <td>-0.678738</td>\n",
       "      <td>-0.673009</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.573702</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.004689</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669191</td>\n",
       "      <td>-0.671065</td>\n",
       "      <td>-0.678912</td>\n",
       "      <td>-0.673056</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>4</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.580681</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.841163</td>\n",
       "      <td>0.297668</td>\n",
       "      <td>0.101427</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671780</td>\n",
       "      <td>-0.669664</td>\n",
       "      <td>-0.677814</td>\n",
       "      <td>-0.673086</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>5</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.563652</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1.156157</td>\n",
       "      <td>0.303291</td>\n",
       "      <td>0.103092</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669714</td>\n",
       "      <td>-0.670462</td>\n",
       "      <td>-0.679106</td>\n",
       "      <td>-0.673094</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>6</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.580960</td>\n",
       "      <td>0.017784</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.954173</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670004</td>\n",
       "      <td>-0.671762</td>\n",
       "      <td>-0.677552</td>\n",
       "      <td>-0.673106</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>7</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.107433</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.109486</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.670246</td>\n",
       "      <td>-0.670674</td>\n",
       "      <td>-0.678426</td>\n",
       "      <td>-0.673115</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>8</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.566164</td>\n",
       "      <td>0.578169</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.733315</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669381</td>\n",
       "      <td>-0.670897</td>\n",
       "      <td>-0.679089</td>\n",
       "      <td>-0.673122</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>9</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.770164</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.313379</td>\n",
       "      <td>0.301552</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670948</td>\n",
       "      <td>-0.670709</td>\n",
       "      <td>-0.677717</td>\n",
       "      <td>-0.673125</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>10</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.554439</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "186       1.026956      0.006196         0.313454        0.299331   \n",
       "201       0.714656      0.003949         0.099995        0.000245   \n",
       "45        1.036484      0.007792         0.110218        0.000721   \n",
       "182       1.004689      0.007679         0.100871        0.001236   \n",
       "130       0.841163      0.297668         0.101427        0.001652   \n",
       "228       1.156157      0.303291         0.103092        0.001277   \n",
       "178       0.954173      0.001785         0.100213        0.001110   \n",
       "123       1.107433      0.005035         0.109486        0.000659   \n",
       "155       0.733315      0.002264         0.100377        0.000298   \n",
       "144       0.770164      0.000856         0.313379        0.301552   \n",
       "\n",
       "    param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "186               linear                    0.3               18   \n",
       "201               linear                    0.6                8   \n",
       "45          hard_sigmoid                    0.3               15   \n",
       "182               linear                    0.3               18   \n",
       "130               linear                    0.3                8   \n",
       "228               linear                    0.6               15   \n",
       "178               linear                    0.3               18   \n",
       "123         hard_sigmoid                    0.6               18   \n",
       "155               linear                    0.3               10   \n",
       "144               linear                    0.3               10   \n",
       "\n",
       "    param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "186                36                Adam                           1   \n",
       "201                36             RMSprop                           3   \n",
       "45                 40             RMSprop                           3   \n",
       "182                24                Adam                           1   \n",
       "130                12                Adam                           1   \n",
       "228                24             RMSprop                           1   \n",
       "178                12                Adam                           1   \n",
       "123                36                Adam                           3   \n",
       "155                36                Adam                           3   \n",
       "144                12             RMSprop                           1   \n",
       "\n",
       "                                                params  \\\n",
       "186  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "201  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "45   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "182  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "130  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "228  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "178  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "123  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "155  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "144  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "\n",
       "     split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "186                 -0.670244                 -0.670506   \n",
       "201                 -0.669582                 -0.671819   \n",
       "45                  -0.669712                 -0.670576   \n",
       "182                 -0.669191                 -0.671065   \n",
       "130                 -0.671780                 -0.669664   \n",
       "228                 -0.669714                 -0.670462   \n",
       "178                 -0.670004                 -0.671762   \n",
       "123                 -0.670246                 -0.670674   \n",
       "155                 -0.669381                 -0.670897   \n",
       "144                 -0.670948                 -0.670709   \n",
       "\n",
       "     split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "186                 -0.677651               -0.672800               0.003431   \n",
       "201                 -0.677286               -0.672896               0.003236   \n",
       "45                  -0.678738               -0.673009               0.004066   \n",
       "182                 -0.678912               -0.673056               0.004211   \n",
       "130                 -0.677814               -0.673086               0.003453   \n",
       "228                 -0.679106               -0.673094               0.004262   \n",
       "178                 -0.677552               -0.673106               0.003225   \n",
       "123                 -0.678426               -0.673115               0.003759   \n",
       "155                 -0.679089               -0.673122               0.004264   \n",
       "144                 -0.677717               -0.673125               0.003249   \n",
       "\n",
       "     rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "186                       1              0.585427              0.594640   \n",
       "201                       2              0.582915              0.602178   \n",
       "45                        3              0.574539              0.595477   \n",
       "182                       4              0.585427              0.592127   \n",
       "130                       5              0.576214              0.583752   \n",
       "228                       6              0.580402              0.603015   \n",
       "178                       7              0.582077              0.595477   \n",
       "123                       8              0.572864              0.595477   \n",
       "155                       9              0.592127              0.592127   \n",
       "144                      10              0.586265              0.597152   \n",
       "\n",
       "     split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "186              0.564489            0.581519           0.012615   \n",
       "201              0.559464            0.581519           0.017466   \n",
       "45               0.573702            0.581240           0.010073   \n",
       "182              0.564489            0.580681           0.011772   \n",
       "130              0.563652            0.574539           0.008291   \n",
       "228              0.559464            0.580960           0.017784   \n",
       "178              0.567839            0.581798           0.011285   \n",
       "123              0.566164            0.578169           0.012541   \n",
       "155              0.564489            0.582915           0.013029   \n",
       "144              0.554439            0.579285           0.018123   \n",
       "\n",
       "     rank_test_accuracy  \n",
       "186                  66  \n",
       "201                  66  \n",
       "45                   79  \n",
       "182                  91  \n",
       "130                 220  \n",
       "228                  84  \n",
       "178                  61  \n",
       "123                 142  \n",
       "155                  37  \n",
       "144                 120  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_results = pd.DataFrame(nn_40_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Rolling Game Features With Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.696296Z",
     "start_time": "2021-05-07T22:34:19.667544Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:42:10.436891Z",
     "start_time": "2021-05-05T23:42:10.432366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 104)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:20.363708Z",
     "start_time": "2021-05-07T22:34:20.359232Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "rfecv = RFECV(estimator= LogisticRegression(max_iter =10000, penalty = 'l2', solver='liblinear', C=.1), step=1, scoring='accuracy')\n",
    "rfecv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:21.913288Z",
     "start_time": "2021-05-07T22:34:21.029546Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_last_40_FF%_5v5',\n",
       "                                                   'home_last_40_GF%_5v5',\n",
       "                                                   'home_last_40_xGF%_5v5',\n",
       "                                                   'home_last_40_SH%',\n",
       "                                                   'home_last40_xGF_per_min_pp',\n",
       "                                                   'home_last40_GF_per_min_pp',\n",
       "                                                   'home_last40_xGA_per_min_pk',\n",
       "                                                   'home_last40_GA_per_min_pk',\n",
       "                                                   'away_last_40_FF%_5v5',\n",
       "                                                   'away_...\n",
       "                                                   'home_Goalie_FenwickSV%',\n",
       "                                                   'home_Goalie_GSAx/60',\n",
       "                                                   'home_Goalie_HDCSV%',\n",
       "                                                   'away_Goalie_FenwickSV%',\n",
       "                                                   'away_Goalie_GSAx/60',\n",
       "                                                   'away_Goalie_HDCSV%',\n",
       "                                                   'home_Rating.A.Pre',\n",
       "                                                   'away_Rating.A.Pre']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['B2B_Status'])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(estimator=LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:22.591913Z",
     "start_time": "2021-05-07T22:34:22.588917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:23.322200Z",
     "start_time": "2021-05-07T22:34:23.318966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 13,  8, 18, 14,  9,  6,  2, 20, 17,  7, 10, 12, 16, 15,  1,\n",
       "        1,  5, 19, 11,  4,  1,  1,  1,  1,  1,  3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.000125Z",
     "start_time": "2021-05-07T22:34:23.992070Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last3_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>home_last_20_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_last_30_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_Rating.A.Pre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_10_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last10_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_last40_GF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  Ranking\n",
       "0    home_last3_xGF_per_min_pp        1\n",
       "1       home_Goalie_FenwickSV%        1\n",
       "25        home_last_20_GF%_5v5        1\n",
       "24        away_last_30_GF%_5v5        1\n",
       "23           away_Rating.A.Pre        1\n",
       "22        home_last_10_FF%_5v5        1\n",
       "17  away_last10_xGF_per_min_pp        1\n",
       "16       home_last_40_xGF%_5v5        1\n",
       "26   away_last40_GF_per_min_pp        1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_results = pd.DataFrame(list(zip(X_train.columns, rfecv_pipeline[1].ranking_)), columns = ['Feature', 'Ranking']).sort_values('Ranking')\n",
    "rfecv_results.head(rfecv_pipeline[1].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.669318Z",
     "start_time": "2021-05-07T22:34:24.665437Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_last3_xGF_per_min_pp',\n",
       " 'home_Goalie_FenwickSV%',\n",
       " 'home_last_20_GF%_5v5',\n",
       " 'away_last_30_GF%_5v5',\n",
       " 'away_Rating.A.Pre',\n",
       " 'home_last_10_FF%_5v5',\n",
       " 'away_last10_xGF_per_min_pp',\n",
       " 'home_last_40_xGF%_5v5',\n",
       " 'away_last40_GF_per_min_pp']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = list(rfecv_results.iloc[:rfecv_pipeline[1].n_features_,0])\n",
    "rfecv_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.349708Z",
     "start_time": "2021-05-07T22:34:25.324672Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.925726Z",
     "start_time": "2021-05-07T22:34:25.921927Z"
    }
   },
   "outputs": [],
   "source": [
    "log_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None]}\n",
    "\n",
    "log_cv_all = GridSearchCV(log_rfecv_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:27.929642Z",
     "start_time": "2021-05-07T22:34:26.511858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_all.fit(X_train[rfecv_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:28.552604Z",
     "start_time": "2021-05-07T22:34:28.528948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.676186</td>\n",
       "      <td>-0.674550</td>\n",
       "      <td>-0.672781</td>\n",
       "      <td>-0.673968</td>\n",
       "      <td>-0.676196</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.575661</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682996</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>3</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682877</td>\n",
       "      <td>-0.675304</td>\n",
       "      <td>-0.675674</td>\n",
       "      <td>-0.674005</td>\n",
       "      <td>-0.673641</td>\n",
       "      <td>-0.676300</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.576497</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676038</td>\n",
       "      <td>-0.675903</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673425</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>5</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676037</td>\n",
       "      <td>-0.675902</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673426</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684022</td>\n",
       "      <td>-0.676034</td>\n",
       "      <td>-0.675904</td>\n",
       "      <td>-0.673109</td>\n",
       "      <td>-0.673453</td>\n",
       "      <td>-0.676504</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>7</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684239</td>\n",
       "      <td>-0.676227</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>-0.672984</td>\n",
       "      <td>-0.673468</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>8</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577057</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 20, 'logisticregress...</td>\n",
       "      <td>-0.684245</td>\n",
       "      <td>-0.676233</td>\n",
       "      <td>-0.675967</td>\n",
       "      <td>-0.672985</td>\n",
       "      <td>-0.673465</td>\n",
       "      <td>-0.676579</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>9</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576778</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684249</td>\n",
       "      <td>-0.676236</td>\n",
       "      <td>-0.675975</td>\n",
       "      <td>-0.672987</td>\n",
       "      <td>-0.673460</td>\n",
       "      <td>-0.676582</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>10</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        0.006220      0.000130         0.003461        0.000075   \n",
       "4        0.007108      0.000076         0.003425        0.000014   \n",
       "5        0.013248      0.001218         0.004097        0.000478   \n",
       "3        0.005481      0.000175         0.003253        0.000013   \n",
       "10       0.007337      0.000301         0.003419        0.000033   \n",
       "11       0.011399      0.000528         0.003445        0.000016   \n",
       "9        0.005766      0.000048         0.003394        0.000016   \n",
       "12       0.006644      0.000130         0.003406        0.000029   \n",
       "18       0.006527      0.000311         0.003445        0.000019   \n",
       "16       0.007279      0.000221         0.003613        0.000365   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "6                          0.1                                   None   \n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "12                          10                                   None   \n",
       "18                          20                                   None   \n",
       "16                          10                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "6                                 l1                        liblinear   \n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "9                                 l2                        liblinear   \n",
       "12                                l1                        liblinear   \n",
       "18                                l1                        liblinear   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 20, 'logisticregress...   \n",
       "16  {'logisticregression__C': 10, 'logisticregress...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.683493                 -0.676186   \n",
       "4                  -0.682996                 -0.675241   \n",
       "5                  -0.682997                 -0.675241   \n",
       "3                  -0.682877                 -0.675304   \n",
       "10                 -0.684044                 -0.676038   \n",
       "11                 -0.684044                 -0.676037   \n",
       "9                  -0.684022                 -0.676034   \n",
       "12                 -0.684239                 -0.676227   \n",
       "18                 -0.684245                 -0.676233   \n",
       "16                 -0.684249                 -0.676236   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.674550                 -0.672781   \n",
       "4                  -0.675597                 -0.673949   \n",
       "5                  -0.675597                 -0.673949   \n",
       "3                  -0.675674                 -0.674005   \n",
       "10                 -0.675903                 -0.673108   \n",
       "11                 -0.675902                 -0.673108   \n",
       "9                  -0.675904                 -0.673109   \n",
       "12                 -0.675958                 -0.672984   \n",
       "18                 -0.675967                 -0.672985   \n",
       "16                 -0.675975                 -0.672987   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.673968               -0.676196               0.003810   \n",
       "4                  -0.673375               -0.676232               0.003479   \n",
       "5                  -0.673375               -0.676232               0.003479   \n",
       "3                  -0.673641               -0.676300               0.003376   \n",
       "10                 -0.673425               -0.676503               0.003961   \n",
       "11                 -0.673426               -0.676503               0.003961   \n",
       "9                  -0.673453               -0.676504               0.003948   \n",
       "12                 -0.673468               -0.676575               0.004045   \n",
       "18                 -0.673465               -0.676579               0.004046   \n",
       "16                 -0.673460               -0.676582               0.004048   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.550907              0.581590   \n",
       "4                        2              0.546722              0.585774   \n",
       "5                        3              0.546722              0.585774   \n",
       "3                        4              0.555091              0.584379   \n",
       "10                       5              0.549512              0.585774   \n",
       "11                       6              0.549512              0.585774   \n",
       "9                        7              0.546722              0.585774   \n",
       "12                       8              0.549512              0.585774   \n",
       "18                       9              0.548117              0.585774   \n",
       "16                      10              0.548117              0.584379   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.594972              0.574022              0.576816   \n",
       "4               0.596369              0.565642              0.581006   \n",
       "5               0.596369              0.565642              0.581006   \n",
       "3               0.587989              0.575419              0.579609   \n",
       "10              0.592179              0.578212              0.581006   \n",
       "11              0.592179              0.578212              0.581006   \n",
       "9               0.589385              0.579609              0.581006   \n",
       "12              0.589385              0.579609              0.581006   \n",
       "18              0.590782              0.578212              0.581006   \n",
       "16              0.590782              0.578212              0.581006   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.575661           0.014317                  17  \n",
       "4             0.575103           0.017297                  18  \n",
       "5             0.575103           0.017297                  18  \n",
       "3             0.576497           0.011518                  16  \n",
       "10            0.577337           0.014696                   1  \n",
       "11            0.577337           0.014696                   1  \n",
       "9             0.576499           0.015289                   5  \n",
       "12            0.577057           0.014204                   3  \n",
       "18            0.576778           0.014956                   4  \n",
       "16            0.576499           0.014798                   5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_all_results = pd.DataFrame(log_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.189755Z",
     "start_time": "2021-05-07T22:34:29.164773Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.784811Z",
     "start_time": "2021-05-07T22:34:29.780602Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [ .1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression(max_iter =10000, C=.01, penalty = 'l1', solver = 'liblinear')],}\n",
    "\n",
    "ada_cv_all = GridSearchCV(ada_rfecv_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:10.420059Z",
     "start_time": "2021-05-07T22:34:30.382762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression(C=0.01,\n",
       "                                                                    max_iter=10000,\n",
       "                                                                    penalty='l1',\n",
       "                                                                    solver='liblinear')],\n",
       "                         'ada__learning_rate': [0.1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:11.046731Z",
     "start_time": "2021-05-07T22:41:11.023674Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.347400</td>\n",
       "      <td>0.550717</td>\n",
       "      <td>2.137133</td>\n",
       "      <td>0.103863</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683982</td>\n",
       "      <td>-0.678475</td>\n",
       "      <td>-0.679754</td>\n",
       "      <td>-0.682702</td>\n",
       "      <td>-0.681416</td>\n",
       "      <td>-0.681266</td>\n",
       "      <td>1.976734e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.567836</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.946891</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>2.113290</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684418</td>\n",
       "      <td>-0.682521</td>\n",
       "      <td>-0.682660</td>\n",
       "      <td>-0.681958</td>\n",
       "      <td>-0.682048</td>\n",
       "      <td>-0.682721</td>\n",
       "      <td>8.898324e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.560581</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      32.347400      0.550717         2.137133        0.103863   \n",
       "0      32.946891      0.287765         2.113290        0.028486   \n",
       "2       0.055528      0.000309         0.010574        0.000029   \n",
       "3       0.055622      0.000853         0.010454        0.000019   \n",
       "\n",
       "                           param_ada__base_estimator param_ada__learning_rate  \\\n",
       "1             SVC(kernel='linear', probability=True)                       10   \n",
       "0             SVC(kernel='linear', probability=True)                      0.1   \n",
       "2  LogisticRegression(C=0.01, max_iter=10000, pen...                      0.1   \n",
       "3  LogisticRegression(C=0.01, max_iter=10000, pen...                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "2                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "3                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1                 -0.683982                 -0.678475   \n",
       "0                 -0.684418                 -0.682521   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "1                 -0.679754                 -0.682702   \n",
       "0                 -0.682660                 -0.681958   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1                 -0.681416               -0.681266           1.976734e-03   \n",
       "0                 -0.682048               -0.682721           8.898324e-04   \n",
       "2                 -0.693147               -0.693147           8.599751e-17   \n",
       "3                 -0.693147               -0.693147           8.599751e-17   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1                       1              0.556485              0.591353   \n",
       "0                       2              0.553696              0.564854   \n",
       "2                       3              0.456067              0.456067   \n",
       "3                       3              0.456067              0.456067   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "1              0.574022              0.561453              0.555866   \n",
       "0              0.571229              0.553073              0.560056   \n",
       "2              0.456704              0.456704              0.455307   \n",
       "3              0.456704              0.456704              0.455307   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "1            0.567836           0.013448                   1  \n",
       "0            0.560581           0.006866                   2  \n",
       "2            0.456170           0.000517                   3  \n",
       "3            0.456170           0.000517                   3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_all_results = pd.DataFrame(ada_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:48:40.610937Z",
     "start_time": "2021-05-09T23:48:40.579642Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:54:06.096617Z",
     "start_time": "2021-05-09T23:54:06.092448Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = list(X_train.columns)\n",
    "numeric_features.remove('B2B_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:52:51.092376Z",
     "start_time": "2021-05-09T23:52:51.087263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 105)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:54:57.385729Z",
     "start_time": "2021-05-09T23:54:57.374793Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='relu', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=108, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['Adam'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_all_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_all_cv = GridSearchCV(estimator=nn_all_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:01:32.847696Z",
     "start_time": "2021-05-09T23:54:59.140040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last3_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_FenwickSV%',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last30_xGA_per_min_pk',\n",
       "                                                                          'away_last5_xGF_per_min_pp',\n",
       "                                                                          'home_last20_GA_per_min_pk',\n",
       "                                                                          'away_last10_xGA_per_min_pk',\n",
       "                                                                          'home_las...\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd1dfe35160>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:33.662619Z",
     "start_time": "2021-05-10T00:20:33.638957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.794308</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.112324</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.674352</td>\n",
       "      <td>-0.673008</td>\n",
       "      <td>-0.681466</td>\n",
       "      <td>-0.676276</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.551926</td>\n",
       "      <td>0.577052</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729534</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>0.111911</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.674617</td>\n",
       "      <td>-0.672954</td>\n",
       "      <td>-0.683073</td>\n",
       "      <td>-0.676882</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>2</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.603853</td>\n",
       "      <td>0.544389</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.101628</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.112252</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.675368</td>\n",
       "      <td>-0.673330</td>\n",
       "      <td>-0.682021</td>\n",
       "      <td>-0.676906</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.575377</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.253149</td>\n",
       "      <td>0.113350</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.674908</td>\n",
       "      <td>-0.673728</td>\n",
       "      <td>-0.682318</td>\n",
       "      <td>-0.676985</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>4</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.541876</td>\n",
       "      <td>0.573423</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.991799</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.113802</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.675537</td>\n",
       "      <td>-0.672514</td>\n",
       "      <td>-0.683368</td>\n",
       "      <td>-0.677140</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>5</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.594640</td>\n",
       "      <td>0.552764</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "43       0.794308      0.002446         0.112324        0.000971   \n",
       "4        0.729534      0.005631         0.111911        0.000338   \n",
       "56       1.101628      0.005594         0.112252        0.000862   \n",
       "3        0.905045      0.253149         0.113350        0.000761   \n",
       "50       0.991799      0.002320         0.113802        0.003088   \n",
       "\n",
       "   param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "43         hard_sigmoid                    0.6               10   \n",
       "4          hard_sigmoid                    0.3                8   \n",
       "56         hard_sigmoid                    0.6               18   \n",
       "3          hard_sigmoid                    0.3                8   \n",
       "50         hard_sigmoid                    0.6               15   \n",
       "\n",
       "   param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "43                24                Adam                           3   \n",
       "4                 36                Adam                           1   \n",
       "56                12                Adam                           1   \n",
       "3                 24                Adam                           3   \n",
       "50                24                Adam                           1   \n",
       "\n",
       "                                               params  \\\n",
       "43  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "4   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "56  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "3   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "50  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "43                 -0.674352                 -0.673008   \n",
       "4                  -0.674617                 -0.672954   \n",
       "56                 -0.675368                 -0.673330   \n",
       "3                  -0.674908                 -0.673728   \n",
       "50                 -0.675537                 -0.672514   \n",
       "\n",
       "    split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "43                 -0.681466               -0.676276               0.003711   \n",
       "4                  -0.683073               -0.676882               0.004430   \n",
       "56                 -0.682021               -0.676906               0.003711   \n",
       "3                  -0.682318               -0.676985               0.003802   \n",
       "50                 -0.683368               -0.677140               0.004574   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "43                       1              0.577889              0.601340   \n",
       "4                        2              0.583752              0.603853   \n",
       "56                       3              0.576214              0.601340   \n",
       "3                        4              0.582077              0.596315   \n",
       "50                       5              0.577889              0.594640   \n",
       "\n",
       "    split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "43              0.551926            0.577052           0.020182   \n",
       "4               0.544389            0.577331           0.024697   \n",
       "56              0.548576            0.575377           0.021549   \n",
       "3               0.541876            0.573423           0.023052   \n",
       "50              0.552764            0.575098           0.017209   \n",
       "\n",
       "    rank_test_accuracy  \n",
       "43                  27  \n",
       "4                   24  \n",
       "56                  44  \n",
       "3                   56  \n",
       "50                  47  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_results = pd.DataFrame(nn_all_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_all_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Models To Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will evaluate the best model iterations on the held out 2021 season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:50.112107Z",
     "start_time": "2021-05-10T00:20:50.108036Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {'cv accuracy': {}, 'cv log loss': {}, 'test accuracy': {}, 'test log_loss':{}}\n",
    "accuracy_list = []\n",
    "log_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:51.960795Z",
     "start_time": "2021-05-10T00:20:51.907781Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 41 features, but ColumnTransformer is expecting 49 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-1a3c1309b502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_preds_5_40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_probs_5_40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         if (self._feature_names_in is not None and\n\u001b[1;32m    559\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 41 features, but ColumnTransformer is expecting 49 features as input."
     ]
    }
   ],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_5_40 = log_cv.predict(X_test)\n",
    "\n",
    "test_probs_5_40 = log_cv.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_5_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_5_40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:51.966592Z",
     "start_time": "2021-05-10T00:20:51.261Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_40 = log_cv_40.predict(X_test)\n",
    "\n",
    "test_probs_40 = log_cv_40.predict_proba(X_test)\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:51.970472Z",
     "start_time": "2021-05-10T00:20:51.757Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "test_preds_rfecv = log_cv_all.predict(X_test)\n",
    "\n",
    "test_probs_rfecv = log_cv_all.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_rfecv))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_rfecv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T00:20:52.292481Z",
     "start_time": "2021-05-10T00:20:52.243433Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 41 features, but ColumnTransformer is expecting 49 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-e73dcaad4f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mada_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlog_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mada_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         if (self._feature_names_in is not None and\n\u001b[1;32m    559\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 41 features, but ColumnTransformer is expecting 49 features as input."
     ]
    }
   ],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test,ada_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:13:17.614125Z",
     "start_time": "2021-05-05T23:13:14.601780Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv_40.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, ada_cv_40.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_40_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_40_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_40_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_40_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:38.360192Z",
     "start_time": "2021-05-06T02:12:38.340495Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict['test accuracy'] = accuracy_list\n",
    "results_dict['test log_loss'] = log_loss_list\n",
    "models = ['5 and 40 Logistic Regression', \n",
    "          '40 Logistic Regression', \n",
    "          'rfecv Logistic Regression', \n",
    "          '5 and 40 AdaBoost', \n",
    "          '40 AdaBoost', \n",
    "          '5 and 40 Neural Network', \n",
    "          '40 Neural Network', \n",
    "          'All Neural Network']\n",
    "results_dict['cv accuracy'] = [log_results['mean_test_accuracy'][0], \n",
    "                               log_40_results['mean_test_accuracy'][0], \n",
    "                               log_all_results['mean_test_accuracy'][0], \n",
    "                               ada_results['mean_test_accuracy'][0], \n",
    "                               ada_40_results['mean_test_accuracy'][0], \n",
    "                               nn_results['mean_test_accuracy'][0],\n",
    "                              nn_40_results['mean_test_accuracy'][0],\n",
    "                              nn_all_results['mean_test_accuracy'][0]]\n",
    "results_dict['cv log loss'] = [log_cv.best_score_*-1, \n",
    "                               log_cv_40.best_score_*-1, \n",
    "                               log_cv_all.best_score_*-1, \n",
    "                               ada_cv.best_score_*-1, \n",
    "                               ada_cv_40.best_score_*-1, \n",
    "                               nn_cv.best_score_*-1, \n",
    "                               nn_40_cv.best_score_*-1, \n",
    "                               nn_all_cv.best_score_*-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:40.320625Z",
     "start_time": "2021-05-06T02:12:40.316596Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, index = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model was logistic regression with the rolling 5 and 40 features on the test data. Interestingly, this was the 4th best model on the CV training data set though it did have the best CV accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:41.708494Z",
     "start_time": "2021-05-06T02:12:41.698849Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv accuracy</th>\n",
       "      <th>cv log loss</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>test log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5 and 40 log</th>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.677735</td>\n",
       "      <td>0.597205</td>\n",
       "      <td>0.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 log</th>\n",
       "      <td>0.580267</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0.593393</td>\n",
       "      <td>0.657240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 ada</th>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>0.606099</td>\n",
       "      <td>0.660695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv log</th>\n",
       "      <td>0.571733</td>\n",
       "      <td>0.675783</td>\n",
       "      <td>0.590851</td>\n",
       "      <td>0.665077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 ada</th>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.681288</td>\n",
       "      <td>0.560356</td>\n",
       "      <td>0.678121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cv accuracy  cv log loss  test accuracy  test log_loss\n",
       "5 and 40 log     0.581067     0.677735       0.597205       0.657201\n",
       "40 log           0.580267     0.674081       0.593393       0.657240\n",
       "40 ada           0.579467     0.675472       0.606099       0.660695\n",
       "rfecv log        0.571733     0.675783       0.590851       0.665077\n",
       "5 and 40 ada     0.562667     0.681288       0.560356       0.678121"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('test log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To further improve the models I would like to take the following next steps\n",
    "\n",
    "- Train a neural network model\n",
    "- Categorize B2B better\n",
    "- Include team ELO feature\n",
    "- Try linear weightings in rolling features\n",
    "- Increase goalie games\n",
    "- Add prior year goalie GAR feature\n",
    "- Add Team HDSC % feature\n",
    "- Add more seasons to training set\n",
    "- Compare against historical implied odds from a bookmaker\n",
    "- Adjust ineperienced goalie imputed stats and exclude 2021 season to avoid data leakage on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
