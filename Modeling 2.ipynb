{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Game Prediction Modeling\n",
    "by Gary Schwaeber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sport betting becoming increasingly popular and mainstream I believe that data science can be used to make superior decisions over gut intuitions. In this notebook I will attempt to train logistic regression, ada boost, and gradient boosting models in an attempt to make the best possible game prediction model. I will train my models and tune model hyperparemetres using game results from seasons '2017-2018', '2018-2019', '2019-2020'. Then I will predict on held out games from the current 2021 season and evaluate my model. There are currently a handful of public models whose log loss on the current season's games is being [tracked](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/) on which I can compare the quality of my model to. The score I will look to optimize is log loss, however, I will also review accuracy scores due to their interpretability.\n",
    "\n",
    "Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value (0 or 1 in case of binary classification). The more the predicted probability diverges from the actual value, the higher is the log-loss value. [Source](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:44:02.803721Z",
     "start_time": "2021-05-07T21:43:51.561923Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import hockey_scraper\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#for the Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:48:44.859949Z",
     "start_time": "2021-05-07T19:48:44.723497Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_games_multirolling_SVA_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:02.802611Z",
     "start_time": "2021-05-07T19:49:02.798659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4447, 155)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:59:36.967400Z",
     "start_time": "2021-05-07T19:59:36.957271Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature columns for different rolling intervals\n",
    "\n",
    "common = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', \n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']\n",
    "\n",
    "r3 = ['home_last_3_FF%_5v5',\n",
    " 'home_last_3_GF%_5v5',\n",
    " 'home_last_3_xGF%_5v5',\n",
    " 'home_last_3_SH%',\n",
    " 'home_last3_xGF_per_min_pp',\n",
    " 'home_last3_GF_per_min_pp',\n",
    " 'home_last3_xGA_per_min_pk',\n",
    " 'home_last3_GA_per_min_pk',\n",
    " 'away_last_3_FF%_5v5',\n",
    " 'away_last_3_GF%_5v5',\n",
    " 'away_last_3_xGF%_5v5',\n",
    " 'away_last_3_SH%',\n",
    " 'away_last3_xGF_per_min_pp',\n",
    " 'away_last3_GF_per_min_pp',\n",
    " 'away_last3_xGA_per_min_pk',\n",
    " 'away_last3_GA_per_min_pk'] + common\n",
    "\n",
    "r5 =['home_last_5_FF%_5v5',\n",
    " 'home_last_5_GF%_5v5',\n",
    " 'home_last_5_xGF%_5v5',\n",
    " 'home_last_5_SH%',\n",
    "\n",
    " 'home_last5_xGF_per_min_pp',\n",
    " 'home_last5_GF_per_min_pp',\n",
    "\n",
    " 'home_last5_xGA_per_min_pk',\n",
    " 'home_last5_GA_per_min_pk',\n",
    " 'away_last_5_FF%_5v5',\n",
    " 'away_last_5_GF%_5v5',\n",
    " 'away_last_5_xGF%_5v5',\n",
    " 'away_last_5_SH%',\n",
    " 'away_last5_xGF_per_min_pp',\n",
    " 'away_last5_GF_per_min_pp',\n",
    " 'away_last5_xGA_per_min_pk',\n",
    " 'away_last5_GA_per_min_pk'] + common\n",
    "\n",
    "r10 =['home_last_10_FF%_5v5',\n",
    " 'home_last_10_GF%_5v5',\n",
    " 'home_last_10_xGF%_5v5',\n",
    " 'home_last_10_SH%',\n",
    " 'home_last10_xGF_per_min_pp',\n",
    " 'home_last10_GF_per_min_pp',\n",
    " 'home_last10_xGA_per_min_pk',\n",
    " 'home_last10_GA_per_min_pk',\n",
    "  'away_last_10_FF%_5v5',\n",
    " 'away_last_10_GF%_5v5',\n",
    " 'away_last_10_xGF%_5v5',\n",
    " 'away_last_10_SH%',\n",
    " 'away_last10_xGF_per_min_pp',\n",
    " 'away_last10_GF_per_min_pp',\n",
    " 'away_last10_xGA_per_min_pk',\n",
    " 'away_last10_GA_per_min_pk',]\n",
    "\n",
    "\n",
    "r20 = ['home_last_20_FF%_5v5',\n",
    " 'home_last_20_GF%_5v5',\n",
    " 'home_last_20_xGF%_5v5',\n",
    " 'home_last_20_SH%',\n",
    "\n",
    " 'home_last20_xGF_per_min_pp',\n",
    " 'home_last20_GF_per_min_pp',\n",
    "\n",
    " 'home_last20_xGA_per_min_pk',\n",
    " 'home_last20_GA_per_min_pk',\n",
    " 'away_last_20_FF%_5v5',\n",
    " 'away_last_20_GF%_5v5',\n",
    " 'away_last_20_xGF%_5v5',\n",
    " 'away_last_20_SH%',\n",
    "\n",
    " 'away_last20_xGF_per_min_pp',\n",
    " 'away_last20_GF_per_min_pp',\n",
    "\n",
    " 'away_last20_xGA_per_min_pk',\n",
    " 'away_last20_GA_per_min_pk']\n",
    "\n",
    "r30 = ['home_last_30_FF%_5v5',\n",
    " 'home_last_30_GF%_5v5',\n",
    " 'home_last_30_xGF%_5v5',\n",
    " 'home_last_30_SH%',\n",
    " 'home_last30_xGF_per_min_pp',\n",
    " 'home_last30_GF_per_min_pp',\n",
    " 'home_last30_xGA_per_min_pk',\n",
    " 'home_last30_GA_per_min_pk',\n",
    " 'away_last_30_FF%_5v5',\n",
    " 'away_last_30_GF%_5v5',\n",
    " 'away_last_30_xGF%_5v5',\n",
    " 'away_last_30_SH%',\n",
    " 'away_last30_xGF_per_min_pp',\n",
    " 'away_last30_GF_per_min_pp',\n",
    " 'away_last30_xGA_per_min_pk',\n",
    " 'away_last30_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "r40 = ['home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk',\n",
    " 'away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "all_r = list(set(r3+r5+r10+r20+r30+r40))\n",
    "\n",
    "r3_30 =list(set(r3+r30))\n",
    "r5_30 = list(set(r5+r30))\n",
    "r10_30 = list(set(r10+r30))\n",
    "r_3_5_30 = list(set(r3+r5+r30))\n",
    "r_5_20 = list(set(r5+r20))\n",
    "r_5_40 = list(set(r5+r40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model will predict that every home team wins their game and that the probability of that is the ratio of games the home team has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:09.214501Z",
     "start_time": "2021-05-07T19:49:09.014908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.541714\n",
       "0    0.458286\n",
       "Name: Home_Team_Won, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Home_Team_Won'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:10.476331Z",
     "start_time": "2021-05-07T19:49:10.468915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417135147290308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = np.ones(df.shape[0])\n",
    "accuracy_score(df['Home_Team_Won'],baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:11.547357Z",
     "start_time": "2021-05-07T19:49:11.536477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896630977766495"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_probs = np.repeat(df['Home_Team_Won'].value_counts(normalize=True)[1], df.shape[0])\n",
    "\n",
    "log_loss(df['Home_Team_Won'], baseline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need to beat an accuracy score of 54.17% and a log loss of .6897, otherwise they are no better than just predicting the home team will win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling 5 and 40 game features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first set of models I will attempt using 5 and 40 game rolling features. These seemed like a good set based on the feature selection notebook. 40 games is currently the longest rolling runway I have currently for the team statistics. The 40 games stats intuitively provide the most smoothing of team data over the course of the season, while the 5 game stats may provide some insight on any streakiness or may cover recent developments that would affect short term team performances such as player injuries, trades coaching changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:34.732475Z",
     "start_time": "2021-05-07T19:49:34.697858Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T15:37:01.054519Z",
     "start_time": "2021-05-07T15:37:01.049641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
       "       'home_last5_pp_TOI_per_game', 'home_last_40_GF%_5v5',\n",
       "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
       "       'home_last_40_SH%', 'home_last5_pk_TOI_per_game',\n",
       "       'away_last40_pp_TOI_per_game', 'home_Goalie_GSAx/60',\n",
       "       'away_last40_pk_TOI_per_game', 'away_Goalie_GSAx/60',\n",
       "       'away_last_5_GF%_5v5', 'home_last40_pk_TOI_per_game', 'B2B_Status',\n",
       "       'home_last_40_xGF%_5v5', 'away_last5_pp_TOI_per_game',\n",
       "       'away_last5_pk_TOI_per_game', 'home_last5_GF_per_min_pp',\n",
       "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
       "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
       "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
       "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
       "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
       "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
       "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
       "       'home_last40_pp_TOI_per_game', 'away_last5_GF_per_min_pp',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
       "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
       "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
       "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
       "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
       "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:38.914528Z",
     "start_time": "2021-05-07T19:49:38.909752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 49)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:55:44.747167Z",
     "start_time": "2021-05-07T19:55:44.741690Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
    "       'home_last_40_GF%_5v5',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_40_SH%', \n",
    "       'home_Goalie_GSAx/60',\n",
    "        'away_Goalie_GSAx/60',\n",
    "       'away_last_5_GF%_5v5', \n",
    "       'home_last_40_xGF%_5v5', \n",
    "     'home_last5_GF_per_min_pp',\n",
    "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
    "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
    "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
    "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
    "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
    "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
    "     'away_last5_GF_per_min_pp',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
    "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
    "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
    "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
    "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:50:17.173759Z",
     "start_time": "2021-05-07T19:50:17.139897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>home_last5_pp_TOI_per_game</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_last5_pk_TOI_per_game</th>\n",
       "      <th>away_last40_pp_TOI_per_game</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>away_last40_pk_TOI_per_game</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>home_last40_pk_TOI_per_game</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>away_last5_pp_TOI_per_game</th>\n",
       "      <th>away_last5_pk_TOI_per_game</th>\n",
       "      <th>home_last5_GF_per_min_pp</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_last5_GA_per_min_pk</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GA_per_min_pk</th>\n",
       "      <th>home_last40_pp_TOI_per_game</th>\n",
       "      <th>away_last5_GF_per_min_pp</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112699</td>\n",
       "      <td>48.770492</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>50.127801</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>9.025236</td>\n",
       "      <td>3.693333</td>\n",
       "      <td>4.646667</td>\n",
       "      <td>-0.202922</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>0.082345</td>\n",
       "      <td>45.937500</td>\n",
       "      <td>4.923333</td>\n",
       "      <td>48.992719</td>\n",
       "      <td>5.893333</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>57.080799</td>\n",
       "      <td>52.399869</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.195440</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>1500.66</td>\n",
       "      <td>51.663405</td>\n",
       "      <td>6.967375</td>\n",
       "      <td>1495.03</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>49.339386</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>5.328333</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>51.399425</td>\n",
       "      <td>8.124451</td>\n",
       "      <td>52.562502</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>9.426112</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>48.803377</td>\n",
       "      <td>0.942516</td>\n",
       "      <td>49.991679</td>\n",
       "      <td>0.117297</td>\n",
       "      <td>0.121145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124909</td>\n",
       "      <td>51.204482</td>\n",
       "      <td>3.336667</td>\n",
       "      <td>56.868932</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>9.060588</td>\n",
       "      <td>3.546667</td>\n",
       "      <td>4.315417</td>\n",
       "      <td>0.169541</td>\n",
       "      <td>4.928750</td>\n",
       "      <td>-0.239655</td>\n",
       "      <td>49.927641</td>\n",
       "      <td>4.774167</td>\n",
       "      <td>51.954595</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>59.064609</td>\n",
       "      <td>42.564205</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1535.17</td>\n",
       "      <td>46.860987</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>1577.10</td>\n",
       "      <td>0.143856</td>\n",
       "      <td>52.486645</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>4.705417</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>58.184556</td>\n",
       "      <td>8.420932</td>\n",
       "      <td>46.882217</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>12.093988</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>50.828439</td>\n",
       "      <td>0.941294</td>\n",
       "      <td>50.633643</td>\n",
       "      <td>0.138139</td>\n",
       "      <td>0.086229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132248</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>6.283333</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>4.921667</td>\n",
       "      <td>0.302087</td>\n",
       "      <td>5.185417</td>\n",
       "      <td>-0.097423</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>4.233750</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>5.853333</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.112194</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.116830</td>\n",
       "      <td>1496.85</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>1522.11</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>4.682500</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>0.938246</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.149493</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105738</td>\n",
       "      <td>49.941995</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>53.260259</td>\n",
       "      <td>0.120913</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>7.970138</td>\n",
       "      <td>4.763333</td>\n",
       "      <td>5.571250</td>\n",
       "      <td>-0.164139</td>\n",
       "      <td>5.305000</td>\n",
       "      <td>-0.080476</td>\n",
       "      <td>56.272661</td>\n",
       "      <td>4.379167</td>\n",
       "      <td>52.809227</td>\n",
       "      <td>5.173333</td>\n",
       "      <td>5.963333</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>57.771883</td>\n",
       "      <td>54.316401</td>\n",
       "      <td>0.137242</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0.869266</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.103208</td>\n",
       "      <td>1496.86</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>6.524847</td>\n",
       "      <td>1525.37</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>50.855171</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>4.778333</td>\n",
       "      <td>0.115979</td>\n",
       "      <td>45.246898</td>\n",
       "      <td>5.932286</td>\n",
       "      <td>51.909534</td>\n",
       "      <td>0.934447</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.093779</td>\n",
       "      <td>9.804628</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>52.890654</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>51.197815</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.131951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129293</td>\n",
       "      <td>43.637300</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>48.882718</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>7.303942</td>\n",
       "      <td>5.446667</td>\n",
       "      <td>4.720833</td>\n",
       "      <td>-0.310233</td>\n",
       "      <td>4.475833</td>\n",
       "      <td>-0.346771</td>\n",
       "      <td>52.130045</td>\n",
       "      <td>5.193333</td>\n",
       "      <td>54.871795</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>48.959081</td>\n",
       "      <td>52.400715</td>\n",
       "      <td>0.142088</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121801</td>\n",
       "      <td>1545.81</td>\n",
       "      <td>50.929752</td>\n",
       "      <td>7.311321</td>\n",
       "      <td>1521.29</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>50.381002</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>4.482083</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>52.122642</td>\n",
       "      <td>7.885816</td>\n",
       "      <td>47.102597</td>\n",
       "      <td>0.933383</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>5.518246</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>55.762037</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>51.309591</td>\n",
       "      <td>0.189644</td>\n",
       "      <td>0.128468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_last40_xGF_per_min_pp  away_last_5_xGF%_5v5  \\\n",
       "0                    0.112699             48.770492   \n",
       "1                    0.124909             51.204482   \n",
       "2                    0.132248             40.305523   \n",
       "3                    0.105738             49.941995   \n",
       "4                    0.129293             43.637300   \n",
       "\n",
       "   home_last5_pp_TOI_per_game  home_last_40_GF%_5v5  \\\n",
       "0                    4.190000             50.127801   \n",
       "1                    3.336667             56.868932   \n",
       "2                    6.283333             56.575634   \n",
       "3                    4.620000             53.260259   \n",
       "4                    2.690000             48.882718   \n",
       "\n",
       "   home_last40_xGA_per_min_pk  home_last5_xGA_per_min_pk  home_last_40_SH%  \\\n",
       "0                    0.104858                   0.098556          9.025236   \n",
       "1                    0.129028                   0.153383          9.060588   \n",
       "2                    0.116445                   0.131278          9.025460   \n",
       "3                    0.120913                   0.137299          7.970138   \n",
       "4                    0.084868                   0.067197          7.303942   \n",
       "\n",
       "   home_last5_pk_TOI_per_game  away_last40_pp_TOI_per_game  \\\n",
       "0                    3.693333                     4.646667   \n",
       "1                    3.546667                     4.315417   \n",
       "2                    4.540000                     4.921667   \n",
       "3                    4.763333                     5.571250   \n",
       "4                    5.446667                     4.720833   \n",
       "\n",
       "   home_Goalie_GSAx/60  away_last40_pk_TOI_per_game  away_Goalie_GSAx/60  \\\n",
       "0            -0.202922                     4.540000             0.082345   \n",
       "1             0.169541                     4.928750            -0.239655   \n",
       "2             0.302087                     5.185417            -0.097423   \n",
       "3            -0.164139                     5.305000            -0.080476   \n",
       "4            -0.310233                     4.475833            -0.346771   \n",
       "\n",
       "   away_last_5_GF%_5v5  home_last40_pk_TOI_per_game  home_last_40_xGF%_5v5  \\\n",
       "0            45.937500                     4.923333              48.992719   \n",
       "1            49.927641                     4.774167              51.954595   \n",
       "2            45.427286                     4.233750              49.851785   \n",
       "3            56.272661                     4.379167              52.809227   \n",
       "4            52.130045                     5.193333              54.871795   \n",
       "\n",
       "   away_last5_pp_TOI_per_game  away_last5_pk_TOI_per_game  \\\n",
       "0                    5.893333                    3.070000   \n",
       "1                    6.000000                    4.966667   \n",
       "2                    4.816667                    5.853333   \n",
       "3                    5.173333                    5.963333   \n",
       "4                    6.066667                    3.630000   \n",
       "\n",
       "   home_last5_GF_per_min_pp  home_last_5_GF%_5v5  home_last_5_FF%_5v5  \\\n",
       "0                  0.095465            57.080799            52.399869   \n",
       "1                  0.299700            59.064609            42.564205   \n",
       "2                  0.190981            58.385392            60.511924   \n",
       "3                  0.043290            57.771883            54.316401   \n",
       "4                  0.297398            48.959081            52.400715   \n",
       "\n",
       "   away_last5_xGF_per_min_pp  away_last40_xGF_per_min_pp  \\\n",
       "0                   0.069910                    0.122400   \n",
       "1                   0.096000                    0.102018   \n",
       "2                   0.153218                    0.120843   \n",
       "3                   0.137242                    0.143998   \n",
       "4                   0.142088                    0.087855   \n",
       "\n",
       "   home_last40_GA_per_min_pk  home_Goalie_HDCSV%  away_last5_GA_per_min_pk  \\\n",
       "0                   0.137102            0.858462                  0.195440   \n",
       "1                   0.104730            0.877358                  0.040268   \n",
       "2                   0.112194            0.897778                  0.068337   \n",
       "3                   0.125595            0.869266                  0.100615   \n",
       "4                   0.101091            0.830721                  0.000000   \n",
       "\n",
       "   away_last40_GF_per_min_pp  away_Rating.A.Pre  home_last_5_xGF%_5v5  \\\n",
       "0                   0.139885            1500.66             51.663405   \n",
       "1                   0.115864            1535.17             46.860987   \n",
       "2                   0.116830            1496.85             60.180542   \n",
       "3                   0.103208            1496.86             52.571429   \n",
       "4                   0.121801            1545.81             50.929752   \n",
       "\n",
       "   away_last_5_SH%  home_Rating.A.Pre  home_last5_xGF_per_min_pp  \\\n",
       "0         6.967375            1495.03                   0.079714   \n",
       "1        11.358025            1577.10                   0.143856   \n",
       "2         9.286882            1522.11                   0.113316   \n",
       "3         6.524847            1525.37                   0.118615   \n",
       "4         7.311321            1521.29                   0.098885   \n",
       "\n",
       "   away_last_40_xGF%_5v5  home_last5_GA_per_min_pk  \\\n",
       "0              49.339386                  0.054152   \n",
       "1              52.486645                  0.225564   \n",
       "2              49.136336                  0.132159   \n",
       "3              50.855171                  0.125962   \n",
       "4              50.381002                  0.036720   \n",
       "\n",
       "   home_last40_pp_TOI_per_game  away_last5_GF_per_min_pp  \\\n",
       "0                     5.328333                  0.101810   \n",
       "1                     4.705417                  0.100000   \n",
       "2                     4.682500                  0.166090   \n",
       "3                     4.778333                  0.115979   \n",
       "4                     4.482083                  0.065934   \n",
       "\n",
       "   away_last_40_GF%_5v5  away_last_40_SH%  away_last_5_FF%_5v5  \\\n",
       "0             51.399425          8.124451            52.562502   \n",
       "1             58.184556          8.420932            46.882217   \n",
       "2             50.499508          7.879167            43.520998   \n",
       "3             45.246898          5.932286            51.909534   \n",
       "4             52.122642          7.885816            47.102597   \n",
       "\n",
       "   home_Goalie_FenwickSV%  away_Goalie_HDCSV%  away_last40_xGA_per_min_pk  \\\n",
       "0                0.937294            0.873171                    0.133976   \n",
       "1                0.941904            0.864516                    0.097844   \n",
       "2                0.942492            0.878613                    0.107127   \n",
       "3                0.934447            0.848000                    0.093779   \n",
       "4                0.933383            0.839117                    0.102718   \n",
       "\n",
       "   home_last_5_SH%  away_last5_xGA_per_min_pk  home_last_40_FF%_5v5  \\\n",
       "0         9.426112                   0.074267             48.803377   \n",
       "1        12.093988                   0.109128             50.828439   \n",
       "2         8.478124                   0.112415             50.407241   \n",
       "3         9.804628                   0.086864             52.890654   \n",
       "4         5.518246                   0.107438             55.762037   \n",
       "\n",
       "   away_Goalie_FenwickSV%  away_last_40_FF%_5v5  home_last40_GF_per_min_pp  \\\n",
       "0                0.942516             49.991679                   0.117297   \n",
       "1                0.941294             50.633643                   0.138139   \n",
       "2                0.938246             50.595552                   0.149493   \n",
       "3                0.938305             51.197815                   0.099407   \n",
       "4                0.939698             51.309591                   0.189644   \n",
       "\n",
       "   away_last40_GA_per_min_pk  \n",
       "0                   0.121145  \n",
       "1                   0.086229  \n",
       "2                   0.106067  \n",
       "3                   0.131951  \n",
       "4                   0.128468  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numeric_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:50:18.261930Z",
     "start_time": "2021-05-07T19:50:18.258992Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['neg_log_loss', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:55:48.368793Z",
     "start_time": "2021-05-07T19:55:48.363567Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:39.885499Z",
     "start_time": "2021-05-07T20:01:39.880819Z"
    }
   },
   "outputs": [],
   "source": [
    "log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.00001, .0001, .001, .01, .05, 0.1],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv = GridSearchCV(log_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:44.530594Z",
     "start_time": "2021-05-07T20:01:40.634523Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                   0.05, 0.1],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:47.614964Z",
     "start_time": "2021-05-07T20:01:47.610337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6754370089204439"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:01:48.860448Z",
     "start_time": "2021-05-07T20:01:48.834622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671673</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673921</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019093</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673923</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678653</td>\n",
       "      <td>-0.672743</td>\n",
       "      <td>-0.678873</td>\n",
       "      <td>-0.676277</td>\n",
       "      <td>-0.675154</td>\n",
       "      <td>-0.676340</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.619247</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.587378</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677641</td>\n",
       "      <td>-0.668417</td>\n",
       "      <td>-0.680201</td>\n",
       "      <td>-0.678592</td>\n",
       "      <td>-0.676997</td>\n",
       "      <td>-0.676369</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677863</td>\n",
       "      <td>-0.668443</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679093</td>\n",
       "      <td>-0.676975</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677864</td>\n",
       "      <td>-0.668444</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679094</td>\n",
       "      <td>-0.676973</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.678655</td>\n",
       "      <td>-0.671507</td>\n",
       "      <td>-0.677800</td>\n",
       "      <td>-0.679098</td>\n",
       "      <td>-0.675913</td>\n",
       "      <td>-0.676595</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677719</td>\n",
       "      <td>-0.669147</td>\n",
       "      <td>-0.678903</td>\n",
       "      <td>-0.679826</td>\n",
       "      <td>-0.677732</td>\n",
       "      <td>-0.676665</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.573696</td>\n",
       "      <td>0.015507</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677728</td>\n",
       "      <td>-0.669121</td>\n",
       "      <td>-0.681685</td>\n",
       "      <td>-0.681348</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.677963</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.599721</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575648</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677767</td>\n",
       "      <td>-0.669153</td>\n",
       "      <td>-0.681584</td>\n",
       "      <td>-0.681528</td>\n",
       "      <td>-0.679915</td>\n",
       "      <td>-0.677990</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       0.012287      0.000163         0.007713        0.000084   \n",
       "17       0.019093      0.000621         0.007772        0.000036   \n",
       "15       0.014589      0.000732         0.008238        0.000482   \n",
       "21       0.017617      0.000735         0.007767        0.000023   \n",
       "23       0.025454      0.001999         0.008297        0.000467   \n",
       "22       0.016674      0.000611         0.007799        0.000178   \n",
       "24       0.017753      0.000853         0.007911        0.000061   \n",
       "30       0.025024      0.004794         0.009411        0.000891   \n",
       "27       0.024262      0.001168         0.008714        0.000813   \n",
       "28       0.022607      0.000736         0.008461        0.000296   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "16                       0.001                                   None   \n",
       "17                       0.001                                   None   \n",
       "15                       0.001                                   None   \n",
       "21                        0.01                                   None   \n",
       "23                        0.01                                   None   \n",
       "22                        0.01                                   None   \n",
       "24                        0.05                                   None   \n",
       "30                         0.1                                   None   \n",
       "27                        0.05                                   None   \n",
       "28                        0.05                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "16                                l2                            lbfgs   \n",
       "17                                l2                        newton-cg   \n",
       "15                                l2                        liblinear   \n",
       "21                                l2                        liblinear   \n",
       "23                                l2                        newton-cg   \n",
       "22                                l2                            lbfgs   \n",
       "24                                l1                        liblinear   \n",
       "30                                l1                        liblinear   \n",
       "27                                l2                        liblinear   \n",
       "28                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "16  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "17  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "15  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "21  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "23  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "22  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "24  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "30  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "27  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "28  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "16                 -0.678374                 -0.671673   \n",
       "17                 -0.678374                 -0.671674   \n",
       "15                 -0.678653                 -0.672743   \n",
       "21                 -0.677641                 -0.668417   \n",
       "23                 -0.677863                 -0.668443   \n",
       "22                 -0.677864                 -0.668444   \n",
       "24                 -0.678655                 -0.671507   \n",
       "30                 -0.677719                 -0.669147   \n",
       "27                 -0.677728                 -0.669121   \n",
       "28                 -0.677767                 -0.669153   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "16                 -0.677392                 -0.675825   \n",
       "17                 -0.677392                 -0.675825   \n",
       "15                 -0.678873                 -0.676277   \n",
       "21                 -0.680201                 -0.678592   \n",
       "23                 -0.679819                 -0.679093   \n",
       "22                 -0.679819                 -0.679094   \n",
       "24                 -0.677800                 -0.679098   \n",
       "30                 -0.678903                 -0.679826   \n",
       "27                 -0.681685                 -0.681348   \n",
       "28                 -0.681584                 -0.681528   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "16                 -0.673921               -0.675437               0.002411   \n",
       "17                 -0.673923               -0.675437               0.002410   \n",
       "15                 -0.675154               -0.676340               0.002285   \n",
       "21                 -0.676997               -0.676369               0.004120   \n",
       "23                 -0.676975               -0.676439               0.004116   \n",
       "22                 -0.676973               -0.676439               0.004116   \n",
       "24                 -0.675913               -0.676595               0.002768   \n",
       "30                 -0.677732               -0.676665               0.003841   \n",
       "27                 -0.679935               -0.677963               0.004635   \n",
       "28                 -0.679915               -0.677990               0.004632   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "16                       1              0.566248              0.592748   \n",
       "17                       2              0.566248              0.592748   \n",
       "15                       3              0.567643              0.619247   \n",
       "21                       4              0.584379              0.598326   \n",
       "23                       5              0.585774              0.594142   \n",
       "22                       6              0.585774              0.594142   \n",
       "24                       7              0.567643              0.588563   \n",
       "30                       8              0.570432              0.596932   \n",
       "27                       9              0.581590              0.599721   \n",
       "28                      10              0.577406              0.598326   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "16              0.594972              0.571229              0.578212   \n",
       "17              0.594972              0.571229              0.578212   \n",
       "15              0.594972              0.585196              0.569832   \n",
       "21              0.587989              0.565642              0.565642   \n",
       "23              0.587989              0.557263              0.569832   \n",
       "22              0.587989              0.557263              0.569832   \n",
       "24              0.596369              0.561453              0.575419   \n",
       "30              0.585196              0.561453              0.554469   \n",
       "27              0.579609              0.561453              0.555866   \n",
       "28              0.581006              0.562849              0.555866   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "16            0.580682           0.011433                   2  \n",
       "17            0.580682           0.011433                   2  \n",
       "15            0.587378           0.018843                   1  \n",
       "21            0.580396           0.012887                   4  \n",
       "23            0.579000           0.013510                   6  \n",
       "22            0.579000           0.013510                   6  \n",
       "24            0.577889           0.012936                   8  \n",
       "30            0.573696           0.015507                  13  \n",
       "27            0.575648           0.015642                  10  \n",
       "28            0.575091           0.014830                  11  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results = pd.DataFrame(log_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T20:41:45.519776Z",
     "start_time": "2021-05-07T20:41:45.509666Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25, 50],\n",
    "         'ada__learning_rate': [.1, 1, 10, 20],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv = GridSearchCV(ada_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:28.422107Z",
     "start_time": "2021-05-07T20:41:46.318203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.1, 1, 10, 20],\n",
       "                         'ada__n_estimators': [25, 50]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:49.571527Z",
     "start_time": "2021-05-07T21:39:49.568150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6799359662807147"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:28.797531Z",
     "start_time": "2021-05-07T21:24:28.766354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.529209</td>\n",
       "      <td>0.277327</td>\n",
       "      <td>2.543278</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683305</td>\n",
       "      <td>-0.674921</td>\n",
       "      <td>-0.681226</td>\n",
       "      <td>-0.681435</td>\n",
       "      <td>-0.678793</td>\n",
       "      <td>-0.679936</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.341996</td>\n",
       "      <td>0.235797</td>\n",
       "      <td>2.495557</td>\n",
       "      <td>0.040371</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682869</td>\n",
       "      <td>-0.679884</td>\n",
       "      <td>-0.681938</td>\n",
       "      <td>-0.681413</td>\n",
       "      <td>-0.681377</td>\n",
       "      <td>-0.681496</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.559740</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.132445</td>\n",
       "      <td>1.405995</td>\n",
       "      <td>5.013317</td>\n",
       "      <td>0.237507</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684522</td>\n",
       "      <td>-0.676831</td>\n",
       "      <td>-0.682880</td>\n",
       "      <td>-0.684050</td>\n",
       "      <td>-0.680332</td>\n",
       "      <td>-0.681723</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.571187</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.064554</td>\n",
       "      <td>1.219384</td>\n",
       "      <td>2.431893</td>\n",
       "      <td>0.203562</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684800</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>-0.682937</td>\n",
       "      <td>-0.684372</td>\n",
       "      <td>-0.680497</td>\n",
       "      <td>-0.682232</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.565324</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684109</td>\n",
       "      <td>-0.681523</td>\n",
       "      <td>-0.684027</td>\n",
       "      <td>-0.682690</td>\n",
       "      <td>-0.682635</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.938708</td>\n",
       "      <td>0.095818</td>\n",
       "      <td>4.740888</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685502</td>\n",
       "      <td>-0.683732</td>\n",
       "      <td>-0.684680</td>\n",
       "      <td>-0.685002</td>\n",
       "      <td>-0.684744</td>\n",
       "      <td>-0.684732</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.542155</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73.917730</td>\n",
       "      <td>4.193198</td>\n",
       "      <td>3.965984</td>\n",
       "      <td>0.348138</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.686802</td>\n",
       "      <td>-0.683494</td>\n",
       "      <td>-0.685372</td>\n",
       "      <td>-0.686456</td>\n",
       "      <td>-0.683155</td>\n",
       "      <td>-0.685056</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.546902</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.229651</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.022538</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.686993</td>\n",
       "      <td>-0.685253</td>\n",
       "      <td>-0.687152</td>\n",
       "      <td>-0.686154</td>\n",
       "      <td>-0.686353</td>\n",
       "      <td>-0.686381</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.582634</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.319119</td>\n",
       "      <td>0.179226</td>\n",
       "      <td>2.073445</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688066</td>\n",
       "      <td>-0.688023</td>\n",
       "      <td>-0.687880</td>\n",
       "      <td>-0.688809</td>\n",
       "      <td>-0.687754</td>\n",
       "      <td>-0.688106</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>9</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.084216</td>\n",
       "      <td>0.296903</td>\n",
       "      <td>4.008086</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688713</td>\n",
       "      <td>-0.688734</td>\n",
       "      <td>-0.688831</td>\n",
       "      <td>-0.688501</td>\n",
       "      <td>-0.688628</td>\n",
       "      <td>-0.688681</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      42.529209      0.277327         2.543278        0.006013   \n",
       "0      43.341996      0.235797         2.495557        0.040371   \n",
       "5      83.132445      1.405995         5.013317        0.237507   \n",
       "6      41.064554      1.219384         2.431893        0.203562   \n",
       "8       0.122800      0.002372         0.015609        0.000248   \n",
       "1      81.938708      0.095818         4.740888        0.009278   \n",
       "7      73.917730      4.193198         3.965984        0.348138   \n",
       "9       0.229651      0.005856         0.022538        0.000169   \n",
       "2      35.319119      0.179226         2.073445        0.010988   \n",
       "3      68.084216      0.296903         4.008086        0.018197   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "4  SVC(kernel='linear', probability=True)                       10   \n",
       "0  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5  SVC(kernel='linear', probability=True)                       10   \n",
       "6  SVC(kernel='linear', probability=True)                       20   \n",
       "8                    LogisticRegression()                      0.1   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "7  SVC(kernel='linear', probability=True)                       20   \n",
       "9                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "3  SVC(kernel='linear', probability=True)                        1   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "4                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "8                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "1                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "7                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "9                      50  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "3                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.683305                 -0.674921   \n",
       "0                 -0.682869                 -0.679884   \n",
       "5                 -0.684522                 -0.676831   \n",
       "6                 -0.684800                 -0.678553   \n",
       "8                 -0.684109                 -0.681523   \n",
       "1                 -0.685502                 -0.683732   \n",
       "7                 -0.686802                 -0.683494   \n",
       "9                 -0.686993                 -0.685253   \n",
       "2                 -0.688066                 -0.688023   \n",
       "3                 -0.688713                 -0.688734   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.681226                 -0.681435   \n",
       "0                 -0.681938                 -0.681413   \n",
       "5                 -0.682880                 -0.684050   \n",
       "6                 -0.682937                 -0.684372   \n",
       "8                 -0.684027                 -0.682690   \n",
       "1                 -0.684680                 -0.685002   \n",
       "7                 -0.685372                 -0.686456   \n",
       "9                 -0.687152                 -0.686154   \n",
       "2                 -0.687880                 -0.688809   \n",
       "3                 -0.688831                 -0.688501   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.678793               -0.679936               0.002889   \n",
       "0                 -0.681377               -0.681496               0.000969   \n",
       "5                 -0.680332               -0.681723               0.002844   \n",
       "6                 -0.680497               -0.682232               0.002375   \n",
       "8                 -0.682635               -0.682997               0.000969   \n",
       "1                 -0.684744               -0.684732               0.000578   \n",
       "7                 -0.683155               -0.685056               0.001494   \n",
       "9                 -0.686353               -0.686381               0.000677   \n",
       "2                 -0.687754               -0.688106               0.000368   \n",
       "3                 -0.688628               -0.688681               0.000111   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.553696              0.596932   \n",
       "0                       2              0.560669              0.569038   \n",
       "5                       3              0.557880              0.591353   \n",
       "6                       4              0.545328              0.594142   \n",
       "8                       5              0.564854              0.594142   \n",
       "1                       6              0.543933              0.542538   \n",
       "7                       7              0.543933              0.545328   \n",
       "9                       8              0.569038              0.602510   \n",
       "2                       9              0.543933              0.543933   \n",
       "3                      10              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.583799              0.561453              0.569832   \n",
       "0              0.564246              0.551676              0.553073   \n",
       "5              0.585196              0.554469              0.567039   \n",
       "6              0.571229              0.546089              0.569832   \n",
       "8              0.597765              0.569832              0.581006   \n",
       "1              0.537709              0.540503              0.546089   \n",
       "7              0.540503              0.543296              0.561453   \n",
       "9              0.597765              0.572626              0.571229   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "3              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.573142           0.015526                   4  \n",
       "0            0.559740           0.006589                   8  \n",
       "5            0.571187           0.014674                   6  \n",
       "6            0.565324           0.018196                   7  \n",
       "8            0.581520           0.012945                   2  \n",
       "1            0.542155           0.002873                  12  \n",
       "7            0.546902           0.007443                   9  \n",
       "9            0.582634           0.014416                   1  \n",
       "2            0.543830           0.000517                  10  \n",
       "3            0.543830           0.000517                  10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(ada_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:24:29.172013Z",
     "start_time": "2021-05-07T21:24:29.167686Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "gb_params = {'gb__n_estimators': [200, 300, 400],\n",
    "         'gb__learning_rate': [.001,.01, .1],\n",
    "         'gb__max_depth' : [3,5]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipeline, param_grid=gb_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:48.284336Z",
     "start_time": "2021-05-07T21:24:29.598260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last5_GF_per_min_pp',\n",
       "                                                                          'away_last_40_GF%_5v5',\n",
       "                                                                          'away_last_40_SH%',\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('gb', GradientBoostingClassifier())]),\n",
       "             param_grid={'gb__learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'gb__max_depth': [3, 5],\n",
       "                         'gb__n_estimators': [200, 300, 400]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:48.700152Z",
     "start_time": "2021-05-07T21:39:48.696870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6813351464598496"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:39:49.128256Z",
     "start_time": "2021-05-07T21:39:49.105537Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.060808</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.013046</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682658</td>\n",
       "      <td>-0.679488</td>\n",
       "      <td>-0.684309</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.679678</td>\n",
       "      <td>-0.681335</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.574265</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.613778</td>\n",
       "      <td>0.132845</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682625</td>\n",
       "      <td>-0.679836</td>\n",
       "      <td>-0.685340</td>\n",
       "      <td>-0.681250</td>\n",
       "      <td>-0.680842</td>\n",
       "      <td>-0.681979</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.091404</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682338</td>\n",
       "      <td>-0.681422</td>\n",
       "      <td>-0.686645</td>\n",
       "      <td>-0.682562</td>\n",
       "      <td>-0.682085</td>\n",
       "      <td>-0.683010</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.066107</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683842</td>\n",
       "      <td>-0.681349</td>\n",
       "      <td>-0.688062</td>\n",
       "      <td>-0.682242</td>\n",
       "      <td>-0.684823</td>\n",
       "      <td>-0.684064</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.568958</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.050758</td>\n",
       "      <td>0.085446</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685737</td>\n",
       "      <td>-0.683565</td>\n",
       "      <td>-0.686076</td>\n",
       "      <td>-0.685384</td>\n",
       "      <td>-0.684671</td>\n",
       "      <td>-0.685087</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>5</td>\n",
       "      <td>0.538354</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.995703</td>\n",
       "      <td>0.058481</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685431</td>\n",
       "      <td>-0.682782</td>\n",
       "      <td>-0.689631</td>\n",
       "      <td>-0.685636</td>\n",
       "      <td>-0.684904</td>\n",
       "      <td>-0.685677</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>6</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.986876</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686009</td>\n",
       "      <td>-0.683521</td>\n",
       "      <td>-0.688014</td>\n",
       "      <td>-0.686682</td>\n",
       "      <td>-0.685319</td>\n",
       "      <td>-0.685909</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>7</td>\n",
       "      <td>0.531381</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.542153</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.521795</td>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.015967</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686319</td>\n",
       "      <td>-0.684856</td>\n",
       "      <td>-0.686472</td>\n",
       "      <td>-0.686419</td>\n",
       "      <td>-0.685634</td>\n",
       "      <td>-0.685940</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.542713</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.228661</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683065</td>\n",
       "      <td>-0.684688</td>\n",
       "      <td>-0.690831</td>\n",
       "      <td>-0.686171</td>\n",
       "      <td>-0.688825</td>\n",
       "      <td>-0.686716</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>9</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.566724</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.987818</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.016568</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686886</td>\n",
       "      <td>-0.685194</td>\n",
       "      <td>-0.688012</td>\n",
       "      <td>-0.688228</td>\n",
       "      <td>-0.685266</td>\n",
       "      <td>-0.686717</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>10</td>\n",
       "      <td>0.535565</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.550279</td>\n",
       "      <td>0.541876</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        5.060808      0.005743         0.013046        0.000360   \n",
       "7        7.613778      0.132845         0.014969        0.000935   \n",
       "8       10.091404      0.022878         0.015978        0.000220   \n",
       "9        8.066107      0.019059         0.016398        0.000273   \n",
       "2       10.050758      0.085446         0.018590        0.000354   \n",
       "5       15.995703      0.058481         0.026158        0.001207   \n",
       "4       11.986876      0.043948         0.021257        0.000472   \n",
       "1        7.521795      0.034738         0.015967        0.000136   \n",
       "10      12.228661      0.028340         0.019323        0.000183   \n",
       "3        7.987818      0.031277         0.016568        0.000518   \n",
       "\n",
       "   param_gb__learning_rate param_gb__max_depth param_gb__n_estimators  \\\n",
       "6                     0.01                   3                    200   \n",
       "7                     0.01                   3                    300   \n",
       "8                     0.01                   3                    400   \n",
       "9                     0.01                   5                    200   \n",
       "2                    0.001                   3                    400   \n",
       "5                    0.001                   5                    400   \n",
       "4                    0.001                   5                    300   \n",
       "1                    0.001                   3                    300   \n",
       "10                    0.01                   5                    300   \n",
       "3                    0.001                   5                    200   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "7   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "8   {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "9   {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "2   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "5   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "4   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "1   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "10  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "3   {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.682658                 -0.679488   \n",
       "7                  -0.682625                 -0.679836   \n",
       "8                  -0.682338                 -0.681422   \n",
       "9                  -0.683842                 -0.681349   \n",
       "2                  -0.685737                 -0.683565   \n",
       "5                  -0.685431                 -0.682782   \n",
       "4                  -0.686009                 -0.683521   \n",
       "1                  -0.686319                 -0.684856   \n",
       "10                 -0.683065                 -0.684688   \n",
       "3                  -0.686886                 -0.685194   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.684309                 -0.680543   \n",
       "7                  -0.685340                 -0.681250   \n",
       "8                  -0.686645                 -0.682562   \n",
       "9                  -0.688062                 -0.682242   \n",
       "2                  -0.686076                 -0.685384   \n",
       "5                  -0.689631                 -0.685636   \n",
       "4                  -0.688014                 -0.686682   \n",
       "1                  -0.686472                 -0.686419   \n",
       "10                 -0.690831                 -0.686171   \n",
       "3                  -0.688012                 -0.688228   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.679678               -0.681335               0.001864   \n",
       "7                  -0.680842               -0.681979               0.001904   \n",
       "8                  -0.682085               -0.683010               0.001857   \n",
       "9                  -0.684823               -0.684064               0.002336   \n",
       "2                  -0.684671               -0.685087               0.000892   \n",
       "5                  -0.684904               -0.685677               0.002221   \n",
       "4                  -0.685319               -0.685909               0.001489   \n",
       "1                  -0.685634               -0.685940               0.000621   \n",
       "10                 -0.688825               -0.686716               0.002797   \n",
       "3                  -0.685266               -0.686717               0.001297   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.559275              0.570432   \n",
       "7                        2              0.550907              0.557880   \n",
       "8                        3              0.549512              0.559275   \n",
       "9                        4              0.559275              0.570432   \n",
       "2                        5              0.538354              0.548117   \n",
       "5                        6              0.536960              0.560669   \n",
       "4                        7              0.531381              0.560669   \n",
       "1                        8              0.542538              0.545328   \n",
       "10                       9              0.566248              0.560669   \n",
       "3                       10              0.535565              0.546722   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.590782              0.568436              0.582402   \n",
       "7               0.586592              0.565642              0.579609   \n",
       "8               0.585196              0.572626              0.574022   \n",
       "9               0.571229              0.581006              0.562849   \n",
       "2               0.539106              0.551676              0.541899   \n",
       "5               0.526536              0.544693              0.547486   \n",
       "4               0.533520              0.537709              0.547486   \n",
       "1               0.539106              0.543296              0.543296   \n",
       "10              0.567039              0.575419              0.564246   \n",
       "3               0.536313              0.540503              0.550279   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.574265           0.011067                   1  \n",
       "7             0.568126           0.013270                   3  \n",
       "8             0.568126           0.012419                   3  \n",
       "9             0.568958           0.007531                   2  \n",
       "2             0.543831           0.005215                  13  \n",
       "5             0.543269           0.011335                  14  \n",
       "4             0.542153           0.010785                  16  \n",
       "1             0.542713           0.002028                  15  \n",
       "10            0.566724           0.004873                   6  \n",
       "3             0.541876           0.005775                  17  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.DataFrame(gb_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "gb_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not seem that gradient boosting is producing good results for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:49:41.343142Z",
     "start_time": "2021-05-07T21:49:41.337437Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu', input_dim=44))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:16:01.938573Z",
     "start_time": "2021-05-07T22:16:01.932418Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model = scikit_learn.KerasClassifier(build_model,\n",
    "                                          epochs=50,\n",
    "                                          batch_size=32,\n",
    "                                          verbose=2)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:16:07.550928Z",
     "start_time": "2021-05-07T22:16:04.002416Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "112/112 - 0s - loss: 0.6968 - accuracy: 0.5475\n",
      "Epoch 2/50\n",
      "112/112 - 0s - loss: 0.6840 - accuracy: 0.5558\n",
      "Epoch 3/50\n",
      "112/112 - 0s - loss: 0.6778 - accuracy: 0.5617\n",
      "Epoch 4/50\n",
      "112/112 - 0s - loss: 0.6747 - accuracy: 0.5653\n",
      "Epoch 5/50\n",
      "112/112 - 0s - loss: 0.6721 - accuracy: 0.5676\n",
      "Epoch 6/50\n",
      "112/112 - 0s - loss: 0.6700 - accuracy: 0.5843\n",
      "Epoch 7/50\n",
      "112/112 - 0s - loss: 0.6674 - accuracy: 0.5918\n",
      "Epoch 8/50\n",
      "112/112 - 0s - loss: 0.6656 - accuracy: 0.5941\n",
      "Epoch 9/50\n",
      "112/112 - 0s - loss: 0.6630 - accuracy: 0.5988\n",
      "Epoch 10/50\n",
      "112/112 - 0s - loss: 0.6616 - accuracy: 0.6002\n",
      "Epoch 11/50\n",
      "112/112 - 0s - loss: 0.6590 - accuracy: 0.5960\n",
      "Epoch 12/50\n",
      "112/112 - 0s - loss: 0.6570 - accuracy: 0.6064\n",
      "Epoch 13/50\n",
      "112/112 - 0s - loss: 0.6545 - accuracy: 0.6072\n",
      "Epoch 14/50\n",
      "112/112 - 0s - loss: 0.6528 - accuracy: 0.6033\n",
      "Epoch 15/50\n",
      "112/112 - 0s - loss: 0.6509 - accuracy: 0.6080\n",
      "Epoch 16/50\n",
      "112/112 - 0s - loss: 0.6488 - accuracy: 0.6139\n",
      "Epoch 17/50\n",
      "112/112 - 0s - loss: 0.6466 - accuracy: 0.6175\n",
      "Epoch 18/50\n",
      "112/112 - 0s - loss: 0.6451 - accuracy: 0.6173\n",
      "Epoch 19/50\n",
      "112/112 - 0s - loss: 0.6426 - accuracy: 0.6251\n",
      "Epoch 20/50\n",
      "112/112 - 0s - loss: 0.6405 - accuracy: 0.6206\n",
      "Epoch 21/50\n",
      "112/112 - 0s - loss: 0.6386 - accuracy: 0.6203\n",
      "Epoch 22/50\n",
      "112/112 - 0s - loss: 0.6367 - accuracy: 0.6237\n",
      "Epoch 23/50\n",
      "112/112 - 0s - loss: 0.6346 - accuracy: 0.6248\n",
      "Epoch 24/50\n",
      "112/112 - 0s - loss: 0.6319 - accuracy: 0.6312\n",
      "Epoch 25/50\n",
      "112/112 - 0s - loss: 0.6310 - accuracy: 0.6354\n",
      "Epoch 26/50\n",
      "112/112 - 0s - loss: 0.6291 - accuracy: 0.6337\n",
      "Epoch 27/50\n",
      "112/112 - 0s - loss: 0.6267 - accuracy: 0.6348\n",
      "Epoch 28/50\n",
      "112/112 - 0s - loss: 0.6248 - accuracy: 0.6340\n",
      "Epoch 29/50\n",
      "112/112 - 0s - loss: 0.6224 - accuracy: 0.6382\n",
      "Epoch 30/50\n",
      "112/112 - 0s - loss: 0.6213 - accuracy: 0.6421\n",
      "Epoch 31/50\n",
      "112/112 - 0s - loss: 0.6196 - accuracy: 0.6438\n",
      "Epoch 32/50\n",
      "112/112 - 0s - loss: 0.6178 - accuracy: 0.6457\n",
      "Epoch 33/50\n",
      "112/112 - 0s - loss: 0.6154 - accuracy: 0.6488\n",
      "Epoch 34/50\n",
      "112/112 - 0s - loss: 0.6129 - accuracy: 0.6510\n",
      "Epoch 35/50\n",
      "112/112 - 0s - loss: 0.6120 - accuracy: 0.6558\n",
      "Epoch 36/50\n",
      "112/112 - 0s - loss: 0.6108 - accuracy: 0.6533\n",
      "Epoch 37/50\n",
      "112/112 - 0s - loss: 0.6090 - accuracy: 0.6549\n",
      "Epoch 38/50\n",
      "112/112 - 0s - loss: 0.6075 - accuracy: 0.6566\n",
      "Epoch 39/50\n",
      "112/112 - 0s - loss: 0.6056 - accuracy: 0.6563\n",
      "Epoch 40/50\n",
      "112/112 - 0s - loss: 0.6037 - accuracy: 0.6619\n",
      "Epoch 41/50\n",
      "112/112 - 0s - loss: 0.6043 - accuracy: 0.6575\n",
      "Epoch 42/50\n",
      "112/112 - 0s - loss: 0.6001 - accuracy: 0.6650\n",
      "Epoch 43/50\n",
      "112/112 - 0s - loss: 0.6000 - accuracy: 0.6591\n",
      "Epoch 44/50\n",
      "112/112 - 0s - loss: 0.5991 - accuracy: 0.6608\n",
      "Epoch 45/50\n",
      "112/112 - 0s - loss: 0.5970 - accuracy: 0.6639\n",
      "Epoch 46/50\n",
      "112/112 - 0s - loss: 0.5962 - accuracy: 0.6639\n",
      "Epoch 47/50\n",
      "112/112 - 0s - loss: 0.5939 - accuracy: 0.6695\n",
      "Epoch 48/50\n",
      "112/112 - 0s - loss: 0.5933 - accuracy: 0.6711\n",
      "Epoch 49/50\n",
      "112/112 - 0s - loss: 0.5920 - accuracy: 0.6686\n",
      "Epoch 50/50\n",
      "112/112 - 0s - loss: 0.5888 - accuracy: 0.6717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_last40_xGF_per_min_pp',\n",
       "                                                   'away_last_5_xGF%_5v5',\n",
       "                                                   'home_last_40_GF%_5v5',\n",
       "                                                   'home_last40_xGA_per_min_pk',\n",
       "                                                   'home_last5_xGA_per_min_pk',\n",
       "                                                   'home_last_40_SH%',\n",
       "                                                   'home_Goalie_GSAx/60',\n",
       "                                                   'away_Goalie_GSAx/60',\n",
       "                                                   'away_last_5_GF%_5v5',\n",
       "                                                   'home_last_40_x...\n",
       "                                                   'home_Rating.A.Pre',\n",
       "                                                   'home_last5_xGF_per_min_pp',\n",
       "                                                   'away_last_40_xGF%_5v5',\n",
       "                                                   'home_last5_GA_per_min_pk',\n",
       "                                                   'away_last5_GF_per_min_pp',\n",
       "                                                   'away_last_40_GF%_5v5',\n",
       "                                                   'away_last_40_SH%',\n",
       "                                                   'away_last_5_FF%_5v5', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['B2B_Status'])])),\n",
       "                ('nn',\n",
       "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd20af3f730>)])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:16:48.515314Z",
     "start_time": "2021-05-07T22:16:48.482996Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['0'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0ad9426e3a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;34m\"data given during fit.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             )\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    433\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 delayed(func)(\n\u001b[1;32m    437\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown,\n\u001b[0m\u001b[1;32m    462\u001b[0m                                         force_all_finite='allow-nan')\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[1;32m    135\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['0'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "nn_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_loss = n.history['loss']\n",
    "sigmoid_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the logistic regression, coefficients, I can see which feature the algorithm deemed most impactful. I am\n",
    "very surprised that away_last_40_xGF%_5v5 was cut by the l1 regularization, that seemed like it would be one of the more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T21:40:47.420829Z",
     "start_time": "2021-05-07T21:40:47.405909Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B2B_Status</td>\n",
       "      <td>-0.057949</td>\n",
       "      <td>0.057949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_5_xGF%_5v5</td>\n",
       "      <td>0.056853</td>\n",
       "      <td>0.056853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>home_last40_GF_per_min_pp</td>\n",
       "      <td>-0.048104</td>\n",
       "      <td>0.048104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>away_last40_GA_per_min_pk</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.047458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_last5_xGA_per_min_pk</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.045442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>home_Rating.A.Pre</td>\n",
       "      <td>-0.039534</td>\n",
       "      <td>0.039534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home_last_5_GF%_5v5</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>0.036940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>-0.036372</td>\n",
       "      <td>0.036372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>0.036092</td>\n",
       "      <td>0.036092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>-0.027892</td>\n",
       "      <td>0.027892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home_last5_pp_TOI_per_game</td>\n",
       "      <td>-0.027105</td>\n",
       "      <td>0.027105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>-0.025317</td>\n",
       "      <td>0.025317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>home_last40_GA_per_min_pk</td>\n",
       "      <td>-0.025067</td>\n",
       "      <td>0.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_last_5_SH%</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>0.024895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>home_last_5_FF%_5v5</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.024562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>away_last_5_FF%_5v5</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>0.020716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>away_last_5_xGF%_5v5</td>\n",
       "      <td>-0.019800</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>away_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.018728</td>\n",
       "      <td>0.018728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>away_last5_xGF_per_min_pp</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>away_last5_xGA_per_min_pk</td>\n",
       "      <td>-0.016923</td>\n",
       "      <td>0.016923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>home_last40_pp_TOI_per_game</td>\n",
       "      <td>-0.015822</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_last40_pk_TOI_per_game</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.015449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>away_last_40_GF%_5v5</td>\n",
       "      <td>-0.014134</td>\n",
       "      <td>0.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>away_last40_GF_per_min_pp</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.013513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.013225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>0.011488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>home_last5_GF_per_min_pp</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>0.011099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>away_last5_GF_per_min_pp</td>\n",
       "      <td>-0.010147</td>\n",
       "      <td>0.010147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.008087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>-0.007119</td>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>-0.007003</td>\n",
       "      <td>0.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>away_last_5_SH%</td>\n",
       "      <td>-0.006758</td>\n",
       "      <td>0.006758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>away_last5_pp_TOI_per_game</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>0.005485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_last5_GA_per_min_pk</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>0.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_last40_xGA_per_min_pk</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away_last40_pp_TOI_per_game</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.003575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>home_last5_xGF_per_min_pp</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>0.002946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_last5_GA_per_min_pk</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home_last5_pk_TOI_per_game</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>-0.001876</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>home_last40_xGF_per_min_pp</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature      Coef  Coef_abs\n",
       "19                   B2B_Status -0.057949  0.057949\n",
       "22         home_last_5_xGF%_5v5  0.056853  0.056853\n",
       "37    home_last40_GF_per_min_pp -0.048104  0.048104\n",
       "35    away_last40_GA_per_min_pk  0.047458  0.047458\n",
       "9     home_last5_xGA_per_min_pk  0.045442  0.045442\n",
       "24            home_Rating.A.Pre -0.039534  0.039534\n",
       "27          home_last_5_GF%_5v5 -0.036940  0.036940\n",
       "15           home_Goalie_HDCSV% -0.036372  0.036372\n",
       "30             home_last_40_SH%  0.036092  0.036092\n",
       "38             away_last_40_SH%  0.032656  0.032656\n",
       "31        away_last_40_xGF%_5v5 -0.027892  0.027892\n",
       "18   home_last5_pp_TOI_per_game -0.027105  0.027105\n",
       "28          away_Goalie_GSAx/60 -0.025317  0.025317\n",
       "21    home_last40_GA_per_min_pk -0.025067  0.025067\n",
       "7               home_last_5_SH% -0.024895  0.024895\n",
       "40          home_last_5_FF%_5v5  0.024562  0.024562\n",
       "17   home_last40_xGA_per_min_pk -0.022679  0.022679\n",
       "14          away_last_5_FF%_5v5 -0.020716  0.020716\n",
       "36         away_last_5_xGF%_5v5 -0.019800  0.019800\n",
       "29  away_last40_pk_TOI_per_game -0.018728  0.018728\n",
       "12    away_last5_xGF_per_min_pp  0.017911  0.017911\n",
       "4     away_last5_xGA_per_min_pk -0.016923  0.016923\n",
       "33  home_last40_pp_TOI_per_game -0.015822  0.015822\n",
       "6   home_last40_pk_TOI_per_game  0.015449  0.015449\n",
       "11         away_last_40_GF%_5v5 -0.014134  0.014134\n",
       "0     away_last40_GF_per_min_pp  0.013513  0.013513\n",
       "32        home_last_40_xGF%_5v5  0.013225  0.013225\n",
       "42       away_Goalie_FenwickSV% -0.011488  0.011488\n",
       "23     home_last5_GF_per_min_pp -0.011099  0.011099\n",
       "41     away_last5_GF_per_min_pp -0.010147  0.010147\n",
       "2          away_last_40_FF%_5v5  0.008087  0.008087\n",
       "13         home_last_40_GF%_5v5 -0.007119  0.007119\n",
       "16         home_last_40_FF%_5v5 -0.007003  0.007003\n",
       "25              away_last_5_SH% -0.006758  0.006758\n",
       "10   away_last5_pp_TOI_per_game -0.005485  0.005485\n",
       "8      home_last5_GA_per_min_pk -0.004725  0.004725\n",
       "20   away_last40_xGA_per_min_pk  0.003585  0.003585\n",
       "1   away_last40_pp_TOI_per_game  0.003575  0.003575\n",
       "43    home_last5_xGF_per_min_pp -0.002946  0.002946\n",
       "26     away_last5_GA_per_min_pk  0.002811  0.002811\n",
       "3    home_last5_pk_TOI_per_game -0.001906  0.001906\n",
       "5        home_Goalie_FenwickSV% -0.001876  0.001876\n",
       "34   home_last40_xGF_per_min_pp  0.001713  0.001713\n",
       "39   away_last40_xGF_per_min_pp -0.001619  0.001619"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_coef = pd.DataFrame(list(zip(X_train.columns, log_cv.best_estimator_[1].coef_[0])), columns = ['Feature', 'Coef'] )\n",
    "log_coef['Coef_abs'] = abs(log_coef['Coef'])\n",
    "log_coef.sort_values('Coef_abs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Game Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run some models using only the rolling 40 game team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:18:06.525933Z",
     "start_time": "2021-05-07T22:18:06.490814Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:18:30.478163Z",
     "start_time": "2021-05-07T22:18:30.473773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
       "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
       "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
       "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
       "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
       "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
       "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
       "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
       "       'home_Rating.A.Pre', 'away_Rating.A.Pre', 'B2B_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:04.007807Z",
     "start_time": "2021-05-07T22:20:04.003451Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features =['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
    "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
    "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
    "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
    "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
    "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
    "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
    "       'home_Rating.A.Pre', 'away_Rating.A.Pre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.004644Z",
     "start_time": "2021-05-07T22:20:04.999111Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.572777Z",
     "start_time": "2021-05-07T22:20:05.569772Z"
    }
   },
   "outputs": [],
   "source": [
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 1, 10],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv_40 = GridSearchCV(log_40_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:09.679038Z",
     "start_time": "2021-05-07T22:20:06.429450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:16.590632Z",
     "start_time": "2021-05-05T14:55:16.557290Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672521</td>\n",
       "      <td>-0.678186</td>\n",
       "      <td>-0.674674</td>\n",
       "      <td>-0.669348</td>\n",
       "      <td>-0.674081</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672520</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>-0.674673</td>\n",
       "      <td>-0.669355</td>\n",
       "      <td>-0.674082</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675375</td>\n",
       "      <td>-0.672548</td>\n",
       "      <td>-0.678078</td>\n",
       "      <td>-0.674946</td>\n",
       "      <td>-0.669716</td>\n",
       "      <td>-0.674133</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>3</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674011</td>\n",
       "      <td>-0.672891</td>\n",
       "      <td>-0.678995</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.671304</td>\n",
       "      <td>-0.674360</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>4</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674061</td>\n",
       "      <td>-0.672896</td>\n",
       "      <td>-0.679035</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.671252</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674062</td>\n",
       "      <td>-0.672900</td>\n",
       "      <td>-0.679034</td>\n",
       "      <td>-0.674562</td>\n",
       "      <td>-0.671250</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673682</td>\n",
       "      <td>-0.672968</td>\n",
       "      <td>-0.679327</td>\n",
       "      <td>-0.674495</td>\n",
       "      <td>-0.671486</td>\n",
       "      <td>-0.674391</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>7</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673574</td>\n",
       "      <td>-0.673067</td>\n",
       "      <td>-0.679649</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.672060</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>8</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.021284</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673579</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679654</td>\n",
       "      <td>-0.674596</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>9</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673578</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679656</td>\n",
       "      <td>-0.674598</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674591</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>10</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4        0.014693      0.001130         0.007716        0.000719   \n",
       "5        0.017283      0.000292         0.006951        0.000118   \n",
       "3        0.014061      0.000746         0.008523        0.001029   \n",
       "9        0.014426      0.000387         0.006950        0.000158   \n",
       "11       0.020913      0.000814         0.007221        0.000453   \n",
       "10       0.015567      0.000349         0.007100        0.000190   \n",
       "12       0.022668      0.001238         0.007185        0.000171   \n",
       "15       0.015133      0.000416         0.007112        0.000265   \n",
       "17       0.021284      0.000212         0.007193        0.000235   \n",
       "16       0.016655      0.000304         0.006913        0.000190   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "9                          0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "12                           1                                   None   \n",
       "15                           1                                   None   \n",
       "17                           1                                   None   \n",
       "16                           1                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "11                                l2                        newton-cg   \n",
       "10                                l2                            lbfgs   \n",
       "12                                l1                        liblinear   \n",
       "15                                l2                        liblinear   \n",
       "17                                l2                        newton-cg   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                  -0.675677                 -0.672521   \n",
       "5                  -0.675677                 -0.672520   \n",
       "3                  -0.675375                 -0.672548   \n",
       "9                  -0.674011                 -0.672891   \n",
       "11                 -0.674061                 -0.672896   \n",
       "10                 -0.674062                 -0.672900   \n",
       "12                 -0.673682                 -0.672968   \n",
       "15                 -0.673574                 -0.673067   \n",
       "17                 -0.673579                 -0.673068   \n",
       "16                 -0.673578                 -0.673068   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                  -0.678186                 -0.674674   \n",
       "5                  -0.678187                 -0.674673   \n",
       "3                  -0.678078                 -0.674946   \n",
       "9                  -0.678995                 -0.674600   \n",
       "11                 -0.679035                 -0.674563   \n",
       "10                 -0.679034                 -0.674562   \n",
       "12                 -0.679327                 -0.674495   \n",
       "15                 -0.679649                 -0.674600   \n",
       "17                 -0.679654                 -0.674596   \n",
       "16                 -0.679656                 -0.674598   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                  -0.669348               -0.674081               0.002986   \n",
       "5                  -0.669355               -0.674082               0.002984   \n",
       "3                  -0.669716               -0.674133               0.002821   \n",
       "9                  -0.671304               -0.674360               0.002575   \n",
       "11                 -0.671252               -0.674362               0.002600   \n",
       "10                 -0.671250               -0.674362               0.002599   \n",
       "12                 -0.671486               -0.674391               0.002659   \n",
       "15                 -0.672060               -0.674590               0.002659   \n",
       "17                 -0.672055               -0.674590               0.002661   \n",
       "16                 -0.672055               -0.674591               0.002662   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                        1              0.570667              0.593333   \n",
       "5                        2              0.570667              0.593333   \n",
       "3                        3              0.568000              0.596000   \n",
       "9                        4              0.570667              0.584000   \n",
       "11                       5              0.568000              0.582667   \n",
       "10                       6              0.568000              0.582667   \n",
       "12                       7              0.572000              0.580000   \n",
       "15                       8              0.573333              0.582667   \n",
       "17                       9              0.573333              0.582667   \n",
       "16                      10              0.573333              0.582667   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4               0.592000              0.569333              0.581333   \n",
       "5               0.592000              0.569333              0.581333   \n",
       "3               0.592000              0.573333              0.584000   \n",
       "9               0.593333              0.578667              0.576000   \n",
       "11              0.593333              0.581333              0.577333   \n",
       "10              0.593333              0.581333              0.577333   \n",
       "12              0.590667              0.577333              0.576000   \n",
       "15              0.585333              0.574667              0.572000   \n",
       "17              0.585333              0.574667              0.572000   \n",
       "16              0.585333              0.574667              0.572000   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4             0.581333           0.010154                   3  \n",
       "5             0.581333           0.010154                   3  \n",
       "3             0.582667           0.010667                   2  \n",
       "9             0.580533           0.007710                   5  \n",
       "11            0.580533           0.008202                   5  \n",
       "10            0.580533           0.008202                   5  \n",
       "12            0.579200           0.006288                   9  \n",
       "15            0.577600           0.005360                  10  \n",
       "17            0.577600           0.005360                  10  \n",
       "16            0.577600           0.005360                  10  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_results = pd.DataFrame(log_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:01:02.159647Z",
     "start_time": "2021-05-05T15:01:02.147007Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>0.167769</td>\n",
       "      <td>0.167769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>0.128198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>away_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.127853</td>\n",
       "      <td>0.127853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_last40_pp_TOI_per_game</td>\n",
       "      <td>-0.120332</td>\n",
       "      <td>0.120332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>0.092343</td>\n",
       "      <td>0.092343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>away_Goalie_HDCSV%</td>\n",
       "      <td>-0.069468</td>\n",
       "      <td>0.069468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>away_B2B</td>\n",
       "      <td>-0.069465</td>\n",
       "      <td>0.069465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_last40_xGA_per_min_pk</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.068317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>-0.058731</td>\n",
       "      <td>0.058731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_B2B</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.057827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_Goalie_GSAx/60</td>\n",
       "      <td>-0.057538</td>\n",
       "      <td>0.057538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>-0.053817</td>\n",
       "      <td>0.053817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>-0.049700</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.048419</td>\n",
       "      <td>0.048419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.047514</td>\n",
       "      <td>0.047514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>0.044988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_last40_pp_TOI_per_game</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.042033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last_40_GF%_5v5</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.037274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.031585</td>\n",
       "      <td>0.031585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>0.028338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.017327</td>\n",
       "      <td>0.017327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.014227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>0.008973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature      Coef  Coef_abs\n",
       "10        home_last_40_xGF%_5v5  0.167769  0.167769\n",
       "16         away_last_40_FF%_5v5  0.128198  0.128198\n",
       "22  away_last40_pk_TOI_per_game -0.127853  0.127853\n",
       "20  away_last40_pp_TOI_per_game -0.120332  0.120332\n",
       "9          home_last_40_GF%_5v5  0.092343  0.092343\n",
       "5            away_Goalie_HDCSV% -0.069468  0.069468\n",
       "7                      away_B2B -0.069465  0.069465\n",
       "23   away_last40_xGA_per_min_pk  0.068317  0.068317\n",
       "4           away_Goalie_GSAx/60 -0.058731  0.058731\n",
       "6                      home_B2B  0.057827  0.057827\n",
       "1           home_Goalie_GSAx/60 -0.057538  0.057538\n",
       "2            home_Goalie_HDCSV% -0.053817  0.053817\n",
       "11             home_last_40_SH% -0.049700  0.049700\n",
       "13   home_last40_xGF_per_min_pp -0.048419  0.048419\n",
       "21   away_last40_xGF_per_min_pp -0.047514  0.047514\n",
       "8          home_last_40_FF%_5v5 -0.044988  0.044988\n",
       "12  home_last40_pp_TOI_per_game  0.042033  0.042033\n",
       "17         away_last_40_GF%_5v5  0.037274  0.037274\n",
       "14  home_last40_pk_TOI_per_game -0.031585  0.031585\n",
       "0        home_Goalie_FenwickSV%  0.028338  0.028338\n",
       "3        away_Goalie_FenwickSV%  0.019926  0.019926\n",
       "15   home_last40_xGA_per_min_pk -0.017327  0.017327\n",
       "18        away_last_40_xGF%_5v5  0.014227  0.014227\n",
       "19             away_last_40_SH% -0.008973  0.008973"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_coef = pd.DataFrame(list(zip(X_train.columns, log_cv_40.best_estimator_[1].coef_[0])), columns = ['Feature', 'Coef'] )\n",
    "log_40_coef['Coef_abs'] = abs(log_40_coef['Coef'])\n",
    "log_40_coef.sort_values('Coef_abs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:30.131508Z",
     "start_time": "2021-05-07T22:20:30.124084Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "ada_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [.01, .1, 1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv_40 = GridSearchCV(ada_40_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:18.508263Z",
     "start_time": "2021-05-07T22:20:30.956755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                          'home_Rating.A.Pre',\n",
       "                                                                          'away_Rating.A.Pre']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.01, 0.1, 1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.103033Z",
     "start_time": "2021-05-07T22:34:19.075177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.925709</td>\n",
       "      <td>0.638357</td>\n",
       "      <td>2.145070</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.678507</td>\n",
       "      <td>-0.672283</td>\n",
       "      <td>-0.677155</td>\n",
       "      <td>-0.678249</td>\n",
       "      <td>-0.672888</td>\n",
       "      <td>-0.675816</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.599162</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.573707</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.680541</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-0.678631</td>\n",
       "      <td>-0.675985</td>\n",
       "      <td>-0.678217</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.575654</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.559270</td>\n",
       "      <td>0.155653</td>\n",
       "      <td>2.273125</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.681224</td>\n",
       "      <td>-0.674573</td>\n",
       "      <td>-0.677922</td>\n",
       "      <td>-0.680711</td>\n",
       "      <td>-0.676703</td>\n",
       "      <td>-0.678227</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.204704</td>\n",
       "      <td>0.113358</td>\n",
       "      <td>2.208953</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682440</td>\n",
       "      <td>-0.679579</td>\n",
       "      <td>-0.682155</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.679784</td>\n",
       "      <td>-0.681057</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.574616</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.567559</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.681519</td>\n",
       "      <td>-0.684073</td>\n",
       "      <td>-0.683125</td>\n",
       "      <td>-0.681574</td>\n",
       "      <td>-0.682894</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.579847</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.212874</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>1.813163</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688093</td>\n",
       "      <td>-0.687867</td>\n",
       "      <td>-0.688317</td>\n",
       "      <td>-0.688659</td>\n",
       "      <td>-0.686559</td>\n",
       "      <td>-0.687899</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.057093</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691571</td>\n",
       "      <td>-0.691189</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>-0.691591</td>\n",
       "      <td>-0.691297</td>\n",
       "      <td>-0.691459</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.575376</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691897</td>\n",
       "      <td>-0.691110</td>\n",
       "      <td>-0.702624</td>\n",
       "      <td>-0.690811</td>\n",
       "      <td>-0.691471</td>\n",
       "      <td>-0.693583</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>8</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      37.925709      0.638357         2.145070        0.033783   \n",
       "4       0.112370      0.003209         0.015125        0.000329   \n",
       "3      37.559270      0.155653         2.273125        0.004889   \n",
       "1      38.204704      0.113358         2.208953        0.011606   \n",
       "5       0.114122      0.000884         0.014839        0.000070   \n",
       "2      31.212874      0.111837         1.813163        0.012767   \n",
       "6       0.122421      0.057093         0.015021        0.000210   \n",
       "7       0.232039      0.006414         0.015102        0.000146   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0  SVC(kernel='linear', probability=True)                     0.01   \n",
       "4                    LogisticRegression()                     0.01   \n",
       "3  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "6                    LogisticRegression()                        1   \n",
       "7                    LogisticRegression()                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "4                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "3                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "7                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.678507                 -0.672283   \n",
       "4                 -0.680541                 -0.676259   \n",
       "3                 -0.681224                 -0.674573   \n",
       "1                 -0.682440                 -0.679579   \n",
       "5                 -0.684177                 -0.681519   \n",
       "2                 -0.688093                 -0.687867   \n",
       "6                 -0.691571                 -0.691189   \n",
       "7                 -0.691897                 -0.691110   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.677155                 -0.678249   \n",
       "4                 -0.679670                 -0.678631   \n",
       "3                 -0.677922                 -0.680711   \n",
       "1                 -0.682155                 -0.681328   \n",
       "5                 -0.684073                 -0.683125   \n",
       "2                 -0.688317                 -0.688659   \n",
       "6                 -0.691649                 -0.691591   \n",
       "7                 -0.702624                 -0.690811   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.672888               -0.675816               0.002684   \n",
       "4                 -0.675985               -0.678217               0.001817   \n",
       "3                 -0.676703               -0.678227               0.002487   \n",
       "1                 -0.679784               -0.681057               0.001183   \n",
       "5                 -0.681574               -0.682894               0.001160   \n",
       "2                 -0.686559               -0.687899               0.000719   \n",
       "6                 -0.691297               -0.691459               0.000182   \n",
       "7                 -0.691471               -0.693583               0.004535   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.550907              0.577406   \n",
       "4                       2              0.569038              0.588563   \n",
       "3                       3              0.567643              0.595537   \n",
       "1                       4              0.564854              0.574616   \n",
       "5                       5              0.560669              0.588563   \n",
       "2                       6              0.543933              0.543933   \n",
       "6                       7              0.559275              0.594142   \n",
       "7                       8              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.599162              0.561453              0.579609   \n",
       "4              0.569832              0.567039              0.583799   \n",
       "3              0.608939              0.571229              0.572626   \n",
       "1              0.564246              0.568436              0.565642   \n",
       "5              0.597765              0.569832              0.582402   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "6              0.589385              0.564246              0.569832   \n",
       "7              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.573707           0.016532                   5  \n",
       "4            0.575654           0.008774                   3  \n",
       "3            0.583195           0.016198                   1  \n",
       "1            0.567559           0.003809                   6  \n",
       "5            0.579847           0.013203                   2  \n",
       "2            0.543830           0.000517                   7  \n",
       "6            0.575376           0.013873                   4  \n",
       "7            0.543830           0.000517                   7  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_40_results = pd.DataFrame(ada_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Rolling Game Features With Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.696296Z",
     "start_time": "2021-05-07T22:34:19.667544Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:42:10.436891Z",
     "start_time": "2021-05-05T23:42:10.432366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 104)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:20.363708Z",
     "start_time": "2021-05-07T22:34:20.359232Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "rfecv = RFECV(estimator= LogisticRegression(max_iter =10000, penalty = 'l2', solver='liblinear', C=.1), step=1, scoring='accuracy')\n",
    "rfecv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:21.913288Z",
     "start_time": "2021-05-07T22:34:21.029546Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_last_40_FF%_5v5',\n",
       "                                                   'home_last_40_GF%_5v5',\n",
       "                                                   'home_last_40_xGF%_5v5',\n",
       "                                                   'home_last_40_SH%',\n",
       "                                                   'home_last40_xGF_per_min_pp',\n",
       "                                                   'home_last40_GF_per_min_pp',\n",
       "                                                   'home_last40_xGA_per_min_pk',\n",
       "                                                   'home_last40_GA_per_min_pk',\n",
       "                                                   'away_last_40_FF%_5v5',\n",
       "                                                   'away_...\n",
       "                                                   'home_Goalie_FenwickSV%',\n",
       "                                                   'home_Goalie_GSAx/60',\n",
       "                                                   'home_Goalie_HDCSV%',\n",
       "                                                   'away_Goalie_FenwickSV%',\n",
       "                                                   'away_Goalie_GSAx/60',\n",
       "                                                   'away_Goalie_HDCSV%',\n",
       "                                                   'home_Rating.A.Pre',\n",
       "                                                   'away_Rating.A.Pre']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['B2B_Status'])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(estimator=LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:22.591913Z",
     "start_time": "2021-05-07T22:34:22.588917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:23.322200Z",
     "start_time": "2021-05-07T22:34:23.318966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 13,  8, 18, 14,  9,  6,  2, 20, 17,  7, 10, 12, 16, 15,  1,\n",
       "        1,  5, 19, 11,  4,  1,  1,  1,  1,  1,  3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.000125Z",
     "start_time": "2021-05-07T22:34:23.992070Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last3_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>home_last_20_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_last_30_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_Rating.A.Pre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_10_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last10_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_last40_GF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  Ranking\n",
       "0    home_last3_xGF_per_min_pp        1\n",
       "1       home_Goalie_FenwickSV%        1\n",
       "25        home_last_20_GF%_5v5        1\n",
       "24        away_last_30_GF%_5v5        1\n",
       "23           away_Rating.A.Pre        1\n",
       "22        home_last_10_FF%_5v5        1\n",
       "17  away_last10_xGF_per_min_pp        1\n",
       "16       home_last_40_xGF%_5v5        1\n",
       "26   away_last40_GF_per_min_pp        1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_results = pd.DataFrame(list(zip(X_train.columns, rfecv_pipeline[1].ranking_)), columns = ['Feature', 'Ranking']).sort_values('Ranking')\n",
    "rfecv_results.head(rfecv_pipeline[1].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.669318Z",
     "start_time": "2021-05-07T22:34:24.665437Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_last3_xGF_per_min_pp',\n",
       " 'home_Goalie_FenwickSV%',\n",
       " 'home_last_20_GF%_5v5',\n",
       " 'away_last_30_GF%_5v5',\n",
       " 'away_Rating.A.Pre',\n",
       " 'home_last_10_FF%_5v5',\n",
       " 'away_last10_xGF_per_min_pp',\n",
       " 'home_last_40_xGF%_5v5',\n",
       " 'away_last40_GF_per_min_pp']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = list(rfecv_results.iloc[:rfecv_pipeline[1].n_features_,0])\n",
    "rfecv_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.349708Z",
     "start_time": "2021-05-07T22:34:25.324672Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.925726Z",
     "start_time": "2021-05-07T22:34:25.921927Z"
    }
   },
   "outputs": [],
   "source": [
    "log_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None]}\n",
    "\n",
    "log_cv_all = GridSearchCV(log_rfecv_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:27.929642Z",
     "start_time": "2021-05-07T22:34:26.511858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_all.fit(X_train[rfecv_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:28.552604Z",
     "start_time": "2021-05-07T22:34:28.528948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.676186</td>\n",
       "      <td>-0.674550</td>\n",
       "      <td>-0.672781</td>\n",
       "      <td>-0.673968</td>\n",
       "      <td>-0.676196</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.575661</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682996</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>3</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682877</td>\n",
       "      <td>-0.675304</td>\n",
       "      <td>-0.675674</td>\n",
       "      <td>-0.674005</td>\n",
       "      <td>-0.673641</td>\n",
       "      <td>-0.676300</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.576497</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676038</td>\n",
       "      <td>-0.675903</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673425</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>5</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676037</td>\n",
       "      <td>-0.675902</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673426</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684022</td>\n",
       "      <td>-0.676034</td>\n",
       "      <td>-0.675904</td>\n",
       "      <td>-0.673109</td>\n",
       "      <td>-0.673453</td>\n",
       "      <td>-0.676504</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>7</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684239</td>\n",
       "      <td>-0.676227</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>-0.672984</td>\n",
       "      <td>-0.673468</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>8</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577057</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 20, 'logisticregress...</td>\n",
       "      <td>-0.684245</td>\n",
       "      <td>-0.676233</td>\n",
       "      <td>-0.675967</td>\n",
       "      <td>-0.672985</td>\n",
       "      <td>-0.673465</td>\n",
       "      <td>-0.676579</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>9</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576778</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684249</td>\n",
       "      <td>-0.676236</td>\n",
       "      <td>-0.675975</td>\n",
       "      <td>-0.672987</td>\n",
       "      <td>-0.673460</td>\n",
       "      <td>-0.676582</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>10</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        0.006220      0.000130         0.003461        0.000075   \n",
       "4        0.007108      0.000076         0.003425        0.000014   \n",
       "5        0.013248      0.001218         0.004097        0.000478   \n",
       "3        0.005481      0.000175         0.003253        0.000013   \n",
       "10       0.007337      0.000301         0.003419        0.000033   \n",
       "11       0.011399      0.000528         0.003445        0.000016   \n",
       "9        0.005766      0.000048         0.003394        0.000016   \n",
       "12       0.006644      0.000130         0.003406        0.000029   \n",
       "18       0.006527      0.000311         0.003445        0.000019   \n",
       "16       0.007279      0.000221         0.003613        0.000365   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "6                          0.1                                   None   \n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "12                          10                                   None   \n",
       "18                          20                                   None   \n",
       "16                          10                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "6                                 l1                        liblinear   \n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "9                                 l2                        liblinear   \n",
       "12                                l1                        liblinear   \n",
       "18                                l1                        liblinear   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 20, 'logisticregress...   \n",
       "16  {'logisticregression__C': 10, 'logisticregress...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.683493                 -0.676186   \n",
       "4                  -0.682996                 -0.675241   \n",
       "5                  -0.682997                 -0.675241   \n",
       "3                  -0.682877                 -0.675304   \n",
       "10                 -0.684044                 -0.676038   \n",
       "11                 -0.684044                 -0.676037   \n",
       "9                  -0.684022                 -0.676034   \n",
       "12                 -0.684239                 -0.676227   \n",
       "18                 -0.684245                 -0.676233   \n",
       "16                 -0.684249                 -0.676236   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.674550                 -0.672781   \n",
       "4                  -0.675597                 -0.673949   \n",
       "5                  -0.675597                 -0.673949   \n",
       "3                  -0.675674                 -0.674005   \n",
       "10                 -0.675903                 -0.673108   \n",
       "11                 -0.675902                 -0.673108   \n",
       "9                  -0.675904                 -0.673109   \n",
       "12                 -0.675958                 -0.672984   \n",
       "18                 -0.675967                 -0.672985   \n",
       "16                 -0.675975                 -0.672987   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.673968               -0.676196               0.003810   \n",
       "4                  -0.673375               -0.676232               0.003479   \n",
       "5                  -0.673375               -0.676232               0.003479   \n",
       "3                  -0.673641               -0.676300               0.003376   \n",
       "10                 -0.673425               -0.676503               0.003961   \n",
       "11                 -0.673426               -0.676503               0.003961   \n",
       "9                  -0.673453               -0.676504               0.003948   \n",
       "12                 -0.673468               -0.676575               0.004045   \n",
       "18                 -0.673465               -0.676579               0.004046   \n",
       "16                 -0.673460               -0.676582               0.004048   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.550907              0.581590   \n",
       "4                        2              0.546722              0.585774   \n",
       "5                        3              0.546722              0.585774   \n",
       "3                        4              0.555091              0.584379   \n",
       "10                       5              0.549512              0.585774   \n",
       "11                       6              0.549512              0.585774   \n",
       "9                        7              0.546722              0.585774   \n",
       "12                       8              0.549512              0.585774   \n",
       "18                       9              0.548117              0.585774   \n",
       "16                      10              0.548117              0.584379   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.594972              0.574022              0.576816   \n",
       "4               0.596369              0.565642              0.581006   \n",
       "5               0.596369              0.565642              0.581006   \n",
       "3               0.587989              0.575419              0.579609   \n",
       "10              0.592179              0.578212              0.581006   \n",
       "11              0.592179              0.578212              0.581006   \n",
       "9               0.589385              0.579609              0.581006   \n",
       "12              0.589385              0.579609              0.581006   \n",
       "18              0.590782              0.578212              0.581006   \n",
       "16              0.590782              0.578212              0.581006   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.575661           0.014317                  17  \n",
       "4             0.575103           0.017297                  18  \n",
       "5             0.575103           0.017297                  18  \n",
       "3             0.576497           0.011518                  16  \n",
       "10            0.577337           0.014696                   1  \n",
       "11            0.577337           0.014696                   1  \n",
       "9             0.576499           0.015289                   5  \n",
       "12            0.577057           0.014204                   3  \n",
       "18            0.576778           0.014956                   4  \n",
       "16            0.576499           0.014798                   5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_all_results = pd.DataFrame(log_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.189755Z",
     "start_time": "2021-05-07T22:34:29.164773Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.784811Z",
     "start_time": "2021-05-07T22:34:29.780602Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [ .1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression(max_iter =10000, C=.01, penalty = 'l1', solver = 'liblinear')],}\n",
    "\n",
    "ada_cv_all = GridSearchCV(ada_rfecv_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:10.420059Z",
     "start_time": "2021-05-07T22:34:30.382762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression(C=0.01,\n",
       "                                                                    max_iter=10000,\n",
       "                                                                    penalty='l1',\n",
       "                                                                    solver='liblinear')],\n",
       "                         'ada__learning_rate': [0.1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:11.046731Z",
     "start_time": "2021-05-07T22:41:11.023674Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.347400</td>\n",
       "      <td>0.550717</td>\n",
       "      <td>2.137133</td>\n",
       "      <td>0.103863</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683982</td>\n",
       "      <td>-0.678475</td>\n",
       "      <td>-0.679754</td>\n",
       "      <td>-0.682702</td>\n",
       "      <td>-0.681416</td>\n",
       "      <td>-0.681266</td>\n",
       "      <td>1.976734e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.567836</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.946891</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>2.113290</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684418</td>\n",
       "      <td>-0.682521</td>\n",
       "      <td>-0.682660</td>\n",
       "      <td>-0.681958</td>\n",
       "      <td>-0.682048</td>\n",
       "      <td>-0.682721</td>\n",
       "      <td>8.898324e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.560581</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      32.347400      0.550717         2.137133        0.103863   \n",
       "0      32.946891      0.287765         2.113290        0.028486   \n",
       "2       0.055528      0.000309         0.010574        0.000029   \n",
       "3       0.055622      0.000853         0.010454        0.000019   \n",
       "\n",
       "                           param_ada__base_estimator param_ada__learning_rate  \\\n",
       "1             SVC(kernel='linear', probability=True)                       10   \n",
       "0             SVC(kernel='linear', probability=True)                      0.1   \n",
       "2  LogisticRegression(C=0.01, max_iter=10000, pen...                      0.1   \n",
       "3  LogisticRegression(C=0.01, max_iter=10000, pen...                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "2                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "3                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1                 -0.683982                 -0.678475   \n",
       "0                 -0.684418                 -0.682521   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "1                 -0.679754                 -0.682702   \n",
       "0                 -0.682660                 -0.681958   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1                 -0.681416               -0.681266           1.976734e-03   \n",
       "0                 -0.682048               -0.682721           8.898324e-04   \n",
       "2                 -0.693147               -0.693147           8.599751e-17   \n",
       "3                 -0.693147               -0.693147           8.599751e-17   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1                       1              0.556485              0.591353   \n",
       "0                       2              0.553696              0.564854   \n",
       "2                       3              0.456067              0.456067   \n",
       "3                       3              0.456067              0.456067   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "1              0.574022              0.561453              0.555866   \n",
       "0              0.571229              0.553073              0.560056   \n",
       "2              0.456704              0.456704              0.455307   \n",
       "3              0.456704              0.456704              0.455307   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "1            0.567836           0.013448                   1  \n",
       "0            0.560581           0.006866                   2  \n",
       "2            0.456170           0.000517                   3  \n",
       "3            0.456170           0.000517                   3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_all_results = pd.DataFrame(ada_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Model To Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will evaluate the best model iterations on the held out 2021 season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:46.889912Z",
     "start_time": "2021-05-05T23:12:46.887400Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {'cv accuracy': {}, 'cv log loss': {}, 'test accuracy': {}, 'test log_loss':{}}\n",
    "accuracy_list = []\n",
    "log_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:48.172913Z",
     "start_time": "2021-05-05T23:12:48.125070Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_5_40 = log_cv.predict(X_test)\n",
    "\n",
    "test_probs_5_40 = log_cv.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_5_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_5_40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:49.235114Z",
     "start_time": "2021-05-05T23:12:49.194454Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_40 = log_cv_40.predict(X_test)\n",
    "\n",
    "test_probs_40 = log_cv_40.predict_proba(X_test)\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:50.277948Z",
     "start_time": "2021-05-05T23:12:50.242895Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "test_preds_rfecv = log_cv_all.predict(X_test)\n",
    "\n",
    "test_probs_rfecv = log_cv_all.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_rfecv))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_rfecv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:13:13.589182Z",
     "start_time": "2021-05-05T23:13:10.000569Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test,ada_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:13:17.614125Z",
     "start_time": "2021-05-05T23:13:14.601780Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv_40.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, ada_cv_40.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:38.360192Z",
     "start_time": "2021-05-06T02:12:38.340495Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict['test accuracy'] = accuracy_list\n",
    "results_dict['test log_loss'] = log_loss_list\n",
    "models = ['5 and 40 log', '40 log', 'rfecv log', '5 and 40 ada', '40 ada']\n",
    "results_dict['cv accuracy'] = [log_results['mean_test_accuracy'][0], log_40_results['mean_test_accuracy'][0], log_all_results['mean_test_accuracy'][0], ada_results['mean_test_accuracy'][0], ada_40_results['mean_test_accuracy'][0]]\n",
    "results_dict['cv log loss'] = [log_cv.best_score_*-1, log_cv_40.best_score_*-1, log_cv_all.best_score_*-1, ada_cv.best_score_*-1, ada_cv_40.best_score_*-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:40.320625Z",
     "start_time": "2021-05-06T02:12:40.316596Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, index = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model was logistic regression with the rolling 5 and 40 features on the test data. Interestingly, this was the 4th best model on the CV training data set though it did have the best CV accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:41.708494Z",
     "start_time": "2021-05-06T02:12:41.698849Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv accuracy</th>\n",
       "      <th>cv log loss</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>test log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5 and 40 log</th>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.677735</td>\n",
       "      <td>0.597205</td>\n",
       "      <td>0.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 log</th>\n",
       "      <td>0.580267</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0.593393</td>\n",
       "      <td>0.657240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 ada</th>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>0.606099</td>\n",
       "      <td>0.660695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv log</th>\n",
       "      <td>0.571733</td>\n",
       "      <td>0.675783</td>\n",
       "      <td>0.590851</td>\n",
       "      <td>0.665077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 ada</th>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.681288</td>\n",
       "      <td>0.560356</td>\n",
       "      <td>0.678121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cv accuracy  cv log loss  test accuracy  test log_loss\n",
       "5 and 40 log     0.581067     0.677735       0.597205       0.657201\n",
       "40 log           0.580267     0.674081       0.593393       0.657240\n",
       "40 ada           0.579467     0.675472       0.606099       0.660695\n",
       "rfecv log        0.571733     0.675783       0.590851       0.665077\n",
       "5 and 40 ada     0.562667     0.681288       0.560356       0.678121"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('test log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To further improve the models I would like to take the following next steps\n",
    "\n",
    "- Train a neural network model\n",
    "- Categorize B2B better\n",
    "- Include team ELO feature\n",
    "- Try linear weightings in rolling features\n",
    "- Increase goalie games\n",
    "- Add prior year goalie GAR feature\n",
    "- Add Team HDSC % feature\n",
    "- Add more seasons to training set\n",
    "- Compare against historical implied odds from a bookmaker\n",
    "- Adjust ineperienced goalie imputed stats and exclude 2021 season to avoid data leakage on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
