{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Game Prediction Modeling\n",
    "by Gary Schwaeber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sport betting becoming increasingly popular and mainstream I believe that data science can be used to make superior decisions over gut intuitions. In this notebook I will attempt to train logistic regression, ada boost, and gradient boosting models in an attempt to make the best possible game prediction model. I will train my models and tune model hyperparemetres using game results from seasons '2017-2018', '2018-2019', '2019-2020'. Then I will predict on held out games from the current 2021 season and evaluate my model. There are currently a handful of public models whose log loss on the current season's games is being [tracked](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/) on which I can compare the quality of my model to. The score I will look to optimize is log loss, however, I will also review accuracy scores due to their interpretability.\n",
    "\n",
    "Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value (0 or 1 in case of binary classification). The more the predicted probability diverges from the actual value, the higher is the log-loss value. [Source](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:28:34.093783Z",
     "start_time": "2021-05-05T14:28:34.083346Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import hockey_scraper\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:28:38.175359Z",
     "start_time": "2021-05-04T21:28:38.027713Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_games_multirolling_SVA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:28:38.813086Z",
     "start_time": "2021-05-04T21:28:38.797651Z"
    }
   },
   "outputs": [],
   "source": [
    "conditions = [((df['date'] >= '2017-10-04') & (df['date'] <= '2018-04-08')),\n",
    "              ((df['date'] >= '2018-10-03') & (df['date'] <= '2019-04-06')),\n",
    "              ((df['date'] >= '2019-10-02') & (df['date'] <= '2020-03-12')),\n",
    "              ((df['date'] >= '2021-01-13') & (df['date'] <= '2021-04-29'))\n",
    "             ]\n",
    ", \n",
    "choices = ['2017-2018',\n",
    "           '2018-2019',\n",
    "           '2019-2020',\n",
    "           '2020-2021']\n",
    "           \n",
    "    \n",
    "\n",
    "df['Season'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:40:16.486905Z",
     "start_time": "2021-05-05T15:40:16.474687Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature columns for different rolling intervals\n",
    "r3 = ['home_B2B', 'away_B2B', 'home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_last_3_FF%_5v5',\n",
    " 'home_last_3_GF%_5v5',\n",
    " 'home_last_3_xGF%_5v5',\n",
    " 'home_last_3_SH%',\n",
    " 'home_last3_pp_TOI_per_game',\n",
    " 'home_last3_xGF_per_min_pp',\n",
    " 'home_last3_pk_TOI_per_game',\n",
    " 'home_last3_xGA_per_min_pk', 'away_last_3_FF%_5v5',\n",
    " 'away_last_3_GF%_5v5',\n",
    " 'away_last_3_xGF%_5v5',\n",
    " 'away_last_3_SH%',\n",
    " 'away_last3_pp_TOI_per_game',\n",
    " 'away_last3_xGF_per_min_pp',\n",
    " 'away_last3_pk_TOI_per_game',\n",
    " 'away_last3_xGA_per_min_pk']\n",
    "r5 =['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_B2B', 'away_B2B', 'home_last_5_FF%_5v5',\n",
    " 'home_last_5_GF%_5v5',\n",
    " 'home_last_5_xGF%_5v5',\n",
    " 'home_last_5_SH%',\n",
    " 'home_last5_pp_TOI_per_game',\n",
    " 'home_last5_xGF_per_min_pp',\n",
    " 'home_last5_pk_TOI_per_game',\n",
    " 'home_last5_xGA_per_min_pk', 'away_last_5_FF%_5v5',\n",
    " 'away_last_5_GF%_5v5',\n",
    " 'away_last_5_xGF%_5v5',\n",
    " 'away_last_5_SH%',\n",
    " 'away_last5_pp_TOI_per_game',\n",
    " 'away_last5_xGF_per_min_pp',\n",
    " 'away_last5_pk_TOI_per_game',\n",
    " 'away_last5_xGA_per_min_pk']\n",
    "r10 =['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_B2B', 'away_B2B', 'home_last_10_FF%_5v5',\n",
    " 'home_last_10_GF%_5v5',\n",
    " 'home_last_10_xGF%_5v5',\n",
    " 'home_last_10_SH%',\n",
    " 'home_last10_pp_TOI_per_game',\n",
    " 'home_last10_xGF_per_min_pp',\n",
    " 'home_last10_pk_TOI_per_game',\n",
    " 'home_last10_xGA_per_min_pk', 'away_last_10_FF%_5v5',\n",
    " 'away_last_10_GF%_5v5',\n",
    " 'away_last_10_xGF%_5v5',\n",
    " 'away_last_10_SH%',\n",
    " 'away_last10_pp_TOI_per_game',\n",
    " 'away_last10_xGF_per_min_pp',\n",
    " 'away_last10_pk_TOI_per_game',\n",
    " 'away_last10_xGA_per_min_pk']\n",
    "r20 = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_B2B', 'away_B2B',  'home_last_20_FF%_5v5',\n",
    " 'home_last_20_GF%_5v5',\n",
    " 'home_last_20_xGF%_5v5',\n",
    " 'home_last_20_SH%',\n",
    " 'home_last20_pp_TOI_per_game',\n",
    " 'home_last20_xGF_per_min_pp',\n",
    " 'home_last20_pk_TOI_per_game',\n",
    " 'home_last20_xGA_per_min_pk', 'away_last_20_FF%_5v5',\n",
    " 'away_last_20_GF%_5v5',\n",
    " 'away_last_20_xGF%_5v5',\n",
    " 'away_last_20_SH%',\n",
    " 'away_last20_pp_TOI_per_game',\n",
    " 'away_last20_xGF_per_min_pp',\n",
    " 'away_last20_pk_TOI_per_game',\n",
    " 'away_last20_xGA_per_min_pk']\n",
    "r30 = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_B2B', 'away_B2B',  'home_last_30_FF%_5v5',\n",
    " 'home_last_30_GF%_5v5',\n",
    " 'home_last_30_xGF%_5v5',\n",
    " 'home_last_30_SH%',\n",
    " 'home_last30_pp_TOI_per_game',\n",
    " 'home_last30_xGF_per_min_pp',\n",
    " 'home_last30_pk_TOI_per_game',\n",
    " 'home_last30_xGA_per_min_pk', 'away_last_30_FF%_5v5',\n",
    " 'away_last_30_GF%_5v5',\n",
    " 'away_last_30_xGF%_5v5',\n",
    " 'away_last_30_SH%',\n",
    " 'away_last30_pp_TOI_per_game',\n",
    " 'away_last30_xGF_per_min_pp',\n",
    " 'away_last30_pk_TOI_per_game',\n",
    " 'away_last30_xGA_per_min_pk']\n",
    "r40 = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', 'home_B2B', 'away_B2B',\n",
    "'home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_pp_TOI_per_game',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_pk_TOI_per_game',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    "'away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_pp_TOI_per_game',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_pk_TOI_per_game',\n",
    " 'away_last40_xGA_per_min_pk']\n",
    "all_r = list(set(r3+r5+r10+r20+r30+r40))\n",
    "\n",
    "r3_30 =list(set(r3+r30))\n",
    "r5_30 = list(set(r5+r30))\n",
    "r10_30 = list(set(r10+r30))\n",
    "r_3_5_30 = list(set(r3+r5+r30))\n",
    "r_5_20 = list(set(r5+r20))\n",
    "r_5_40 = list(set(r5+r40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model will predict that every home team wins their game and that the probability of that is the ratio of games the home team has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:30:07.909715Z",
     "start_time": "2021-05-05T23:30:07.902593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.541458\n",
       "0    0.458542\n",
       "Name: Home_Team_Won, dtype: float64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Home_Team_Won'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:28:30.406075Z",
     "start_time": "2021-05-05T23:28:30.399270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5414581066376496"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = np.ones(df.shape[0])\n",
    "accuracy_score(df['Home_Team_Won'],baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:32:50.092794Z",
     "start_time": "2021-05-05T23:32:50.083685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.689705681560888"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_probs = np.repeat(df['Home_Team_Won'].value_counts(normalize=True)[1], df.shape[0])\n",
    "\n",
    "log_loss(df['Home_Team_Won'], baseline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need to beat an accuracy score of 54.15% and a log loss of .6897, otherwise they are no better than just predicting the home team will win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling 5 and 40 game features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first set of models I will attempt using 5 and 40 game rolling features. These seemed like a good set based on the feature selection notebook. 40 games is currently the longest rolling runway I have currently for the team statistics. The 40 games stats intuitively provide the most smoothing of team data over the course of the season, while the 5 game stats may provide some insight on any streakiness or may cover recent developments that would affect short term team performances such as player injuries, trades coaching changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:49:05.116781Z",
     "start_time": "2021-05-04T21:49:05.082798Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:49:21.678731Z",
     "start_time": "2021-05-04T21:49:21.673527Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last_5_FF%_5v5', 'home_last5_xGF_per_min_pp',\n",
       "       'home_last40_pp_TOI_per_game', 'away_last40_pk_TOI_per_game',\n",
       "       'home_last5_pk_TOI_per_game', 'away_B2B', 'away_last40_xGF_per_min_pp',\n",
       "       'home_Goalie_GSAx/60', 'home_last_5_SH%', 'away_last5_pk_TOI_per_game',\n",
       "       'away_last_5_GF%_5v5', 'away_Goalie_GSAx/60', 'home_last_40_GF%_5v5',\n",
       "       'away_last_5_xGF%_5v5', 'home_B2B', 'away_last5_xGF_per_min_pp',\n",
       "       'home_last40_pk_TOI_per_game', 'away_last_40_SH%',\n",
       "       'away_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
       "       'home_Goalie_FenwickSV%', 'home_last5_xGA_per_min_pk',\n",
       "       'home_last_5_GF%_5v5', 'away_Goalie_HDCSV%', 'home_last_40_SH%',\n",
       "       'away_last_40_xGF%_5v5', 'away_last40_pp_TOI_per_game',\n",
       "       'home_last40_xGA_per_min_pk', 'home_last5_pp_TOI_per_game',\n",
       "       'away_last_5_FF%_5v5', 'away_last5_xGA_per_min_pk',\n",
       "       'home_last_40_FF%_5v5', 'away_last5_pp_TOI_per_game',\n",
       "       'home_last40_xGF_per_min_pp', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
       "       'away_last40_xGA_per_min_pk', 'away_Goalie_FenwickSV%',\n",
       "       'away_last_40_FF%_5v5', 'home_Goalie_HDCSV%'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:58:53.328282Z",
     "start_time": "2021-05-04T21:58:53.324021Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last_5_FF%_5v5', 'home_last5_xGF_per_min_pp',\n",
    "       'home_last40_pp_TOI_per_game', 'away_last40_pk_TOI_per_game',\n",
    "       'home_last5_pk_TOI_per_game', 'away_last40_xGF_per_min_pp',\n",
    "       'home_Goalie_GSAx/60', 'home_last_5_SH%', 'away_last5_pk_TOI_per_game',\n",
    "       'away_last_5_GF%_5v5', 'away_Goalie_GSAx/60', 'home_last_40_GF%_5v5',\n",
    "       'away_last_5_xGF%_5v5', 'away_last5_xGF_per_min_pp',\n",
    "       'home_last40_pk_TOI_per_game', 'away_last_40_SH%',\n",
    "       'away_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_5_GF%_5v5', 'away_Goalie_HDCSV%', 'home_last_40_SH%',\n",
    "       'away_last_40_xGF%_5v5', 'away_last40_pp_TOI_per_game',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_pp_TOI_per_game',\n",
    "       'away_last_5_FF%_5v5', 'away_last5_xGA_per_min_pk',\n",
    "       'home_last_40_FF%_5v5', 'away_last5_pp_TOI_per_game',\n",
    "       'home_last40_xGF_per_min_pp', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'away_last40_xGA_per_min_pk', 'away_Goalie_FenwickSV%',\n",
    "       'away_last_40_FF%_5v5', 'home_Goalie_HDCSV%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:50:13.172611Z",
     "start_time": "2021-05-04T21:50:13.131781Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>home_last40_pp_TOI_per_game</th>\n",
       "      <th>away_last40_pk_TOI_per_game</th>\n",
       "      <th>home_last5_pk_TOI_per_game</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>away_last5_pk_TOI_per_game</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>home_last40_pk_TOI_per_game</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>away_last40_pp_TOI_per_game</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last5_pp_TOI_per_game</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>away_last5_pp_TOI_per_game</th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.399869</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>5.328333</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>3.693333</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>-0.334940</td>\n",
       "      <td>9.426112</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>45.937500</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>50.127801</td>\n",
       "      <td>48.770492</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>4.923333</td>\n",
       "      <td>8.124451</td>\n",
       "      <td>51.399425</td>\n",
       "      <td>48.992719</td>\n",
       "      <td>0.932657</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>57.080799</td>\n",
       "      <td>0.872792</td>\n",
       "      <td>9.025236</td>\n",
       "      <td>49.339386</td>\n",
       "      <td>4.646667</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>52.562502</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>48.803377</td>\n",
       "      <td>5.893333</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>51.663405</td>\n",
       "      <td>6.967375</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>0.942629</td>\n",
       "      <td>49.991679</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.564205</td>\n",
       "      <td>0.143856</td>\n",
       "      <td>4.705417</td>\n",
       "      <td>4.928750</td>\n",
       "      <td>3.546667</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.205712</td>\n",
       "      <td>12.093988</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>49.927641</td>\n",
       "      <td>-0.138771</td>\n",
       "      <td>56.868932</td>\n",
       "      <td>51.204482</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>4.774167</td>\n",
       "      <td>8.420932</td>\n",
       "      <td>58.184556</td>\n",
       "      <td>51.954595</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>59.064609</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>9.060588</td>\n",
       "      <td>52.486645</td>\n",
       "      <td>4.315417</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>3.336667</td>\n",
       "      <td>46.882217</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>50.828439</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.124909</td>\n",
       "      <td>46.860987</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>0.945897</td>\n",
       "      <td>50.633643</td>\n",
       "      <td>0.869942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>4.682500</td>\n",
       "      <td>5.185417</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.312441</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>5.853333</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>4.233750</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>0.942539</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>0.891688</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>4.921667</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>6.283333</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>0.132248</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>0.940136</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.896450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>4.682500</td>\n",
       "      <td>5.185417</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.312441</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>5.853333</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>4.233750</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>0.942539</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>0.891688</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>4.921667</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>6.283333</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>0.132248</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>0.940136</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.896450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.316401</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>4.778333</td>\n",
       "      <td>5.305000</td>\n",
       "      <td>4.763333</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>-0.232180</td>\n",
       "      <td>9.804628</td>\n",
       "      <td>5.963333</td>\n",
       "      <td>56.272661</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>53.260259</td>\n",
       "      <td>49.941995</td>\n",
       "      <td>0.137242</td>\n",
       "      <td>4.379167</td>\n",
       "      <td>5.932286</td>\n",
       "      <td>45.246898</td>\n",
       "      <td>52.809227</td>\n",
       "      <td>0.932564</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>57.771883</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>7.970138</td>\n",
       "      <td>50.855171</td>\n",
       "      <td>5.571250</td>\n",
       "      <td>0.120913</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>51.909534</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>52.890654</td>\n",
       "      <td>5.173333</td>\n",
       "      <td>0.105738</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>6.524847</td>\n",
       "      <td>0.093779</td>\n",
       "      <td>0.940035</td>\n",
       "      <td>51.197815</td>\n",
       "      <td>0.852201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>52.626239</td>\n",
       "      <td>0.059924</td>\n",
       "      <td>5.620833</td>\n",
       "      <td>5.130833</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>0.112455</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>9.856137</td>\n",
       "      <td>4.503333</td>\n",
       "      <td>50.523013</td>\n",
       "      <td>-0.160907</td>\n",
       "      <td>50.702434</td>\n",
       "      <td>54.505170</td>\n",
       "      <td>0.168144</td>\n",
       "      <td>4.886667</td>\n",
       "      <td>6.774670</td>\n",
       "      <td>45.320701</td>\n",
       "      <td>47.185204</td>\n",
       "      <td>0.937551</td>\n",
       "      <td>0.112114</td>\n",
       "      <td>56.342957</td>\n",
       "      <td>0.855114</td>\n",
       "      <td>9.172687</td>\n",
       "      <td>51.722795</td>\n",
       "      <td>4.195000</td>\n",
       "      <td>0.103138</td>\n",
       "      <td>5.273333</td>\n",
       "      <td>52.471344</td>\n",
       "      <td>0.095041</td>\n",
       "      <td>48.478268</td>\n",
       "      <td>4.436667</td>\n",
       "      <td>0.107724</td>\n",
       "      <td>51.508227</td>\n",
       "      <td>7.141273</td>\n",
       "      <td>0.109875</td>\n",
       "      <td>0.932952</td>\n",
       "      <td>50.676962</td>\n",
       "      <td>0.891117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>43.058811</td>\n",
       "      <td>0.096857</td>\n",
       "      <td>4.900833</td>\n",
       "      <td>4.127083</td>\n",
       "      <td>5.073333</td>\n",
       "      <td>0.136510</td>\n",
       "      <td>-0.646591</td>\n",
       "      <td>12.419735</td>\n",
       "      <td>3.396667</td>\n",
       "      <td>70.421512</td>\n",
       "      <td>0.072030</td>\n",
       "      <td>47.486397</td>\n",
       "      <td>46.681034</td>\n",
       "      <td>0.091262</td>\n",
       "      <td>4.458333</td>\n",
       "      <td>7.861206</td>\n",
       "      <td>45.570087</td>\n",
       "      <td>47.911779</td>\n",
       "      <td>0.926621</td>\n",
       "      <td>0.165572</td>\n",
       "      <td>66.463680</td>\n",
       "      <td>0.860963</td>\n",
       "      <td>8.299737</td>\n",
       "      <td>42.816482</td>\n",
       "      <td>4.415417</td>\n",
       "      <td>0.116636</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>51.846709</td>\n",
       "      <td>0.095976</td>\n",
       "      <td>48.281854</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.115644</td>\n",
       "      <td>39.061033</td>\n",
       "      <td>6.831641</td>\n",
       "      <td>0.127148</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>46.900863</td>\n",
       "      <td>0.831615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>48.469552</td>\n",
       "      <td>0.102022</td>\n",
       "      <td>4.770833</td>\n",
       "      <td>4.755833</td>\n",
       "      <td>5.786667</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>-0.435356</td>\n",
       "      <td>11.374701</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>53.981623</td>\n",
       "      <td>0.135063</td>\n",
       "      <td>43.586998</td>\n",
       "      <td>45.388350</td>\n",
       "      <td>0.107551</td>\n",
       "      <td>4.810417</td>\n",
       "      <td>9.108824</td>\n",
       "      <td>58.458552</td>\n",
       "      <td>45.316488</td>\n",
       "      <td>0.928974</td>\n",
       "      <td>0.119585</td>\n",
       "      <td>51.856336</td>\n",
       "      <td>0.901024</td>\n",
       "      <td>7.231170</td>\n",
       "      <td>53.445722</td>\n",
       "      <td>4.307917</td>\n",
       "      <td>0.098068</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>47.912088</td>\n",
       "      <td>0.061953</td>\n",
       "      <td>48.711262</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>0.098096</td>\n",
       "      <td>43.516270</td>\n",
       "      <td>6.481567</td>\n",
       "      <td>0.122481</td>\n",
       "      <td>0.944050</td>\n",
       "      <td>53.247076</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>55.838089</td>\n",
       "      <td>0.086931</td>\n",
       "      <td>5.192083</td>\n",
       "      <td>5.041667</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.121545</td>\n",
       "      <td>-0.029116</td>\n",
       "      <td>9.257587</td>\n",
       "      <td>3.623333</td>\n",
       "      <td>49.006951</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>56.092965</td>\n",
       "      <td>51.102088</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4.855417</td>\n",
       "      <td>8.685066</td>\n",
       "      <td>51.541976</td>\n",
       "      <td>54.701218</td>\n",
       "      <td>0.942539</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>44.565217</td>\n",
       "      <td>0.868195</td>\n",
       "      <td>8.310378</td>\n",
       "      <td>50.256575</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>0.116725</td>\n",
       "      <td>4.463333</td>\n",
       "      <td>53.800952</td>\n",
       "      <td>0.247286</td>\n",
       "      <td>54.328835</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>0.108531</td>\n",
       "      <td>59.167117</td>\n",
       "      <td>9.050064</td>\n",
       "      <td>0.139438</td>\n",
       "      <td>0.935115</td>\n",
       "      <td>50.202661</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>46.028554</td>\n",
       "      <td>0.102724</td>\n",
       "      <td>3.902917</td>\n",
       "      <td>4.673750</td>\n",
       "      <td>5.043333</td>\n",
       "      <td>0.119628</td>\n",
       "      <td>0.211833</td>\n",
       "      <td>8.850640</td>\n",
       "      <td>5.180000</td>\n",
       "      <td>47.310888</td>\n",
       "      <td>-0.483024</td>\n",
       "      <td>46.737740</td>\n",
       "      <td>53.449905</td>\n",
       "      <td>0.135089</td>\n",
       "      <td>4.206250</td>\n",
       "      <td>7.043789</td>\n",
       "      <td>41.652718</td>\n",
       "      <td>50.940006</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.078519</td>\n",
       "      <td>68.025078</td>\n",
       "      <td>0.870482</td>\n",
       "      <td>6.290295</td>\n",
       "      <td>46.619035</td>\n",
       "      <td>4.973750</td>\n",
       "      <td>0.107340</td>\n",
       "      <td>4.283333</td>\n",
       "      <td>51.848135</td>\n",
       "      <td>0.130888</td>\n",
       "      <td>52.317060</td>\n",
       "      <td>7.343333</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>43.880455</td>\n",
       "      <td>8.420889</td>\n",
       "      <td>0.123669</td>\n",
       "      <td>0.929910</td>\n",
       "      <td>46.486492</td>\n",
       "      <td>0.881279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3750 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_last_5_FF%_5v5  home_last5_xGF_per_min_pp  \\\n",
       "0               52.399869                   0.079714   \n",
       "1               42.564205                   0.143856   \n",
       "2               60.511924                   0.113316   \n",
       "3               60.511924                   0.113316   \n",
       "4               54.316401                   0.118615   \n",
       "...                   ...                        ...   \n",
       "3790            52.626239                   0.059924   \n",
       "3791            43.058811                   0.096857   \n",
       "3792            48.469552                   0.102022   \n",
       "3793            55.838089                   0.086931   \n",
       "3794            46.028554                   0.102724   \n",
       "\n",
       "      home_last40_pp_TOI_per_game  away_last40_pk_TOI_per_game  \\\n",
       "0                        5.328333                     4.540000   \n",
       "1                        4.705417                     4.928750   \n",
       "2                        4.682500                     5.185417   \n",
       "3                        4.682500                     5.185417   \n",
       "4                        4.778333                     5.305000   \n",
       "...                           ...                          ...   \n",
       "3790                     5.620833                     5.130833   \n",
       "3791                     4.900833                     4.127083   \n",
       "3792                     4.770833                     4.755833   \n",
       "3793                     5.192083                     5.041667   \n",
       "3794                     3.902917                     4.673750   \n",
       "\n",
       "      home_last5_pk_TOI_per_game  away_last40_xGF_per_min_pp  \\\n",
       "0                       3.693333                    0.122400   \n",
       "1                       3.546667                    0.102018   \n",
       "2                       4.540000                    0.120843   \n",
       "3                       4.540000                    0.120843   \n",
       "4                       4.763333                    0.143998   \n",
       "...                          ...                         ...   \n",
       "3790                    4.210000                    0.112455   \n",
       "3791                    5.073333                    0.136510   \n",
       "3792                    5.786667                    0.122391   \n",
       "3793                    5.200000                    0.121545   \n",
       "3794                    5.043333                    0.119628   \n",
       "\n",
       "      home_Goalie_GSAx/60  home_last_5_SH%  away_last5_pk_TOI_per_game  \\\n",
       "0               -0.334940         9.426112                    3.070000   \n",
       "1                0.205712        12.093988                    4.966667   \n",
       "2                0.312441         8.478124                    5.853333   \n",
       "3                0.312441         8.478124                    5.853333   \n",
       "4               -0.232180         9.804628                    5.963333   \n",
       "...                   ...              ...                         ...   \n",
       "3790            -0.004131         9.856137                    4.503333   \n",
       "3791            -0.646591        12.419735                    3.396667   \n",
       "3792            -0.435356        11.374701                    3.583333   \n",
       "3793            -0.029116         9.257587                    3.623333   \n",
       "3794             0.211833         8.850640                    5.180000   \n",
       "\n",
       "      away_last_5_GF%_5v5  away_Goalie_GSAx/60  home_last_40_GF%_5v5  \\\n",
       "0               45.937500             0.027934             50.127801   \n",
       "1               49.927641            -0.138771             56.868932   \n",
       "2               45.427286             0.041876             56.575634   \n",
       "3               45.427286             0.041876             56.575634   \n",
       "4               56.272661             0.009622             53.260259   \n",
       "...                   ...                  ...                   ...   \n",
       "3790            50.523013            -0.160907             50.702434   \n",
       "3791            70.421512             0.072030             47.486397   \n",
       "3792            53.981623             0.135063             43.586998   \n",
       "3793            49.006951            -0.054492             56.092965   \n",
       "3794            47.310888            -0.483024             46.737740   \n",
       "\n",
       "      away_last_5_xGF%_5v5  away_last5_xGF_per_min_pp  \\\n",
       "0                48.770492                   0.069910   \n",
       "1                51.204482                   0.096000   \n",
       "2                40.305523                   0.153218   \n",
       "3                40.305523                   0.153218   \n",
       "4                49.941995                   0.137242   \n",
       "...                    ...                        ...   \n",
       "3790             54.505170                   0.168144   \n",
       "3791             46.681034                   0.091262   \n",
       "3792             45.388350                   0.107551   \n",
       "3793             51.102088                   0.090909   \n",
       "3794             53.449905                   0.135089   \n",
       "\n",
       "      home_last40_pk_TOI_per_game  away_last_40_SH%  away_last_40_GF%_5v5  \\\n",
       "0                        4.923333          8.124451             51.399425   \n",
       "1                        4.774167          8.420932             58.184556   \n",
       "2                        4.233750          7.879167             50.499508   \n",
       "3                        4.233750          7.879167             50.499508   \n",
       "4                        4.379167          5.932286             45.246898   \n",
       "...                           ...               ...                   ...   \n",
       "3790                     4.886667          6.774670             45.320701   \n",
       "3791                     4.458333          7.861206             45.570087   \n",
       "3792                     4.810417          9.108824             58.458552   \n",
       "3793                     4.855417          8.685066             51.541976   \n",
       "3794                     4.206250          7.043789             41.652718   \n",
       "\n",
       "      home_last_40_xGF%_5v5  home_Goalie_FenwickSV%  \\\n",
       "0                 48.992719                0.932657   \n",
       "1                 51.954595                0.941176   \n",
       "2                 49.851785                0.942539   \n",
       "3                 49.851785                0.942539   \n",
       "4                 52.809227                0.932564   \n",
       "...                     ...                     ...   \n",
       "3790              47.185204                0.937551   \n",
       "3791              47.911779                0.926621   \n",
       "3792              45.316488                0.928974   \n",
       "3793              54.701218                0.942539   \n",
       "3794              50.940006                0.944039   \n",
       "\n",
       "      home_last5_xGA_per_min_pk  home_last_5_GF%_5v5  away_Goalie_HDCSV%  \\\n",
       "0                      0.098556            57.080799            0.872792   \n",
       "1                      0.153383            59.064609            0.882353   \n",
       "2                      0.131278            58.385392            0.891688   \n",
       "3                      0.131278            58.385392            0.891688   \n",
       "4                      0.137299            57.771883            0.852632   \n",
       "...                         ...                  ...                 ...   \n",
       "3790                   0.112114            56.342957            0.855114   \n",
       "3791                   0.165572            66.463680            0.860963   \n",
       "3792                   0.119585            51.856336            0.901024   \n",
       "3793                   0.086154            44.565217            0.868195   \n",
       "3794                   0.078519            68.025078            0.870482   \n",
       "\n",
       "      home_last_40_SH%  away_last_40_xGF%_5v5  away_last40_pp_TOI_per_game  \\\n",
       "0             9.025236              49.339386                     4.646667   \n",
       "1             9.060588              52.486645                     4.315417   \n",
       "2             9.025460              49.136336                     4.921667   \n",
       "3             9.025460              49.136336                     4.921667   \n",
       "4             7.970138              50.855171                     5.571250   \n",
       "...                ...                    ...                          ...   \n",
       "3790          9.172687              51.722795                     4.195000   \n",
       "3791          8.299737              42.816482                     4.415417   \n",
       "3792          7.231170              53.445722                     4.307917   \n",
       "3793          8.310378              50.256575                     5.016667   \n",
       "3794          6.290295              46.619035                     4.973750   \n",
       "\n",
       "      home_last40_xGA_per_min_pk  home_last5_pp_TOI_per_game  \\\n",
       "0                       0.104858                    4.190000   \n",
       "1                       0.129028                    3.336667   \n",
       "2                       0.116445                    6.283333   \n",
       "3                       0.116445                    6.283333   \n",
       "4                       0.120913                    4.620000   \n",
       "...                          ...                         ...   \n",
       "3790                    0.103138                    5.273333   \n",
       "3791                    0.116636                    2.333333   \n",
       "3792                    0.098068                    4.450000   \n",
       "3793                    0.116725                    4.463333   \n",
       "3794                    0.107340                    4.283333   \n",
       "\n",
       "      away_last_5_FF%_5v5  away_last5_xGA_per_min_pk  home_last_40_FF%_5v5  \\\n",
       "0               52.562502                   0.074267             48.803377   \n",
       "1               46.882217                   0.109128             50.828439   \n",
       "2               43.520998                   0.112415             50.407241   \n",
       "3               43.520998                   0.112415             50.407241   \n",
       "4               51.909534                   0.086864             52.890654   \n",
       "...                   ...                        ...                   ...   \n",
       "3790            52.471344                   0.095041             48.478268   \n",
       "3791            51.846709                   0.095976             48.281854   \n",
       "3792            47.912088                   0.061953             48.711262   \n",
       "3793            53.800952                   0.247286             54.328835   \n",
       "3794            51.848135                   0.130888             52.317060   \n",
       "\n",
       "      away_last5_pp_TOI_per_game  home_last40_xGF_per_min_pp  \\\n",
       "0                       5.893333                    0.112699   \n",
       "1                       6.000000                    0.124909   \n",
       "2                       4.816667                    0.132248   \n",
       "3                       4.816667                    0.132248   \n",
       "4                       5.173333                    0.105738   \n",
       "...                          ...                         ...   \n",
       "3790                    4.436667                    0.107724   \n",
       "3791                    4.120000                    0.115644   \n",
       "3792                    4.370000                    0.098096   \n",
       "3793                    6.380000                    0.108531   \n",
       "3794                    7.343333                    0.114850   \n",
       "\n",
       "      home_last_5_xGF%_5v5  away_last_5_SH%  away_last40_xGA_per_min_pk  \\\n",
       "0                51.663405         6.967375                    0.133976   \n",
       "1                46.860987        11.358025                    0.097844   \n",
       "2                60.180542         9.286882                    0.107127   \n",
       "3                60.180542         9.286882                    0.107127   \n",
       "4                52.571429         6.524847                    0.093779   \n",
       "...                    ...              ...                         ...   \n",
       "3790             51.508227         7.141273                    0.109875   \n",
       "3791             39.061033         6.831641                    0.127148   \n",
       "3792             43.516270         6.481567                    0.122481   \n",
       "3793             59.167117         9.050064                    0.139438   \n",
       "3794             43.880455         8.420889                    0.123669   \n",
       "\n",
       "      away_Goalie_FenwickSV%  away_last_40_FF%_5v5  home_Goalie_HDCSV%  \n",
       "0                   0.942629             49.991679            0.866667  \n",
       "1                   0.945897             50.633643            0.869942  \n",
       "2                   0.940136             50.595552            0.896450  \n",
       "3                   0.940136             50.595552            0.896450  \n",
       "4                   0.940035             51.197815            0.852201  \n",
       "...                      ...                   ...                 ...  \n",
       "3790                0.932952             50.676962            0.891117  \n",
       "3791                0.939850             46.900863            0.831615  \n",
       "3792                0.944050             53.247076            0.872340  \n",
       "3793                0.935115             50.202661            0.863636  \n",
       "3794                0.929910             46.486492            0.881279  \n",
       "\n",
       "[3750 rows x 38 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:, numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T02:10:04.040842Z",
     "start_time": "2021-05-05T02:10:04.038805Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['neg_log_loss', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:22:26.315098Z",
     "start_time": "2021-05-05T14:22:26.310944Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['home_B2B', 'away_B2B']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T02:14:14.316488Z",
     "start_time": "2021-05-05T02:14:14.310070Z"
    }
   },
   "outputs": [],
   "source": [
    "log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv = GridSearchCV(log_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T02:14:18.164250Z",
     "start_time": "2021-05-05T02:14:15.007035Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_5_FF%_5v5',\n",
       "                                                                          'home_last5_xGF_per_min_pp',\n",
       "                                                                          'home_last40_pp_TOI_per_game',\n",
       "                                                                          'away_last40_pk_TOI_per_game',\n",
       "                                                                          'home_last5_pk_TOI_per_game',\n",
       "                                                                          'away_last40_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'home_last_5_S...\n",
       "                                                                         ['home_B2B',\n",
       "                                                                          'away_B2B'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T02:14:21.904963Z",
     "start_time": "2021-05-05T02:14:21.899276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6777347180223572"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:50:10.367487Z",
     "start_time": "2021-05-05T14:50:10.332703Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677067</td>\n",
       "      <td>-0.675773</td>\n",
       "      <td>-0.682986</td>\n",
       "      <td>-0.677729</td>\n",
       "      <td>-0.675119</td>\n",
       "      <td>-0.677735</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.589333</td>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.675531</td>\n",
       "      <td>-0.677123</td>\n",
       "      <td>-0.683068</td>\n",
       "      <td>-0.676456</td>\n",
       "      <td>-0.677169</td>\n",
       "      <td>-0.677869</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.580267</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.675577</td>\n",
       "      <td>-0.677124</td>\n",
       "      <td>-0.683118</td>\n",
       "      <td>-0.676415</td>\n",
       "      <td>-0.677126</td>\n",
       "      <td>-0.677872</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>3</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017814</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.675577</td>\n",
       "      <td>-0.677125</td>\n",
       "      <td>-0.683118</td>\n",
       "      <td>-0.676414</td>\n",
       "      <td>-0.677127</td>\n",
       "      <td>-0.677872</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>4</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.675282</td>\n",
       "      <td>-0.677541</td>\n",
       "      <td>-0.683798</td>\n",
       "      <td>-0.676713</td>\n",
       "      <td>-0.678060</td>\n",
       "      <td>-0.678279</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>5</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.014655</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 20, 'logisticregress...</td>\n",
       "      <td>-0.675278</td>\n",
       "      <td>-0.677565</td>\n",
       "      <td>-0.683819</td>\n",
       "      <td>-0.676712</td>\n",
       "      <td>-0.678098</td>\n",
       "      <td>-0.678294</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>6</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.610667</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.024154</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.675276</td>\n",
       "      <td>-0.677583</td>\n",
       "      <td>-0.683830</td>\n",
       "      <td>-0.676706</td>\n",
       "      <td>-0.678129</td>\n",
       "      <td>-0.678305</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>7</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582933</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024628</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.675276</td>\n",
       "      <td>-0.677584</td>\n",
       "      <td>-0.683830</td>\n",
       "      <td>-0.676707</td>\n",
       "      <td>-0.678129</td>\n",
       "      <td>-0.678305</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>8</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582933</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018765</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.675279</td>\n",
       "      <td>-0.677585</td>\n",
       "      <td>-0.683832</td>\n",
       "      <td>-0.676704</td>\n",
       "      <td>-0.678134</td>\n",
       "      <td>-0.678307</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>9</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.610667</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-0.675276</td>\n",
       "      <td>-0.677585</td>\n",
       "      <td>-0.683832</td>\n",
       "      <td>-0.676712</td>\n",
       "      <td>-0.678132</td>\n",
       "      <td>-0.678307</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>10</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.610667</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.027825      0.003296         0.009434        0.000387   \n",
       "3        0.023710      0.001415         0.008098        0.000967   \n",
       "5        0.024544      0.001020         0.007175        0.000070   \n",
       "4        0.017814      0.000625         0.007292        0.000235   \n",
       "6        0.042029      0.003558         0.007798        0.000512   \n",
       "12       0.037968      0.004370         0.007319        0.000199   \n",
       "9        0.024154      0.001340         0.007429        0.000419   \n",
       "11       0.024628      0.000918         0.007113        0.000054   \n",
       "10       0.018765      0.000731         0.007361        0.000541   \n",
       "18       0.039950      0.002819         0.007582        0.000092   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "0                          0.1                                   None   \n",
       "3                          0.1                                   None   \n",
       "5                          0.1                                   None   \n",
       "4                          0.1                                   None   \n",
       "6                           10                                   None   \n",
       "12                          20                                   None   \n",
       "9                           10                                   None   \n",
       "11                          10                                   None   \n",
       "10                          10                                   None   \n",
       "18                         100                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "0                                 l1                        liblinear   \n",
       "3                                 l2                        liblinear   \n",
       "5                                 l2                        newton-cg   \n",
       "4                                 l2                            lbfgs   \n",
       "6                                 l1                        liblinear   \n",
       "12                                l1                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "11                                l2                        newton-cg   \n",
       "10                                l2                            lbfgs   \n",
       "18                                l1                        liblinear   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "3   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "6   {'logisticregression__C': 10, 'logisticregress...   \n",
       "12  {'logisticregression__C': 20, 'logisticregress...   \n",
       "9   {'logisticregression__C': 10, 'logisticregress...   \n",
       "11  {'logisticregression__C': 10, 'logisticregress...   \n",
       "10  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 100, 'logisticregres...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                  -0.677067                 -0.675773   \n",
       "3                  -0.675531                 -0.677123   \n",
       "5                  -0.675577                 -0.677124   \n",
       "4                  -0.675577                 -0.677125   \n",
       "6                  -0.675282                 -0.677541   \n",
       "12                 -0.675278                 -0.677565   \n",
       "9                  -0.675276                 -0.677583   \n",
       "11                 -0.675276                 -0.677584   \n",
       "10                 -0.675279                 -0.677585   \n",
       "18                 -0.675276                 -0.677585   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                  -0.682986                 -0.677729   \n",
       "3                  -0.683068                 -0.676456   \n",
       "5                  -0.683118                 -0.676415   \n",
       "4                  -0.683118                 -0.676414   \n",
       "6                  -0.683798                 -0.676713   \n",
       "12                 -0.683819                 -0.676712   \n",
       "9                  -0.683830                 -0.676706   \n",
       "11                 -0.683830                 -0.676707   \n",
       "10                 -0.683832                 -0.676704   \n",
       "18                 -0.683832                 -0.676712   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                  -0.675119               -0.677735               0.002782   \n",
       "3                  -0.677169               -0.677869               0.002666   \n",
       "5                  -0.677126               -0.677872               0.002684   \n",
       "4                  -0.677127               -0.677872               0.002684   \n",
       "6                  -0.678060               -0.678279               0.002915   \n",
       "12                 -0.678098               -0.678294               0.002922   \n",
       "9                  -0.678129               -0.678305               0.002926   \n",
       "11                 -0.678129               -0.678305               0.002926   \n",
       "10                 -0.678134               -0.678307               0.002926   \n",
       "18                 -0.678132               -0.678307               0.002926   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                        1              0.569333              0.590667   \n",
       "3                        2              0.569333              0.608000   \n",
       "5                        3              0.569333              0.608000   \n",
       "4                        4              0.569333              0.608000   \n",
       "6                        5              0.578667              0.609333   \n",
       "12                       6              0.578667              0.610667   \n",
       "9                        7              0.578667              0.609333   \n",
       "11                       8              0.578667              0.609333   \n",
       "10                       9              0.578667              0.610667   \n",
       "18                      10              0.578667              0.610667   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0               0.588000              0.568000              0.589333   \n",
       "3               0.573333              0.584000              0.566667   \n",
       "5               0.573333              0.581333              0.565333   \n",
       "4               0.573333              0.581333              0.565333   \n",
       "6               0.576000              0.584000              0.565333   \n",
       "12              0.574667              0.584000              0.565333   \n",
       "9               0.574667              0.584000              0.568000   \n",
       "11              0.574667              0.584000              0.568000   \n",
       "10              0.574667              0.584000              0.568000   \n",
       "18              0.574667              0.584000              0.568000   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0             0.581067           0.010168                  13  \n",
       "3             0.580267           0.015071                  14  \n",
       "5             0.579467           0.015216                  15  \n",
       "4             0.579467           0.015216                  15  \n",
       "6             0.582667           0.014655                  11  \n",
       "12            0.582667           0.015272                  11  \n",
       "9             0.582933           0.014196                   3  \n",
       "11            0.582933           0.014196                   3  \n",
       "10            0.583200           0.014693                   1  \n",
       "18            0.583200           0.014693                   1  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results = pd.DataFrame(log_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T13:32:59.148471Z",
     "start_time": "2021-05-05T13:32:59.143861Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25, 50],\n",
    "         'ada__learning_rate': [.1, 1, 10, 20],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv = GridSearchCV(ada_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:20:44.765764Z",
     "start_time": "2021-05-05T13:33:01.251444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_5_FF%_5v5',\n",
       "                                                                          'home_last5_xGF_per_min_pp',\n",
       "                                                                          'home_last40_pp_TOI_per_game',\n",
       "                                                                          'away_last40_pk_TOI_per_game',\n",
       "                                                                          'home_last5_pk_TOI_per_game',\n",
       "                                                                          'away_last40_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'home_last_5_S...\n",
       "                                                                          'away_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['home_B2B',\n",
       "                                                                          'away_B2B'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.1, 1, 10, 20],\n",
       "                         'ada__n_estimators': [25, 50]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:21:33.898832Z",
     "start_time": "2021-05-05T14:21:33.895084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6812883430589551"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:22:37.969206Z",
     "start_time": "2021-05-05T14:22:37.929549Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.373599</td>\n",
       "      <td>0.345728</td>\n",
       "      <td>2.937553</td>\n",
       "      <td>0.031958</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682460</td>\n",
       "      <td>-0.678853</td>\n",
       "      <td>-0.681992</td>\n",
       "      <td>-0.682383</td>\n",
       "      <td>-0.680754</td>\n",
       "      <td>-0.681288</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.575467</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.813747</td>\n",
       "      <td>0.627942</td>\n",
       "      <td>2.980223</td>\n",
       "      <td>0.038913</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682541</td>\n",
       "      <td>-0.680892</td>\n",
       "      <td>-0.682944</td>\n",
       "      <td>-0.680844</td>\n",
       "      <td>-0.680954</td>\n",
       "      <td>-0.681635</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>2</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.144892</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.683080</td>\n",
       "      <td>-0.685022</td>\n",
       "      <td>-0.682982</td>\n",
       "      <td>-0.683228</td>\n",
       "      <td>-0.683698</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.569867</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.035846</td>\n",
       "      <td>2.534538</td>\n",
       "      <td>2.475855</td>\n",
       "      <td>0.240989</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685870</td>\n",
       "      <td>-0.680804</td>\n",
       "      <td>-0.684960</td>\n",
       "      <td>-0.684752</td>\n",
       "      <td>-0.684487</td>\n",
       "      <td>-0.684175</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>4</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.550667</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.420303</td>\n",
       "      <td>5.276782</td>\n",
       "      <td>5.004536</td>\n",
       "      <td>0.535126</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.686099</td>\n",
       "      <td>-0.680916</td>\n",
       "      <td>-0.685079</td>\n",
       "      <td>-0.684745</td>\n",
       "      <td>-0.684607</td>\n",
       "      <td>-0.684289</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>5</td>\n",
       "      <td>0.541333</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.537333</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.772775</td>\n",
       "      <td>2.769245</td>\n",
       "      <td>5.614874</td>\n",
       "      <td>0.184574</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685556</td>\n",
       "      <td>-0.684639</td>\n",
       "      <td>-0.685505</td>\n",
       "      <td>-0.684347</td>\n",
       "      <td>-0.684885</td>\n",
       "      <td>-0.684986</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>6</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.538667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.078607</td>\n",
       "      <td>7.450631</td>\n",
       "      <td>4.446727</td>\n",
       "      <td>0.699147</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.687720</td>\n",
       "      <td>-0.681945</td>\n",
       "      <td>-0.686726</td>\n",
       "      <td>-0.686418</td>\n",
       "      <td>-0.686285</td>\n",
       "      <td>-0.685819</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.292306</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>0.027016</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.686973</td>\n",
       "      <td>-0.686153</td>\n",
       "      <td>-0.687641</td>\n",
       "      <td>-0.686227</td>\n",
       "      <td>-0.686640</td>\n",
       "      <td>-0.686727</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>8</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.229604</td>\n",
       "      <td>0.798806</td>\n",
       "      <td>2.387321</td>\n",
       "      <td>0.059241</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688021</td>\n",
       "      <td>-0.688112</td>\n",
       "      <td>-0.688802</td>\n",
       "      <td>-0.688062</td>\n",
       "      <td>-0.688124</td>\n",
       "      <td>-0.688224</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>9</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.819306</td>\n",
       "      <td>1.990608</td>\n",
       "      <td>4.576631</td>\n",
       "      <td>0.098662</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688886</td>\n",
       "      <td>-0.688712</td>\n",
       "      <td>-0.689001</td>\n",
       "      <td>-0.688580</td>\n",
       "      <td>-0.688875</td>\n",
       "      <td>-0.688811</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>10</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      48.373599      0.345728         2.937553        0.031958   \n",
       "0      51.813747      0.627942         2.980223        0.038913   \n",
       "8       0.144892      0.005547         0.017487        0.001032   \n",
       "6      44.035846      2.534538         2.475855        0.240989   \n",
       "5      88.420303      5.276782         5.004536        0.535126   \n",
       "1      95.772775      2.769245         5.614874        0.184574   \n",
       "7      81.078607      7.450631         4.446727        0.699147   \n",
       "9       0.292306      0.043241         0.027016        0.002916   \n",
       "2      39.229604      0.798806         2.387321        0.059241   \n",
       "3      75.819306      1.990608         4.576631        0.098662   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "4  SVC(kernel='linear', probability=True)                       10   \n",
       "0  SVC(kernel='linear', probability=True)                      0.1   \n",
       "8                    LogisticRegression()                      0.1   \n",
       "6  SVC(kernel='linear', probability=True)                       20   \n",
       "5  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "7  SVC(kernel='linear', probability=True)                       20   \n",
       "9                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "3  SVC(kernel='linear', probability=True)                        1   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "4                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "8                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "6                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "7                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "9                      50  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "3                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.682460                 -0.678853   \n",
       "0                 -0.682541                 -0.680892   \n",
       "8                 -0.684177                 -0.683080   \n",
       "6                 -0.685870                 -0.680804   \n",
       "5                 -0.686099                 -0.680916   \n",
       "1                 -0.685556                 -0.684639   \n",
       "7                 -0.687720                 -0.681945   \n",
       "9                 -0.686973                 -0.686153   \n",
       "2                 -0.688021                 -0.688112   \n",
       "3                 -0.688886                 -0.688712   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.681992                 -0.682383   \n",
       "0                 -0.682944                 -0.680844   \n",
       "8                 -0.685022                 -0.682982   \n",
       "6                 -0.684960                 -0.684752   \n",
       "5                 -0.685079                 -0.684745   \n",
       "1                 -0.685505                 -0.684347   \n",
       "7                 -0.686726                 -0.686418   \n",
       "9                 -0.687641                 -0.686227   \n",
       "2                 -0.688802                 -0.688062   \n",
       "3                 -0.689001                 -0.688580   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.680754               -0.681288               0.001363   \n",
       "0                 -0.680954               -0.681635               0.000914   \n",
       "8                 -0.683228               -0.683698               0.000787   \n",
       "6                 -0.684487               -0.684175               0.001748   \n",
       "5                 -0.684607               -0.684289               0.001765   \n",
       "1                 -0.684885               -0.684986               0.000476   \n",
       "7                 -0.686285               -0.685819               0.002001   \n",
       "9                 -0.686640               -0.686727               0.000545   \n",
       "2                 -0.688124               -0.688224               0.000291   \n",
       "3                 -0.688875               -0.688811               0.000148   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.576000              0.597333   \n",
       "0                       2              0.562667              0.578667   \n",
       "8                       3              0.557333              0.588000   \n",
       "6                       4              0.542667              0.582667   \n",
       "5                       5              0.541333              0.597333   \n",
       "1                       6              0.542667              0.542667   \n",
       "7                       7              0.542667              0.586667   \n",
       "9                       8              0.554667              0.584000   \n",
       "2                       9              0.542667              0.542667   \n",
       "3                      10              0.542667              0.542667   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.560000              0.573333              0.570667   \n",
       "0              0.552000              0.557333              0.562667   \n",
       "8              0.557333              0.570667              0.576000   \n",
       "6              0.533333              0.549333              0.545333   \n",
       "5              0.537333              0.548000              0.546667   \n",
       "1              0.538667              0.544000              0.544000   \n",
       "7              0.542667              0.544000              0.544000   \n",
       "9              0.573333              0.561333              0.578667   \n",
       "2              0.542667              0.544000              0.544000   \n",
       "3              0.542667              0.544000              0.544000   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.575467           0.012209                   3  \n",
       "0            0.562667           0.008924                   6  \n",
       "8            0.569867           0.011673                   5  \n",
       "6            0.550667           0.016844                   9  \n",
       "5            0.554133           0.021935                   7  \n",
       "1            0.542400           0.001960                  13  \n",
       "7            0.552000           0.017344                   8  \n",
       "9            0.570400           0.010878                   4  \n",
       "2            0.543200           0.000653                  10  \n",
       "3            0.543200           0.000653                  10  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(ada_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T02:51:51.135921Z",
     "start_time": "2021-05-05T02:51:51.131796Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "gb_params = {'gb__n_estimators': [200, 300, 400],\n",
    "         'gb__learning_rate': [.001,.01, .1],\n",
    "         'gb__max_depth' : [3,5]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipeline, param_grid=gb_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T03:06:55.621259Z",
     "start_time": "2021-05-05T02:51:52.281450Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=200; total time=   4.9s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=200; total time=   5.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=200; total time=   5.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=200; total time=   5.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=300; total time=   7.6s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=300; total time=   7.4s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=300; total time=   7.4s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=400; total time=  10.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=400; total time=   9.8s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=400; total time=  10.3s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=400; total time=  10.4s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=3, gb__n_estimators=400; total time=  10.9s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=200; total time=   8.3s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=200; total time=   8.3s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=200; total time=   8.3s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=300; total time=  12.4s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=300; total time=  12.4s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=300; total time=  12.6s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=300; total time=  12.6s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=300; total time=  12.1s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=400; total time=  16.3s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=400; total time=  16.9s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=400; total time=  16.5s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=400; total time=  16.5s\n",
      "[CV] END gb__learning_rate=0.001, gb__max_depth=5, gb__n_estimators=400; total time=  16.5s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=200; total time=   5.1s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=200; total time=   5.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=200; total time=   5.4s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=200; total time=   5.4s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=200; total time=   5.4s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=300; total time=   7.9s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=300; total time=   7.8s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=300; total time=   7.9s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=300; total time=   7.8s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=300; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=400; total time=  11.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=400; total time=  10.5s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=400; total time=  10.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=200; total time=   8.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=200; total time=   8.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=200; total time=   8.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=200; total time=   8.0s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=300; total time=  12.1s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=300; total time=  12.1s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=400; total time=  16.7s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=400; total time=  16.6s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=400; total time=  17.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=400; total time=  16.2s\n",
      "[CV] END gb__learning_rate=0.01, gb__max_depth=5, gb__n_estimators=400; total time=  16.1s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=200; total time=   5.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=300; total time=   7.4s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=300; total time=   7.5s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=400; total time=   9.9s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=3, gb__n_estimators=400; total time=  10.0s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=200; total time=   8.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=200; total time=   8.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=200; total time=   8.1s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=300; total time=  12.3s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=300; total time=  12.2s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=400; total time=  16.3s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=400; total time=  16.3s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=400; total time=  16.3s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=400; total time=  16.5s\n",
      "[CV] END gb__learning_rate=0.1, gb__max_depth=5, gb__n_estimators=400; total time=  16.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_5_FF%_5v5',\n",
       "                                                                          'home_last5_xGF_per_min_pp',\n",
       "                                                                          'home_last40_pp_TOI_per_game',\n",
       "                                                                          'away_last40_pk_TOI_per_game',\n",
       "                                                                          'home_last5_pk_TOI_per_game',\n",
       "                                                                          'away_last40_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'home_last_5_S...\n",
       "                                                                          'home_last5_pp_TOI_per_game',\n",
       "                                                                          'away_last_5_FF%_5v5',\n",
       "                                                                          'away_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['home_B2B',\n",
       "                                                                          'away_B2B'])])),\n",
       "                                       ('gb', GradientBoostingClassifier())]),\n",
       "             param_grid={'gb__learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'gb__max_depth': [3, 5],\n",
       "                         'gb__n_estimators': [200, 300, 400]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T03:10:27.541809Z",
     "start_time": "2021-05-05T03:10:27.538106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6813076251374858"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T03:10:28.957814Z",
     "start_time": "2021-05-05T03:10:28.923436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.271923</td>\n",
       "      <td>0.141695</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682190</td>\n",
       "      <td>-0.680045</td>\n",
       "      <td>-0.683195</td>\n",
       "      <td>-0.679583</td>\n",
       "      <td>-0.681526</td>\n",
       "      <td>-0.681308</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.010819</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.873014</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.683010</td>\n",
       "      <td>-0.680717</td>\n",
       "      <td>-0.683615</td>\n",
       "      <td>-0.679676</td>\n",
       "      <td>-0.680791</td>\n",
       "      <td>-0.681561</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.565867</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.301410</td>\n",
       "      <td>0.380511</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.684514</td>\n",
       "      <td>-0.682343</td>\n",
       "      <td>-0.684595</td>\n",
       "      <td>-0.679947</td>\n",
       "      <td>-0.681175</td>\n",
       "      <td>-0.682515</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>3</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.567200</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.534748</td>\n",
       "      <td>0.199185</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.684924</td>\n",
       "      <td>-0.684652</td>\n",
       "      <td>-0.683665</td>\n",
       "      <td>-0.685081</td>\n",
       "      <td>-0.686546</td>\n",
       "      <td>-0.684974</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.285022</td>\n",
       "      <td>0.335853</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685048</td>\n",
       "      <td>-0.685482</td>\n",
       "      <td>-0.683626</td>\n",
       "      <td>-0.685462</td>\n",
       "      <td>-0.685492</td>\n",
       "      <td>-0.685022</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>5</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.541333</td>\n",
       "      <td>0.549867</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.998002</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683699</td>\n",
       "      <td>-0.684479</td>\n",
       "      <td>-0.685518</td>\n",
       "      <td>-0.683762</td>\n",
       "      <td>-0.688825</td>\n",
       "      <td>-0.685257</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.541333</td>\n",
       "      <td>0.561067</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.484383</td>\n",
       "      <td>0.079754</td>\n",
       "      <td>0.015311</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685524</td>\n",
       "      <td>-0.686056</td>\n",
       "      <td>-0.684620</td>\n",
       "      <td>-0.686407</td>\n",
       "      <td>-0.685681</td>\n",
       "      <td>-0.685658</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.391780</td>\n",
       "      <td>0.195259</td>\n",
       "      <td>0.024282</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685632</td>\n",
       "      <td>-0.685264</td>\n",
       "      <td>-0.685363</td>\n",
       "      <td>-0.685987</td>\n",
       "      <td>-0.686624</td>\n",
       "      <td>-0.685774</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>8</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.538667</td>\n",
       "      <td>0.549067</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.027624</td>\n",
       "      <td>0.073685</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686338</td>\n",
       "      <td>-0.686972</td>\n",
       "      <td>-0.685883</td>\n",
       "      <td>-0.687305</td>\n",
       "      <td>-0.686566</td>\n",
       "      <td>-0.686613</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>9</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.550667</td>\n",
       "      <td>0.544267</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.214938</td>\n",
       "      <td>0.091112</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686655</td>\n",
       "      <td>-0.686523</td>\n",
       "      <td>-0.685808</td>\n",
       "      <td>-0.687157</td>\n",
       "      <td>-0.687206</td>\n",
       "      <td>-0.686670</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>10</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.538667</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.543733</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6       5.271923      0.141695         0.019683        0.009091   \n",
       "7       7.873014      0.096896         0.016901        0.003443   \n",
       "8      10.301410      0.380511         0.015873        0.000352   \n",
       "5      16.534748      0.199185         0.027762        0.001951   \n",
       "2      10.285022      0.335853         0.019065        0.001787   \n",
       "9       7.998002      0.027494         0.016288        0.000805   \n",
       "1       7.484383      0.079754         0.015311        0.000887   \n",
       "4      12.391780      0.195259         0.024282        0.005705   \n",
       "0       5.027624      0.073685         0.013116        0.001382   \n",
       "3       8.214938      0.091112         0.019273        0.000652   \n",
       "\n",
       "  param_gb__learning_rate param_gb__max_depth param_gb__n_estimators  \\\n",
       "6                    0.01                   3                    200   \n",
       "7                    0.01                   3                    300   \n",
       "8                    0.01                   3                    400   \n",
       "5                   0.001                   5                    400   \n",
       "2                   0.001                   3                    400   \n",
       "9                    0.01                   5                    200   \n",
       "1                   0.001                   3                    300   \n",
       "4                   0.001                   5                    300   \n",
       "0                   0.001                   3                    200   \n",
       "3                   0.001                   5                    200   \n",
       "\n",
       "                                              params  \\\n",
       "6  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "7  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "8  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "5  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "2  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "9  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "1  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "4  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "0  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "3  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                 -0.682190                 -0.680045   \n",
       "7                 -0.683010                 -0.680717   \n",
       "8                 -0.684514                 -0.682343   \n",
       "5                 -0.684924                 -0.684652   \n",
       "2                 -0.685048                 -0.685482   \n",
       "9                 -0.683699                 -0.684479   \n",
       "1                 -0.685524                 -0.686056   \n",
       "4                 -0.685632                 -0.685264   \n",
       "0                 -0.686338                 -0.686972   \n",
       "3                 -0.686655                 -0.686523   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                 -0.683195                 -0.679583   \n",
       "7                 -0.683615                 -0.679676   \n",
       "8                 -0.684595                 -0.679947   \n",
       "5                 -0.683665                 -0.685081   \n",
       "2                 -0.683626                 -0.685462   \n",
       "9                 -0.685518                 -0.683762   \n",
       "1                 -0.684620                 -0.686407   \n",
       "4                 -0.685363                 -0.685987   \n",
       "0                 -0.685883                 -0.687305   \n",
       "3                 -0.685808                 -0.687157   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                 -0.681526               -0.681308               0.001338   \n",
       "7                 -0.680791               -0.681561               0.001495   \n",
       "8                 -0.681175               -0.682515               0.001830   \n",
       "5                 -0.686546               -0.684974               0.000928   \n",
       "2                 -0.685492               -0.685022               0.000718   \n",
       "9                 -0.688825               -0.685257               0.001901   \n",
       "1                 -0.685681               -0.685658               0.000603   \n",
       "4                 -0.686624               -0.685774               0.000493   \n",
       "0                 -0.686566               -0.686613               0.000494   \n",
       "3                 -0.687206               -0.686670               0.000508   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                       1              0.556000              0.573333   \n",
       "7                       2              0.564000              0.573333   \n",
       "8                       3              0.562667              0.568000   \n",
       "5                       4              0.564000              0.565333   \n",
       "2                       5              0.549333              0.549333   \n",
       "9                       6              0.564000              0.578667   \n",
       "1                       7              0.544000              0.542667   \n",
       "4                       8              0.548000              0.552000   \n",
       "0                       9              0.542667              0.542667   \n",
       "3                      10              0.545333              0.544000   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6              0.569333              0.562667              0.542667   \n",
       "7              0.569333              0.568000              0.554667   \n",
       "8              0.577333              0.568000              0.560000   \n",
       "5              0.568000              0.552000              0.546667   \n",
       "2              0.554667              0.554667              0.541333   \n",
       "9              0.565333              0.556000              0.541333   \n",
       "1              0.548000              0.546667              0.552000   \n",
       "4              0.557333              0.549333              0.538667   \n",
       "0              0.542667              0.542667              0.550667   \n",
       "3              0.545333              0.538667              0.545333   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6            0.560800           0.010819                   5  \n",
       "7            0.565867           0.006344                   2  \n",
       "8            0.567200           0.005939                   1  \n",
       "5            0.559200           0.008331                   7  \n",
       "2            0.549867           0.004888                   8  \n",
       "9            0.561067           0.012261                   4  \n",
       "1            0.546667           0.003266                  11  \n",
       "4            0.549067           0.006104                   9  \n",
       "0            0.544267           0.003200                  12  \n",
       "3            0.543733           0.002585                  13  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.DataFrame(gb_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "gb_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not seem that gradient boosting is producing good results for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the logistic regression, coefficients, I can see which feature the algorithm deemed most impactful. I am\n",
    "very surprised that away_last_40_xGF%_5v5 was cut by the l1 regularization, that seemed like it would be one of the more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:45:07.542212Z",
     "start_time": "2021-05-05T14:45:07.526171Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>away_last_40_GF%_5v5</td>\n",
       "      <td>0.190469</td>\n",
       "      <td>0.190469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>away_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.159196</td>\n",
       "      <td>0.159196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>-0.152225</td>\n",
       "      <td>0.152225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>away_last_5_FF%_5v5</td>\n",
       "      <td>0.151841</td>\n",
       "      <td>0.151841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>away_last_5_GF%_5v5</td>\n",
       "      <td>-0.067696</td>\n",
       "      <td>0.067696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.060833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>away_last5_xGF_per_min_pp</td>\n",
       "      <td>-0.060642</td>\n",
       "      <td>0.060642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_B2B</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>0.060171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>0.057695</td>\n",
       "      <td>0.057695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.054198</td>\n",
       "      <td>0.054198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>-0.047271</td>\n",
       "      <td>0.047271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>away_B2B</td>\n",
       "      <td>-0.046307</td>\n",
       "      <td>0.046307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>home_last5_xGA_per_min_pk</td>\n",
       "      <td>-0.045549</td>\n",
       "      <td>0.045549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>-0.042995</td>\n",
       "      <td>0.042995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>-0.038014</td>\n",
       "      <td>0.038014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.036960</td>\n",
       "      <td>0.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>-0.035819</td>\n",
       "      <td>0.035819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_5_GF%_5v5</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.033234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>0.032698</td>\n",
       "      <td>0.032698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>home_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.032378</td>\n",
       "      <td>0.032378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_last40_pp_TOI_per_game</td>\n",
       "      <td>-0.025321</td>\n",
       "      <td>0.025321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_last40_pp_TOI_per_game</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>0.024676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>-0.020544</td>\n",
       "      <td>0.020544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_Goalie_HDCSV%</td>\n",
       "      <td>-0.017224</td>\n",
       "      <td>0.017224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last_5_FF%_5v5</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.012531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_Goalie_GSAx/60</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>0.009327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_last5_pk_TOI_per_game</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_last5_xGF_per_min_pp</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>0.007824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>away_last5_xGA_per_min_pk</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>home_last_5_xGF%_5v5</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>away_last_5_xGF%_5v5</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>away_last5_pp_TOI_per_game</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>home_last5_pp_TOI_per_game</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>away_last_5_SH%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_last_5_SH%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>away_last5_pk_TOI_per_game</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature      Coef  Coef_abs\n",
       "18         away_last_40_GF%_5v5  0.190469  0.190469\n",
       "36   away_last40_xGA_per_min_pk -0.159196  0.159196\n",
       "38         away_last_40_FF%_5v5 -0.152225  0.152225\n",
       "29          away_last_5_FF%_5v5  0.151841  0.151841\n",
       "10          away_last_5_GF%_5v5 -0.067696  0.067696\n",
       "39           home_Goalie_HDCSV%  0.060833  0.060833\n",
       "15    away_last5_xGF_per_min_pp -0.060642  0.060642\n",
       "14                     home_B2B  0.060171  0.060171\n",
       "17             away_last_40_SH%  0.057695  0.057695\n",
       "3   away_last40_pk_TOI_per_game -0.054198  0.054198\n",
       "37       away_Goalie_FenwickSV% -0.047271  0.047271\n",
       "5                      away_B2B -0.046307  0.046307\n",
       "21    home_last5_xGA_per_min_pk -0.045549  0.045549\n",
       "20       home_Goalie_FenwickSV% -0.042995  0.042995\n",
       "11          away_Goalie_GSAx/60 -0.038014  0.038014\n",
       "16  home_last40_pk_TOI_per_game -0.036960  0.036960\n",
       "19        home_last_40_xGF%_5v5 -0.035819  0.035819\n",
       "22          home_last_5_GF%_5v5  0.033234  0.033234\n",
       "31         home_last_40_FF%_5v5  0.032698  0.032698\n",
       "33   home_last40_xGF_per_min_pp -0.032378  0.032378\n",
       "26  away_last40_pp_TOI_per_game -0.025321  0.025321\n",
       "2   home_last40_pp_TOI_per_game  0.024676  0.024676\n",
       "24             home_last_40_SH% -0.020544  0.020544\n",
       "23           away_Goalie_HDCSV% -0.017224  0.017224\n",
       "0           home_last_5_FF%_5v5  0.012531  0.012531\n",
       "7           home_Goalie_GSAx/60 -0.009327  0.009327\n",
       "4    home_last5_pk_TOI_per_game -0.009273  0.009273\n",
       "1     home_last5_xGF_per_min_pp -0.007824  0.007824\n",
       "30    away_last5_xGA_per_min_pk -0.004043  0.004043\n",
       "34         home_last_5_xGF%_5v5  0.003836  0.003836\n",
       "12         home_last_40_GF%_5v5  0.002082  0.002082\n",
       "13         away_last_5_xGF%_5v5 -0.000514  0.000514\n",
       "32   away_last5_pp_TOI_per_game  0.000000  0.000000\n",
       "28   home_last5_pp_TOI_per_game  0.000000  0.000000\n",
       "25        away_last_40_xGF%_5v5  0.000000  0.000000\n",
       "35              away_last_5_SH%  0.000000  0.000000\n",
       "6    away_last40_xGF_per_min_pp  0.000000  0.000000\n",
       "8               home_last_5_SH%  0.000000  0.000000\n",
       "9    away_last5_pk_TOI_per_game  0.000000  0.000000\n",
       "27   home_last40_xGA_per_min_pk  0.000000  0.000000"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_coef = pd.DataFrame(list(zip(X_train.columns, log_cv.best_estimator_[1].coef_[0])), columns = ['Feature', 'Coef'] )\n",
    "log_coef['Coef_abs'] = abs(log_coef['Coef'])\n",
    "log_coef.sort_values('Coef_abs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Game Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run some models using only the rolling 40 game team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:35:06.333148Z",
     "start_time": "2021-05-05T20:35:06.308349Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:35:07.433021Z",
     "start_time": "2021-05-05T20:35:07.430116Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "       'home_last40_pp_TOI_per_game', 'away_last40_pk_TOI_per_game',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    "       'home_Goalie_GSAx/60',  'away_Goalie_GSAx/60', 'home_last_40_GF%_5v5',\n",
    "       'home_last40_pk_TOI_per_game', 'away_last_40_SH%',\n",
    "       'away_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_Goalie_FenwickSV%',\n",
    "       'away_Goalie_HDCSV%', 'home_last_40_SH%',\n",
    "       'away_last_40_xGF%_5v5', 'away_last40_pp_TOI_per_game',\n",
    "       'home_last40_xGA_per_min_pk', \n",
    "       'home_last_40_FF%_5v5', \n",
    "       'home_last40_xGF_per_min_pp',\n",
    "       'away_last40_xGA_per_min_pk', 'away_Goalie_FenwickSV%',\n",
    "       'away_last_40_FF%_5v5', 'home_Goalie_HDCSV%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:07.024493Z",
     "start_time": "2021-05-05T14:55:07.019118Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['home_B2B', 'away_B2B']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:08.424081Z",
     "start_time": "2021-05-05T14:55:08.420000Z"
    }
   },
   "outputs": [],
   "source": [
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 1, 10],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv_40 = GridSearchCV(log_40_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:12.796378Z",
     "start_time": "2021-05-05T14:55:10.392148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_pp_TOI_per_game',\n",
       "                                                                          'away_last40_pk_TOI_per_game',\n",
       "                                                                          'away_last40_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_pk_TOI_per_game',\n",
       "                                                                          'away_last_40_SH%'...\n",
       "                                                                         ['home_B2B',\n",
       "                                                                          'away_B2B'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:55:16.590632Z",
     "start_time": "2021-05-05T14:55:16.557290Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672521</td>\n",
       "      <td>-0.678186</td>\n",
       "      <td>-0.674674</td>\n",
       "      <td>-0.669348</td>\n",
       "      <td>-0.674081</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675677</td>\n",
       "      <td>-0.672520</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>-0.674673</td>\n",
       "      <td>-0.669355</td>\n",
       "      <td>-0.674082</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.675375</td>\n",
       "      <td>-0.672548</td>\n",
       "      <td>-0.678078</td>\n",
       "      <td>-0.674946</td>\n",
       "      <td>-0.669716</td>\n",
       "      <td>-0.674133</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>3</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674011</td>\n",
       "      <td>-0.672891</td>\n",
       "      <td>-0.678995</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.671304</td>\n",
       "      <td>-0.674360</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>4</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674061</td>\n",
       "      <td>-0.672896</td>\n",
       "      <td>-0.679035</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.671252</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.674062</td>\n",
       "      <td>-0.672900</td>\n",
       "      <td>-0.679034</td>\n",
       "      <td>-0.674562</td>\n",
       "      <td>-0.671250</td>\n",
       "      <td>-0.674362</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.580533</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673682</td>\n",
       "      <td>-0.672968</td>\n",
       "      <td>-0.679327</td>\n",
       "      <td>-0.674495</td>\n",
       "      <td>-0.671486</td>\n",
       "      <td>-0.674391</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>7</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673574</td>\n",
       "      <td>-0.673067</td>\n",
       "      <td>-0.679649</td>\n",
       "      <td>-0.674600</td>\n",
       "      <td>-0.672060</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>8</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.021284</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673579</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679654</td>\n",
       "      <td>-0.674596</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674590</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>9</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.673578</td>\n",
       "      <td>-0.673068</td>\n",
       "      <td>-0.679656</td>\n",
       "      <td>-0.674598</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>-0.674591</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>10</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4        0.014693      0.001130         0.007716        0.000719   \n",
       "5        0.017283      0.000292         0.006951        0.000118   \n",
       "3        0.014061      0.000746         0.008523        0.001029   \n",
       "9        0.014426      0.000387         0.006950        0.000158   \n",
       "11       0.020913      0.000814         0.007221        0.000453   \n",
       "10       0.015567      0.000349         0.007100        0.000190   \n",
       "12       0.022668      0.001238         0.007185        0.000171   \n",
       "15       0.015133      0.000416         0.007112        0.000265   \n",
       "17       0.021284      0.000212         0.007193        0.000235   \n",
       "16       0.016655      0.000304         0.006913        0.000190   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "9                          0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "12                           1                                   None   \n",
       "15                           1                                   None   \n",
       "17                           1                                   None   \n",
       "16                           1                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "11                                l2                        newton-cg   \n",
       "10                                l2                            lbfgs   \n",
       "12                                l1                        liblinear   \n",
       "15                                l2                        liblinear   \n",
       "17                                l2                        newton-cg   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                  -0.675677                 -0.672521   \n",
       "5                  -0.675677                 -0.672520   \n",
       "3                  -0.675375                 -0.672548   \n",
       "9                  -0.674011                 -0.672891   \n",
       "11                 -0.674061                 -0.672896   \n",
       "10                 -0.674062                 -0.672900   \n",
       "12                 -0.673682                 -0.672968   \n",
       "15                 -0.673574                 -0.673067   \n",
       "17                 -0.673579                 -0.673068   \n",
       "16                 -0.673578                 -0.673068   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                  -0.678186                 -0.674674   \n",
       "5                  -0.678187                 -0.674673   \n",
       "3                  -0.678078                 -0.674946   \n",
       "9                  -0.678995                 -0.674600   \n",
       "11                 -0.679035                 -0.674563   \n",
       "10                 -0.679034                 -0.674562   \n",
       "12                 -0.679327                 -0.674495   \n",
       "15                 -0.679649                 -0.674600   \n",
       "17                 -0.679654                 -0.674596   \n",
       "16                 -0.679656                 -0.674598   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                  -0.669348               -0.674081               0.002986   \n",
       "5                  -0.669355               -0.674082               0.002984   \n",
       "3                  -0.669716               -0.674133               0.002821   \n",
       "9                  -0.671304               -0.674360               0.002575   \n",
       "11                 -0.671252               -0.674362               0.002600   \n",
       "10                 -0.671250               -0.674362               0.002599   \n",
       "12                 -0.671486               -0.674391               0.002659   \n",
       "15                 -0.672060               -0.674590               0.002659   \n",
       "17                 -0.672055               -0.674590               0.002661   \n",
       "16                 -0.672055               -0.674591               0.002662   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                        1              0.570667              0.593333   \n",
       "5                        2              0.570667              0.593333   \n",
       "3                        3              0.568000              0.596000   \n",
       "9                        4              0.570667              0.584000   \n",
       "11                       5              0.568000              0.582667   \n",
       "10                       6              0.568000              0.582667   \n",
       "12                       7              0.572000              0.580000   \n",
       "15                       8              0.573333              0.582667   \n",
       "17                       9              0.573333              0.582667   \n",
       "16                      10              0.573333              0.582667   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4               0.592000              0.569333              0.581333   \n",
       "5               0.592000              0.569333              0.581333   \n",
       "3               0.592000              0.573333              0.584000   \n",
       "9               0.593333              0.578667              0.576000   \n",
       "11              0.593333              0.581333              0.577333   \n",
       "10              0.593333              0.581333              0.577333   \n",
       "12              0.590667              0.577333              0.576000   \n",
       "15              0.585333              0.574667              0.572000   \n",
       "17              0.585333              0.574667              0.572000   \n",
       "16              0.585333              0.574667              0.572000   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4             0.581333           0.010154                   3  \n",
       "5             0.581333           0.010154                   3  \n",
       "3             0.582667           0.010667                   2  \n",
       "9             0.580533           0.007710                   5  \n",
       "11            0.580533           0.008202                   5  \n",
       "10            0.580533           0.008202                   5  \n",
       "12            0.579200           0.006288                   9  \n",
       "15            0.577600           0.005360                  10  \n",
       "17            0.577600           0.005360                  10  \n",
       "16            0.577600           0.005360                  10  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_results = pd.DataFrame(log_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:01:02.159647Z",
     "start_time": "2021-05-05T15:01:02.147007Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>0.167769</td>\n",
       "      <td>0.167769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>0.128198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>away_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.127853</td>\n",
       "      <td>0.127853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_last40_pp_TOI_per_game</td>\n",
       "      <td>-0.120332</td>\n",
       "      <td>0.120332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>0.092343</td>\n",
       "      <td>0.092343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>away_Goalie_HDCSV%</td>\n",
       "      <td>-0.069468</td>\n",
       "      <td>0.069468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>away_B2B</td>\n",
       "      <td>-0.069465</td>\n",
       "      <td>0.069465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_last40_xGA_per_min_pk</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.068317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>-0.058731</td>\n",
       "      <td>0.058731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_B2B</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.057827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_Goalie_GSAx/60</td>\n",
       "      <td>-0.057538</td>\n",
       "      <td>0.057538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>-0.053817</td>\n",
       "      <td>0.053817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>-0.049700</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.048419</td>\n",
       "      <td>0.048419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>-0.047514</td>\n",
       "      <td>0.047514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>0.044988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_last40_pp_TOI_per_game</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.042033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last_40_GF%_5v5</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.037274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_last40_pk_TOI_per_game</td>\n",
       "      <td>-0.031585</td>\n",
       "      <td>0.031585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>0.028338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>-0.017327</td>\n",
       "      <td>0.017327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.014227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>0.008973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature      Coef  Coef_abs\n",
       "10        home_last_40_xGF%_5v5  0.167769  0.167769\n",
       "16         away_last_40_FF%_5v5  0.128198  0.128198\n",
       "22  away_last40_pk_TOI_per_game -0.127853  0.127853\n",
       "20  away_last40_pp_TOI_per_game -0.120332  0.120332\n",
       "9          home_last_40_GF%_5v5  0.092343  0.092343\n",
       "5            away_Goalie_HDCSV% -0.069468  0.069468\n",
       "7                      away_B2B -0.069465  0.069465\n",
       "23   away_last40_xGA_per_min_pk  0.068317  0.068317\n",
       "4           away_Goalie_GSAx/60 -0.058731  0.058731\n",
       "6                      home_B2B  0.057827  0.057827\n",
       "1           home_Goalie_GSAx/60 -0.057538  0.057538\n",
       "2            home_Goalie_HDCSV% -0.053817  0.053817\n",
       "11             home_last_40_SH% -0.049700  0.049700\n",
       "13   home_last40_xGF_per_min_pp -0.048419  0.048419\n",
       "21   away_last40_xGF_per_min_pp -0.047514  0.047514\n",
       "8          home_last_40_FF%_5v5 -0.044988  0.044988\n",
       "12  home_last40_pp_TOI_per_game  0.042033  0.042033\n",
       "17         away_last_40_GF%_5v5  0.037274  0.037274\n",
       "14  home_last40_pk_TOI_per_game -0.031585  0.031585\n",
       "0        home_Goalie_FenwickSV%  0.028338  0.028338\n",
       "3        away_Goalie_FenwickSV%  0.019926  0.019926\n",
       "15   home_last40_xGA_per_min_pk -0.017327  0.017327\n",
       "18        away_last_40_xGF%_5v5  0.014227  0.014227\n",
       "19             away_last_40_SH% -0.008973  0.008973"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_coef = pd.DataFrame(list(zip(X_train.columns, log_cv_40.best_estimator_[1].coef_[0])), columns = ['Feature', 'Coef'] )\n",
    "log_40_coef['Coef_abs'] = abs(log_40_coef['Coef'])\n",
    "log_40_coef.sort_values('Coef_abs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:35:47.332087Z",
     "start_time": "2021-05-05T20:35:47.324629Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['home_B2B', 'away_B2B']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "ada_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [.01, .1, 1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv_40 = GridSearchCV(ada_40_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:51:08.353702Z",
     "start_time": "2021-05-05T20:35:48.487544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_pp_TOI_per_game',\n",
       "                                                                          'away_last40_pk_TOI_per_game',\n",
       "                                                                          'away_last40_xGF_per_min_pp',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_pk_TOI_per_game',\n",
       "                                                                          'away_last_40_SH%'...\n",
       "                                                                          'away_last_40_FF%_5v5',\n",
       "                                                                          'home_Goalie_HDCSV%']),\n",
       "                                                                        ('cat',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['home_B2B',\n",
       "                                                                          'away_B2B'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.01, 0.1, 1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:07:33.366782Z",
     "start_time": "2021-05-05T23:07:33.306792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.928906</td>\n",
       "      <td>1.102974</td>\n",
       "      <td>2.342911</td>\n",
       "      <td>0.052230</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.676974</td>\n",
       "      <td>-0.673666</td>\n",
       "      <td>-0.677154</td>\n",
       "      <td>-0.676621</td>\n",
       "      <td>-0.672943</td>\n",
       "      <td>-0.675472</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.681029</td>\n",
       "      <td>-0.678332</td>\n",
       "      <td>-0.681242</td>\n",
       "      <td>-0.678748</td>\n",
       "      <td>-0.678069</td>\n",
       "      <td>-0.679484</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.577333</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.569867</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.345423</td>\n",
       "      <td>0.336290</td>\n",
       "      <td>2.573474</td>\n",
       "      <td>0.028111</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683231</td>\n",
       "      <td>-0.672194</td>\n",
       "      <td>-0.682686</td>\n",
       "      <td>-0.680888</td>\n",
       "      <td>-0.680843</td>\n",
       "      <td>-0.679968</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.433099</td>\n",
       "      <td>0.796355</td>\n",
       "      <td>2.499568</td>\n",
       "      <td>0.082708</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682249</td>\n",
       "      <td>-0.680174</td>\n",
       "      <td>-0.681820</td>\n",
       "      <td>-0.680632</td>\n",
       "      <td>-0.680885</td>\n",
       "      <td>-0.681152</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.558667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132891</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684313</td>\n",
       "      <td>-0.682629</td>\n",
       "      <td>-0.684777</td>\n",
       "      <td>-0.683140</td>\n",
       "      <td>-0.682848</td>\n",
       "      <td>-0.683541</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>5</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.585333</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.578933</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.091805</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>2.052148</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688593</td>\n",
       "      <td>-0.688348</td>\n",
       "      <td>-0.688968</td>\n",
       "      <td>-0.688236</td>\n",
       "      <td>-0.687525</td>\n",
       "      <td>-0.688334</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>6</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.101714</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691506</td>\n",
       "      <td>-0.691278</td>\n",
       "      <td>-0.691629</td>\n",
       "      <td>-0.691432</td>\n",
       "      <td>-0.691436</td>\n",
       "      <td>-0.691456</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>7</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.271557</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.690214</td>\n",
       "      <td>-0.693413</td>\n",
       "      <td>-0.700866</td>\n",
       "      <td>-0.689553</td>\n",
       "      <td>-0.694382</td>\n",
       "      <td>-0.693686</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      40.928906      1.102974         2.342911        0.052230   \n",
       "4       0.123535      0.004822         0.016900        0.001988   \n",
       "3      42.345423      0.336290         2.573474        0.028111   \n",
       "1      42.433099      0.796355         2.499568        0.082708   \n",
       "5       0.132891      0.010832         0.016125        0.000969   \n",
       "2      35.091805      0.160695         2.052148        0.016464   \n",
       "6       0.101714      0.006457         0.016900        0.000865   \n",
       "7       0.271557      0.016521         0.017777        0.002543   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0  SVC(kernel='linear', probability=True)                     0.01   \n",
       "4                    LogisticRegression()                     0.01   \n",
       "3  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "6                    LogisticRegression()                        1   \n",
       "7                    LogisticRegression()                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "4                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "3                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "7                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.676974                 -0.673666   \n",
       "4                 -0.681029                 -0.678332   \n",
       "3                 -0.683231                 -0.672194   \n",
       "1                 -0.682249                 -0.680174   \n",
       "5                 -0.684313                 -0.682629   \n",
       "2                 -0.688593                 -0.688348   \n",
       "6                 -0.691506                 -0.691278   \n",
       "7                 -0.690214                 -0.693413   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.677154                 -0.676621   \n",
       "4                 -0.681242                 -0.678748   \n",
       "3                 -0.682686                 -0.680888   \n",
       "1                 -0.681820                 -0.680632   \n",
       "5                 -0.684777                 -0.683140   \n",
       "2                 -0.688968                 -0.688236   \n",
       "6                 -0.691629                 -0.691432   \n",
       "7                 -0.700866                 -0.689553   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.672943               -0.675472               0.001793   \n",
       "4                 -0.678069               -0.679484               0.001367   \n",
       "3                 -0.680843               -0.679968               0.004002   \n",
       "1                 -0.680885               -0.681152               0.000768   \n",
       "5                 -0.682848               -0.683541               0.000848   \n",
       "2                 -0.687525               -0.688334               0.000476   \n",
       "6                 -0.691436               -0.691456               0.000114   \n",
       "7                 -0.694382               -0.693686               0.004031   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.560000              0.590667   \n",
       "4                       2              0.566667              0.577333   \n",
       "3                       3              0.573333              0.597333   \n",
       "1                       4              0.573333              0.580000   \n",
       "5                       5              0.565333              0.585333   \n",
       "2                       6              0.542667              0.542667   \n",
       "6                       7              0.568000              0.586667   \n",
       "7                       8              0.542667              0.542667   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.597333              0.569333              0.580000   \n",
       "4              0.562667              0.573333              0.569333   \n",
       "3              0.546667              0.562667              0.564000   \n",
       "1              0.558667              0.560000              0.548000   \n",
       "5              0.574667              0.590667              0.578667   \n",
       "2              0.542667              0.544000              0.544000   \n",
       "6              0.592000              0.572000              0.586667   \n",
       "7              0.542667              0.544000              0.450667   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.579467           0.013613                   2  \n",
       "4            0.569867           0.005102                   4  \n",
       "3            0.568800           0.016645                   5  \n",
       "1            0.564000           0.011345                   6  \n",
       "5            0.578933           0.008739                   3  \n",
       "2            0.543200           0.000653                   7  \n",
       "6            0.581067           0.009330                   1  \n",
       "7            0.524533           0.036937                   8  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_40_results = pd.DataFrame(ada_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Rolling Game Features With Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:42:07.603654Z",
     "start_time": "2021-05-05T23:42:07.572457Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:42:10.436891Z",
     "start_time": "2021-05-05T23:42:10.432366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 104)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:52:08.495194Z",
     "start_time": "2021-05-05T15:52:08.489118Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['home_B2B', 'away_B2B']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)])\n",
    "\n",
    "rfecv = RFECV(estimator= LogisticRegression(max_iter =10000, penalty = 'l2', solver='liblinear', C=.1), step=1, scoring='accuracy')\n",
    "rfecv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:52:32.945100Z",
     "start_time": "2021-05-05T15:52:09.991572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_Goalie_FenwickSV%',\n",
       "                                                   'home_Goalie_GSAx/60',\n",
       "                                                   'home_Goalie_HDCSV%',\n",
       "                                                   'away_Goalie_FenwickSV%',\n",
       "                                                   'away_Goalie_GSAx/60',\n",
       "                                                   'away_Goalie_HDCSV%',\n",
       "                                                   'home_last_3_FF%_5v5',\n",
       "                                                   'home_last_3_GF%_5v5',\n",
       "                                                   'home_last_3_xGF%_5v5',\n",
       "                                                   'home_last_3_SH%',\n",
       "                                                   'home_last3...\n",
       "                                                   'home_last_5_FF%_5v5',\n",
       "                                                   'home_last_5_GF%_5v5',\n",
       "                                                   'home_last_5_xGF%_5v5',\n",
       "                                                   'home_last_5_SH%',\n",
       "                                                   'home_last5_pp_TOI_per_game',\n",
       "                                                   'home_last5_xGF_per_min_pp',\n",
       "                                                   'home_last5_pk_TOI_per_game',\n",
       "                                                   'home_last5_xGA_per_min_pk', ...]),\n",
       "                                                 ('cat', 'passthrough',\n",
       "                                                  ['home_B2B', 'away_B2B'])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(estimator=LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy'))])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:58:56.937140Z",
     "start_time": "2021-05-05T15:58:56.932307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:58:58.147912Z",
     "start_time": "2021-05-05T15:58:58.142334Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 11, 75,  1, 27,  1, 48,  1, 24, 47, 81,  9, 65, 72, 16, 70,\n",
       "       14, 37, 34, 42, 77,  1, 67,  1, 23, 46, 62, 10, 12, 45, 15, 36, 13,\n",
       "       71, 33, 43, 63, 64, 79, 41, 82, 76, 26, 40, 73, 44, 54, 35, 74, 38,\n",
       "       32, 61, 21, 28, 78, 30, 80, 57, 25,  5,  1,  1, 53,  1,  1, 49, 31,\n",
       "        8, 69,  1, 66, 29, 52, 51, 55, 59,  1, 19, 18,  6,  1, 50,  1,  7,\n",
       "       68,  1,  1,  1,  1, 60, 56,  4,  3, 20, 17,  1,  1, 39,  1, 58, 22,\n",
       "        1,  1])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:59:33.406569Z",
     "start_time": "2021-05-05T15:59:33.393829Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last_10_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>home_last_30_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>away_last3_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>away_last_5_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>home_last_3_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>away_last40_pk_TOI_per_game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>away_last_20_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>home_last5_xGA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>away_last_10_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>away_last_10_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>away_last5_pp_TOI_per_game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>away_last_5_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>away_last30_pk_TOI_per_game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_5_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>home_Goalie_HDCSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>away_last_3_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_last_3_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>away_last10_pk_TOI_per_game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Ranking\n",
       "0           home_last_10_FF%_5v5        1\n",
       "102         home_last_30_FF%_5v5        1\n",
       "61     away_last3_xGF_per_min_pp        1\n",
       "62           away_Goalie_GSAx/60        1\n",
       "64          away_last_5_xGF%_5v5        1\n",
       "65              away_last_40_SH%        1\n",
       "70           home_last_3_GF%_5v5        1\n",
       "77          away_last_40_FF%_5v5        1\n",
       "24        away_Goalie_FenwickSV%        1\n",
       "81   away_last40_pk_TOI_per_game        1\n",
       "86        home_Goalie_FenwickSV%        1\n",
       "87              away_last_20_SH%        1\n",
       "88     home_last5_xGA_per_min_pk        1\n",
       "89              away_last_10_SH%        1\n",
       "96         away_last_10_xGF%_5v5        1\n",
       "97    away_last5_pp_TOI_per_game        1\n",
       "99               away_last_5_SH%        1\n",
       "83   away_last30_pk_TOI_per_game        1\n",
       "22          home_last_5_xGF%_5v5        1\n",
       "103           home_Goalie_HDCSV%        1\n",
       "6            away_last_3_FF%_5v5        1\n",
       "4                home_last_3_SH%        1\n",
       "8    away_last10_pk_TOI_per_game        1"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_results = pd.DataFrame(list(zip(X_train.columns, rfecv_pipeline[1].ranking_)), columns = ['Feature', 'Ranking']).sort_values('Ranking')\n",
    "rfecv_results.head(rfecv_pipeline[1].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:59:42.767753Z",
     "start_time": "2021-05-05T15:59:42.762684Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_last_10_FF%_5v5',\n",
       " 'home_last_30_FF%_5v5',\n",
       " 'away_last3_xGF_per_min_pp',\n",
       " 'away_Goalie_GSAx/60',\n",
       " 'away_last_5_xGF%_5v5',\n",
       " 'away_last_40_SH%',\n",
       " 'home_last_3_GF%_5v5',\n",
       " 'away_last_40_FF%_5v5',\n",
       " 'away_Goalie_FenwickSV%',\n",
       " 'away_last40_pk_TOI_per_game',\n",
       " 'home_Goalie_FenwickSV%',\n",
       " 'away_last_20_SH%',\n",
       " 'home_last5_xGA_per_min_pk',\n",
       " 'away_last_10_SH%',\n",
       " 'away_last_10_xGF%_5v5',\n",
       " 'away_last5_pp_TOI_per_game',\n",
       " 'away_last_5_SH%',\n",
       " 'away_last30_pk_TOI_per_game',\n",
       " 'home_last_5_xGF%_5v5',\n",
       " 'home_Goalie_HDCSV%',\n",
       " 'away_last_3_FF%_5v5',\n",
       " 'home_last_3_SH%',\n",
       " 'away_last10_pk_TOI_per_game']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = list(rfecv_results.iloc[:rfecv_pipeline[1].n_features_,0])\n",
    "rfecv_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:59:54.377936Z",
     "start_time": "2021-05-05T15:59:54.349681Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:00:17.194434Z",
     "start_time": "2021-05-05T16:00:17.189145Z"
    }
   },
   "outputs": [],
   "source": [
    "log_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None]}\n",
    "\n",
    "log_cv_all = GridSearchCV(log_rfecv_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:00:20.768882Z",
     "start_time": "2021-05-05T16:00:18.618575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_all.fit(X_train[rfecv_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:00:24.220413Z",
     "start_time": "2021-05-05T16:00:24.188820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.676998</td>\n",
       "      <td>-0.674722</td>\n",
       "      <td>-0.678140</td>\n",
       "      <td>-0.677774</td>\n",
       "      <td>-0.671281</td>\n",
       "      <td>-0.675783</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677915</td>\n",
       "      <td>-0.675348</td>\n",
       "      <td>-0.678426</td>\n",
       "      <td>-0.678199</td>\n",
       "      <td>-0.670199</td>\n",
       "      <td>-0.676017</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677915</td>\n",
       "      <td>-0.675348</td>\n",
       "      <td>-0.678427</td>\n",
       "      <td>-0.678200</td>\n",
       "      <td>-0.670201</td>\n",
       "      <td>-0.676018</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>3</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677768</td>\n",
       "      <td>-0.675230</td>\n",
       "      <td>-0.678595</td>\n",
       "      <td>-0.678217</td>\n",
       "      <td>-0.670434</td>\n",
       "      <td>-0.676049</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.678761</td>\n",
       "      <td>-0.675954</td>\n",
       "      <td>-0.678914</td>\n",
       "      <td>-0.681263</td>\n",
       "      <td>-0.670352</td>\n",
       "      <td>-0.677049</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>5</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.678788</td>\n",
       "      <td>-0.675981</td>\n",
       "      <td>-0.678899</td>\n",
       "      <td>-0.681268</td>\n",
       "      <td>-0.670329</td>\n",
       "      <td>-0.677053</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>6</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.678788</td>\n",
       "      <td>-0.675980</td>\n",
       "      <td>-0.678899</td>\n",
       "      <td>-0.681270</td>\n",
       "      <td>-0.670329</td>\n",
       "      <td>-0.677053</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>7</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014359</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.678976</td>\n",
       "      <td>-0.676168</td>\n",
       "      <td>-0.678976</td>\n",
       "      <td>-0.681805</td>\n",
       "      <td>-0.670594</td>\n",
       "      <td>-0.677304</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>8</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 20, 'logisticregress...</td>\n",
       "      <td>-0.678992</td>\n",
       "      <td>-0.676181</td>\n",
       "      <td>-0.678983</td>\n",
       "      <td>-0.681833</td>\n",
       "      <td>-0.670604</td>\n",
       "      <td>-0.677318</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>9</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.594667</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-0.679006</td>\n",
       "      <td>-0.676194</td>\n",
       "      <td>-0.678992</td>\n",
       "      <td>-0.681852</td>\n",
       "      <td>-0.670607</td>\n",
       "      <td>-0.677330</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>10</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        0.011894      0.001292         0.003923        0.000006   \n",
       "5        0.015744      0.000855         0.004152        0.000450   \n",
       "4        0.013048      0.001829         0.005018        0.000662   \n",
       "3        0.010138      0.000692         0.004599        0.000393   \n",
       "9        0.010136      0.000326         0.003898        0.000107   \n",
       "11       0.016889      0.000644         0.003922        0.000050   \n",
       "10       0.012270      0.000551         0.003819        0.000032   \n",
       "12       0.014359      0.000719         0.004021        0.000203   \n",
       "18       0.014439      0.000322         0.004291        0.000485   \n",
       "24       0.017296      0.002053         0.004062        0.000077   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "6                          0.1                                   None   \n",
       "5                         0.01                                   None   \n",
       "4                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "9                          0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "12                          10                                   None   \n",
       "18                          20                                   None   \n",
       "24                         100                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "6                                 l1                        liblinear   \n",
       "5                                 l2                        newton-cg   \n",
       "4                                 l2                            lbfgs   \n",
       "3                                 l2                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "11                                l2                        newton-cg   \n",
       "10                                l2                            lbfgs   \n",
       "12                                l1                        liblinear   \n",
       "18                                l1                        liblinear   \n",
       "24                                l1                        liblinear   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 20, 'logisticregress...   \n",
       "24  {'logisticregression__C': 100, 'logisticregres...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.676998                 -0.674722   \n",
       "5                  -0.677915                 -0.675348   \n",
       "4                  -0.677915                 -0.675348   \n",
       "3                  -0.677768                 -0.675230   \n",
       "9                  -0.678761                 -0.675954   \n",
       "11                 -0.678788                 -0.675981   \n",
       "10                 -0.678788                 -0.675980   \n",
       "12                 -0.678976                 -0.676168   \n",
       "18                 -0.678992                 -0.676181   \n",
       "24                 -0.679006                 -0.676194   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.678140                 -0.677774   \n",
       "5                  -0.678426                 -0.678199   \n",
       "4                  -0.678427                 -0.678200   \n",
       "3                  -0.678595                 -0.678217   \n",
       "9                  -0.678914                 -0.681263   \n",
       "11                 -0.678899                 -0.681268   \n",
       "10                 -0.678899                 -0.681270   \n",
       "12                 -0.678976                 -0.681805   \n",
       "18                 -0.678983                 -0.681833   \n",
       "24                 -0.678992                 -0.681852   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.671281               -0.675783               0.002545   \n",
       "5                  -0.670199               -0.676017               0.003113   \n",
       "4                  -0.670201               -0.676018               0.003113   \n",
       "3                  -0.670434               -0.676049               0.003044   \n",
       "9                  -0.670352               -0.677049               0.003748   \n",
       "11                 -0.670329               -0.677053               0.003756   \n",
       "10                 -0.670329               -0.677053               0.003757   \n",
       "12                 -0.670594               -0.677304               0.003799   \n",
       "18                 -0.670604               -0.677318               0.003803   \n",
       "24                 -0.670607               -0.677330               0.003808   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.557333              0.592000   \n",
       "5                        2              0.554667              0.586667   \n",
       "4                        3              0.554667              0.586667   \n",
       "3                        4              0.560000              0.586667   \n",
       "9                        5              0.560000              0.594667   \n",
       "11                       6              0.562667              0.594667   \n",
       "10                       7              0.562667              0.594667   \n",
       "12                       8              0.561333              0.594667   \n",
       "18                       9              0.560000              0.594667   \n",
       "24                      10              0.561333              0.596000   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.570667              0.566667              0.597333   \n",
       "5               0.560000              0.561333              0.597333   \n",
       "4               0.560000              0.561333              0.597333   \n",
       "3               0.573333              0.565333              0.594667   \n",
       "9               0.578667              0.568000              0.592000   \n",
       "11              0.576000              0.568000              0.592000   \n",
       "10              0.576000              0.568000              0.592000   \n",
       "12              0.576000              0.568000              0.593333   \n",
       "18              0.576000              0.568000              0.593333   \n",
       "24              0.574667              0.568000              0.593333   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.576800           0.015310                  16  \n",
       "5             0.572000           0.016823                  18  \n",
       "4             0.572000           0.016823                  18  \n",
       "3             0.576000           0.012955                  17  \n",
       "9             0.578667           0.013387                   3  \n",
       "11            0.578667           0.012733                   3  \n",
       "10            0.578667           0.012733                   3  \n",
       "12            0.578667           0.013360                   3  \n",
       "18            0.578400           0.013712                  15  \n",
       "24            0.578667           0.013753                   3  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_all_results = pd.DataFrame(log_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:51:40.715507Z",
     "start_time": "2021-05-05T23:51:40.685456Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:51:41.929347Z",
     "start_time": "2021-05-05T23:51:41.924862Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [ .1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression(max_iter =10000, C=.01, penalty = 'l1', solver = 'liblinear')],}\n",
    "\n",
    "ada_cv_all = GridSearchCV(ada_rfecv_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T00:00:47.134028Z",
     "start_time": "2021-05-05T23:51:47.286383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression(C=0.01,\n",
       "                                                                    max_iter=10000,\n",
       "                                                                    penalty='l1',\n",
       "                                                                    solver='liblinear')],\n",
       "                         'ada__learning_rate': [0.1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T00:04:10.195452Z",
     "start_time": "2021-05-06T00:04:10.164475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.457442</td>\n",
       "      <td>0.866537</td>\n",
       "      <td>2.623058</td>\n",
       "      <td>0.066013</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683233</td>\n",
       "      <td>-0.681924</td>\n",
       "      <td>-0.683197</td>\n",
       "      <td>-0.682110</td>\n",
       "      <td>-0.681630</td>\n",
       "      <td>-0.682418</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.541333</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.554667</td>\n",
       "      <td>0.558133</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.603495</td>\n",
       "      <td>0.634419</td>\n",
       "      <td>2.648859</td>\n",
       "      <td>0.125019</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684232</td>\n",
       "      <td>-0.681059</td>\n",
       "      <td>-0.684624</td>\n",
       "      <td>-0.682336</td>\n",
       "      <td>-0.683243</td>\n",
       "      <td>-0.683099</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.598667</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>0.569333</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077140</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075963</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.457333</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      45.457442      0.866537         2.623058        0.066013   \n",
       "1      43.603495      0.634419         2.648859        0.125019   \n",
       "2       0.077140      0.000653         0.011736        0.000212   \n",
       "3       0.075963      0.001387         0.012140        0.000086   \n",
       "\n",
       "                           param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0             SVC(kernel='linear', probability=True)                      0.1   \n",
       "1             SVC(kernel='linear', probability=True)                       10   \n",
       "2  LogisticRegression(C=0.01, max_iter=10000, pen...                      0.1   \n",
       "3  LogisticRegression(C=0.01, max_iter=10000, pen...                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "2                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "3                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.683233                 -0.681924   \n",
       "1                 -0.684232                 -0.681059   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.683197                 -0.682110   \n",
       "1                 -0.684624                 -0.682336   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.681630               -0.682418               0.000668   \n",
       "1                 -0.683243               -0.683099               0.001294   \n",
       "2                 -0.693147               -0.693147               0.000000   \n",
       "3                 -0.693147               -0.693147               0.000000   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.561333              0.565333   \n",
       "1                       2              0.569333              0.598667   \n",
       "2                       3              0.457333              0.457333   \n",
       "3                       3              0.457333              0.457333   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.541333                 0.568              0.554667   \n",
       "1              0.553333                 0.568              0.557333   \n",
       "2              0.457333                 0.456              0.456000   \n",
       "3              0.457333                 0.456              0.456000   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.558133           0.009526                   2  \n",
       "1            0.569333           0.015889                   1  \n",
       "2            0.456800           0.000653                   3  \n",
       "3            0.456800           0.000653                   3  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_all_results = pd.DataFrame(ada_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Model To Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will evaluate the best model iterations on the held out 2021 season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:46.889912Z",
     "start_time": "2021-05-05T23:12:46.887400Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {'cv accuracy': {}, 'cv log loss': {}, 'test accuracy': {}, 'test log_loss':{}}\n",
    "accuracy_list = []\n",
    "log_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:48.172913Z",
     "start_time": "2021-05-05T23:12:48.125070Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_5_40 = log_cv.predict(X_test)\n",
    "\n",
    "test_probs_5_40 = log_cv.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_5_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_5_40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:49.235114Z",
     "start_time": "2021-05-05T23:12:49.194454Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_40 = log_cv_40.predict(X_test)\n",
    "\n",
    "test_probs_40 = log_cv_40.predict_proba(X_test)\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:12:50.277948Z",
     "start_time": "2021-05-05T23:12:50.242895Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "test_preds_rfecv = log_cv_all.predict(X_test)\n",
    "\n",
    "test_probs_rfecv = log_cv_all.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_rfecv))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_rfecv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:13:13.589182Z",
     "start_time": "2021-05-05T23:13:10.000569Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test,ada_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:13:17.614125Z",
     "start_time": "2021-05-05T23:13:14.601780Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv_40.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, ada_cv_40.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:38.360192Z",
     "start_time": "2021-05-06T02:12:38.340495Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict['test accuracy'] = accuracy_list\n",
    "results_dict['test log_loss'] = log_loss_list\n",
    "models = ['5 and 40 log', '40 log', 'rfecv log', '5 and 40 ada', '40 ada']\n",
    "results_dict['cv accuracy'] = [log_results['mean_test_accuracy'][0], log_40_results['mean_test_accuracy'][0], log_all_results['mean_test_accuracy'][0], ada_results['mean_test_accuracy'][0], ada_40_results['mean_test_accuracy'][0]]\n",
    "results_dict['cv log loss'] = [log_cv.best_score_*-1, log_cv_40.best_score_*-1, log_cv_all.best_score_*-1, ada_cv.best_score_*-1, ada_cv_40.best_score_*-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:40.320625Z",
     "start_time": "2021-05-06T02:12:40.316596Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, index = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model was logistic regression with the rolling 5 and 40 features on the test data. Interestingly, this was the 4th best model on the CV training data set though it did have the best CV accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T02:12:41.708494Z",
     "start_time": "2021-05-06T02:12:41.698849Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv accuracy</th>\n",
       "      <th>cv log loss</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>test log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5 and 40 log</th>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.677735</td>\n",
       "      <td>0.597205</td>\n",
       "      <td>0.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 log</th>\n",
       "      <td>0.580267</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0.593393</td>\n",
       "      <td>0.657240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 ada</th>\n",
       "      <td>0.579467</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>0.606099</td>\n",
       "      <td>0.660695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv log</th>\n",
       "      <td>0.571733</td>\n",
       "      <td>0.675783</td>\n",
       "      <td>0.590851</td>\n",
       "      <td>0.665077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 ada</th>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.681288</td>\n",
       "      <td>0.560356</td>\n",
       "      <td>0.678121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cv accuracy  cv log loss  test accuracy  test log_loss\n",
       "5 and 40 log     0.581067     0.677735       0.597205       0.657201\n",
       "40 log           0.580267     0.674081       0.593393       0.657240\n",
       "40 ada           0.579467     0.675472       0.606099       0.660695\n",
       "rfecv log        0.571733     0.675783       0.590851       0.665077\n",
       "5 and 40 ada     0.562667     0.681288       0.560356       0.678121"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('test log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To further improve the models I would like to take the following next steps\n",
    "\n",
    "- Train a neural network model\n",
    "- Categorize B2B better\n",
    "- Include team ELO feature\n",
    "- Try linear weightings in rolling features\n",
    "- Increase goalie games\n",
    "- Add prior year goalie GAR feature\n",
    "- Add Team HDSC % feature\n",
    "- Add more seasons to training set\n",
    "- Compare against historical implied odds from a bookmaker\n",
    "- Adjust ineperienced goalie imputed stats and exclude 2021 season to avoid data leakage on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
