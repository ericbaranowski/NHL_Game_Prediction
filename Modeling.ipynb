{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Game Prediction Modeling\n",
    "by Gary Schwaeber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sport betting becoming increasingly popular and mainstream I believe that data science can be used to make superior decisions over gut intuitions. Unlike in Football or Basketball where the betting against the spread is the most popular type of betting, the moneyline is king in the NHL due to lower scoring games. When betting the moneyline, the way to gain an edge is if you know the truer probability of the game outcome then the implied odds from the moneyline. Over the course of the season, if your internally derived game probabilities are superior to the book's, you will be profitable. \n",
    "\n",
    "In this notebook I will attempt to train logistic regression, ada boost, gradient boosting, and neural network models in an attempt to make the best possible game prediction model. I will train my models and tune model hyperparemetres using game results from seasons '2017-2018', '2018-2019', '2019-2020'. Then I will predict on held out games from the current 2021 season and evaluate my model. \n",
    "\n",
    "Log loss is the score which I will use to optimize and judge the models. Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value (0 or 1 in case of binary classification). The more the predicted probability diverges from the actual value, the higher is the log-loss value, [Source](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a). There are currently a handful of public models whose log loss on the current season's games is being [tracked](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/) on which I can compare the quality of my model to.   I will also review accuracy scores due to their interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:28:52.873569Z",
     "start_time": "2021-05-10T16:28:52.861781Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import hockey_scraper\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#for the Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:48:44.859949Z",
     "start_time": "2021-05-07T19:48:44.723497Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_games_multirolling_SVA_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:02.802611Z",
     "start_time": "2021-05-07T19:49:02.798659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4447, 155)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:45:45.144551Z",
     "start_time": "2021-05-10T13:45:45.132773Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature columns for different rolling intervals\n",
    "\n",
    "common = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', \n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']\n",
    "\n",
    "r3 = ['home_last_3_FF%_5v5',\n",
    " 'home_last_3_GF%_5v5',\n",
    " 'home_last_3_xGF%_5v5',\n",
    " 'home_last_3_SH%',\n",
    " 'home_last3_xGF_per_min_pp',\n",
    " 'home_last3_GF_per_min_pp',\n",
    " 'home_last3_xGA_per_min_pk',\n",
    " 'home_last3_GA_per_min_pk',\n",
    " 'away_last_3_FF%_5v5',\n",
    " 'away_last_3_GF%_5v5',\n",
    " 'away_last_3_xGF%_5v5',\n",
    " 'away_last_3_SH%',\n",
    " 'away_last3_xGF_per_min_pp',\n",
    " 'away_last3_GF_per_min_pp',\n",
    " 'away_last3_xGA_per_min_pk',\n",
    " 'away_last3_GA_per_min_pk'] + common\n",
    "\n",
    "r5 =['home_last_5_FF%_5v5',\n",
    " 'home_last_5_GF%_5v5',\n",
    " 'home_last_5_xGF%_5v5',\n",
    " 'home_last_5_SH%',\n",
    "\n",
    " 'home_last5_xGF_per_min_pp',\n",
    " 'home_last5_GF_per_min_pp',\n",
    "\n",
    " 'home_last5_xGA_per_min_pk',\n",
    " 'home_last5_GA_per_min_pk',\n",
    " 'away_last_5_FF%_5v5',\n",
    " 'away_last_5_GF%_5v5',\n",
    " 'away_last_5_xGF%_5v5',\n",
    " 'away_last_5_SH%',\n",
    " 'away_last5_xGF_per_min_pp',\n",
    " 'away_last5_GF_per_min_pp',\n",
    " 'away_last5_xGA_per_min_pk',\n",
    " 'away_last5_GA_per_min_pk'] + common\n",
    "\n",
    "r10 =['home_last_10_FF%_5v5',\n",
    " 'home_last_10_GF%_5v5',\n",
    " 'home_last_10_xGF%_5v5',\n",
    " 'home_last_10_SH%',\n",
    " 'home_last10_xGF_per_min_pp',\n",
    " 'home_last10_GF_per_min_pp',\n",
    " 'home_last10_xGA_per_min_pk',\n",
    " 'home_last10_GA_per_min_pk',\n",
    "  'away_last_10_FF%_5v5',\n",
    " 'away_last_10_GF%_5v5',\n",
    " 'away_last_10_xGF%_5v5',\n",
    " 'away_last_10_SH%',\n",
    " 'away_last10_xGF_per_min_pp',\n",
    " 'away_last10_GF_per_min_pp',\n",
    " 'away_last10_xGA_per_min_pk',\n",
    " 'away_last10_GA_per_min_pk',]\n",
    "\n",
    "\n",
    "r20 = ['home_last_20_FF%_5v5',\n",
    " 'home_last_20_GF%_5v5',\n",
    " 'home_last_20_xGF%_5v5',\n",
    " 'home_last_20_SH%',\n",
    "\n",
    " 'home_last20_xGF_per_min_pp',\n",
    " 'home_last20_GF_per_min_pp',\n",
    "\n",
    " 'home_last20_xGA_per_min_pk',\n",
    " 'home_last20_GA_per_min_pk',\n",
    " 'away_last_20_FF%_5v5',\n",
    " 'away_last_20_GF%_5v5',\n",
    " 'away_last_20_xGF%_5v5',\n",
    " 'away_last_20_SH%',\n",
    "\n",
    " 'away_last20_xGF_per_min_pp',\n",
    " 'away_last20_GF_per_min_pp',\n",
    "\n",
    " 'away_last20_xGA_per_min_pk',\n",
    " 'away_last20_GA_per_min_pk']\n",
    "\n",
    "r30 = ['home_last_30_FF%_5v5',\n",
    " 'home_last_30_GF%_5v5',\n",
    " 'home_last_30_xGF%_5v5',\n",
    " 'home_last_30_SH%',\n",
    " 'home_last30_xGF_per_min_pp',\n",
    " 'home_last30_GF_per_min_pp',\n",
    " 'home_last30_xGA_per_min_pk',\n",
    " 'home_last30_GA_per_min_pk',\n",
    " 'away_last_30_FF%_5v5',\n",
    " 'away_last_30_GF%_5v5',\n",
    " 'away_last_30_xGF%_5v5',\n",
    " 'away_last_30_SH%',\n",
    " 'away_last30_xGF_per_min_pp',\n",
    " 'away_last30_GF_per_min_pp',\n",
    " 'away_last30_xGA_per_min_pk',\n",
    " 'away_last30_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "r40 = ['home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk',\n",
    " 'away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "all_r = list(set(r3+r5+r10+r20+r30+r40))\n",
    "\n",
    "r3_30 =list(set(r3+r30))\n",
    "r5_30 = list(set(r5+r30))\n",
    "r10_30 = list(set(r10+r30))\n",
    "r_3_5_30 = list(set(r3+r5+r30))\n",
    "r_5_20 = list(set(r5+r20))\n",
    "r_5_40 = list(set(r5+r40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model will predict that every home team wins their game and that the probability of that is the ratio of games the home team has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:09.214501Z",
     "start_time": "2021-05-07T19:49:09.014908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.541714\n",
       "0    0.458286\n",
       "Name: Home_Team_Won, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Home_Team_Won'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:10.476331Z",
     "start_time": "2021-05-07T19:49:10.468915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417135147290308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = np.ones(df.shape[0])\n",
    "accuracy_score(df['Home_Team_Won'],baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T19:49:11.547357Z",
     "start_time": "2021-05-07T19:49:11.536477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896630977766495"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_probs = np.repeat(df['Home_Team_Won'].value_counts(normalize=True)[1], df.shape[0])\n",
    "\n",
    "log_loss(df['Home_Team_Won'], baseline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need to beat an accuracy score of 54.17% and a log loss of .6897, otherwise they are no better than just predicting the home team will win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling 5 and 40 game features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first set of models I will attempt using 5 and 40 game rolling features. These seemed like a good set based on the feature selection notebook. 40 games is currently the longest rolling runway I have currently for the team statistics. The 40 games stats intuitively provide the most smoothing of team data over the course of the season, while the 5 game stats may provide some insight on any streakiness or may cover recent developments that would affect short term team performances such as player injuries, trades coaching changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:09.120540Z",
     "start_time": "2021-05-10T13:47:09.092582Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:10.740559Z",
     "start_time": "2021-05-10T13:47:10.737008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['away_last40_GF_per_min_pp', 'away_last_40_FF%_5v5',\n",
       "       'away_last5_xGA_per_min_pk', 'home_Goalie_FenwickSV%',\n",
       "       'home_last_5_SH%', 'home_last5_GA_per_min_pk',\n",
       "       'home_last5_xGA_per_min_pk', 'away_last_40_GF%_5v5',\n",
       "       'away_last5_xGF_per_min_pp', 'home_last_40_GF%_5v5',\n",
       "       'away_last_5_FF%_5v5', 'home_Goalie_HDCSV%', 'home_last_40_FF%_5v5',\n",
       "       'home_last40_xGA_per_min_pk', 'B2B_Status',\n",
       "       'away_last40_xGA_per_min_pk', 'home_last40_GA_per_min_pk',\n",
       "       'home_last_5_xGF%_5v5', 'home_last5_GF_per_min_pp', 'home_Rating.A.Pre',\n",
       "       'away_last_5_SH%', 'away_last5_GA_per_min_pk', 'home_last_5_GF%_5v5',\n",
       "       'away_Goalie_GSAx/60', 'home_last_40_SH%', 'away_last_40_xGF%_5v5',\n",
       "       'home_last_40_xGF%_5v5', 'home_last40_xGF_per_min_pp',\n",
       "       'away_last40_GA_per_min_pk', 'away_last_5_xGF%_5v5',\n",
       "       'home_last40_GF_per_min_pp', 'away_last_40_SH%',\n",
       "       'away_last40_xGF_per_min_pp', 'home_last_5_FF%_5v5',\n",
       "       'away_last5_GF_per_min_pp', 'away_Goalie_FenwickSV%',\n",
       "       'home_last5_xGF_per_min_pp', 'away_Goalie_HDCSV%',\n",
       "       'away_last_5_GF%_5v5', 'away_Rating.A.Pre', 'home_Goalie_GSAx/60'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:15.222881Z",
     "start_time": "2021-05-10T13:47:15.218287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 41)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:24.963914Z",
     "start_time": "2021-05-10T13:47:24.958721Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
    "       'home_last_40_GF%_5v5',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_40_SH%', \n",
    "       'home_Goalie_GSAx/60',\n",
    "        'away_Goalie_GSAx/60',\n",
    "       'away_last_5_GF%_5v5', \n",
    "       'home_last_40_xGF%_5v5', \n",
    "     'home_last5_GF_per_min_pp',\n",
    "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
    "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
    "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
    "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
    "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
    "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
    "     'away_last5_GF_per_min_pp',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
    "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
    "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
    "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
    "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:26.656305Z",
     "start_time": "2021-05-10T13:47:26.629839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GF_per_min_pp</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_last5_GA_per_min_pk</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GA_per_min_pk</th>\n",
       "      <th>away_last5_GF_per_min_pp</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112699</td>\n",
       "      <td>48.770492</td>\n",
       "      <td>50.127801</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>9.025236</td>\n",
       "      <td>-0.202922</td>\n",
       "      <td>0.082345</td>\n",
       "      <td>45.937500</td>\n",
       "      <td>48.992719</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>57.080799</td>\n",
       "      <td>52.399869</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.195440</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>1500.66</td>\n",
       "      <td>51.663405</td>\n",
       "      <td>6.967375</td>\n",
       "      <td>1495.03</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>49.339386</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>51.399425</td>\n",
       "      <td>8.124451</td>\n",
       "      <td>52.562502</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>9.426112</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>48.803377</td>\n",
       "      <td>0.942516</td>\n",
       "      <td>49.991679</td>\n",
       "      <td>0.117297</td>\n",
       "      <td>0.121145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124909</td>\n",
       "      <td>51.204482</td>\n",
       "      <td>56.868932</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>9.060588</td>\n",
       "      <td>0.169541</td>\n",
       "      <td>-0.239655</td>\n",
       "      <td>49.927641</td>\n",
       "      <td>51.954595</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>59.064609</td>\n",
       "      <td>42.564205</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1535.17</td>\n",
       "      <td>46.860987</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>1577.10</td>\n",
       "      <td>0.143856</td>\n",
       "      <td>52.486645</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>58.184556</td>\n",
       "      <td>8.420932</td>\n",
       "      <td>46.882217</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>12.093988</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>50.828439</td>\n",
       "      <td>0.941294</td>\n",
       "      <td>50.633643</td>\n",
       "      <td>0.138139</td>\n",
       "      <td>0.086229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132248</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>0.302087</td>\n",
       "      <td>-0.097423</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.112194</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.116830</td>\n",
       "      <td>1496.85</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>1522.11</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>0.938246</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.149493</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105738</td>\n",
       "      <td>49.941995</td>\n",
       "      <td>53.260259</td>\n",
       "      <td>0.120913</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>7.970138</td>\n",
       "      <td>-0.164139</td>\n",
       "      <td>-0.080476</td>\n",
       "      <td>56.272661</td>\n",
       "      <td>52.809227</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>57.771883</td>\n",
       "      <td>54.316401</td>\n",
       "      <td>0.137242</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0.869266</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.103208</td>\n",
       "      <td>1496.86</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>6.524847</td>\n",
       "      <td>1525.37</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>50.855171</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.115979</td>\n",
       "      <td>45.246898</td>\n",
       "      <td>5.932286</td>\n",
       "      <td>51.909534</td>\n",
       "      <td>0.934447</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.093779</td>\n",
       "      <td>9.804628</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>52.890654</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>51.197815</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.131951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129293</td>\n",
       "      <td>43.637300</td>\n",
       "      <td>48.882718</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>7.303942</td>\n",
       "      <td>-0.310233</td>\n",
       "      <td>-0.346771</td>\n",
       "      <td>52.130045</td>\n",
       "      <td>54.871795</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>48.959081</td>\n",
       "      <td>52.400715</td>\n",
       "      <td>0.142088</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121801</td>\n",
       "      <td>1545.81</td>\n",
       "      <td>50.929752</td>\n",
       "      <td>7.311321</td>\n",
       "      <td>1521.29</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>50.381002</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>52.122642</td>\n",
       "      <td>7.885816</td>\n",
       "      <td>47.102597</td>\n",
       "      <td>0.933383</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>5.518246</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>55.762037</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>51.309591</td>\n",
       "      <td>0.189644</td>\n",
       "      <td>0.128468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_last40_xGF_per_min_pp  away_last_5_xGF%_5v5  home_last_40_GF%_5v5  \\\n",
       "0                    0.112699             48.770492             50.127801   \n",
       "1                    0.124909             51.204482             56.868932   \n",
       "2                    0.132248             40.305523             56.575634   \n",
       "3                    0.105738             49.941995             53.260259   \n",
       "4                    0.129293             43.637300             48.882718   \n",
       "\n",
       "   home_last40_xGA_per_min_pk  home_last5_xGA_per_min_pk  home_last_40_SH%  \\\n",
       "0                    0.104858                   0.098556          9.025236   \n",
       "1                    0.129028                   0.153383          9.060588   \n",
       "2                    0.116445                   0.131278          9.025460   \n",
       "3                    0.120913                   0.137299          7.970138   \n",
       "4                    0.084868                   0.067197          7.303942   \n",
       "\n",
       "   home_Goalie_GSAx/60  away_Goalie_GSAx/60  away_last_5_GF%_5v5  \\\n",
       "0            -0.202922             0.082345            45.937500   \n",
       "1             0.169541            -0.239655            49.927641   \n",
       "2             0.302087            -0.097423            45.427286   \n",
       "3            -0.164139            -0.080476            56.272661   \n",
       "4            -0.310233            -0.346771            52.130045   \n",
       "\n",
       "   home_last_40_xGF%_5v5  home_last5_GF_per_min_pp  home_last_5_GF%_5v5  \\\n",
       "0              48.992719                  0.095465            57.080799   \n",
       "1              51.954595                  0.299700            59.064609   \n",
       "2              49.851785                  0.190981            58.385392   \n",
       "3              52.809227                  0.043290            57.771883   \n",
       "4              54.871795                  0.297398            48.959081   \n",
       "\n",
       "   home_last_5_FF%_5v5  away_last5_xGF_per_min_pp  away_last40_xGF_per_min_pp  \\\n",
       "0            52.399869                   0.069910                    0.122400   \n",
       "1            42.564205                   0.096000                    0.102018   \n",
       "2            60.511924                   0.153218                    0.120843   \n",
       "3            54.316401                   0.137242                    0.143998   \n",
       "4            52.400715                   0.142088                    0.087855   \n",
       "\n",
       "   home_last40_GA_per_min_pk  home_Goalie_HDCSV%  away_last5_GA_per_min_pk  \\\n",
       "0                   0.137102            0.858462                  0.195440   \n",
       "1                   0.104730            0.877358                  0.040268   \n",
       "2                   0.112194            0.897778                  0.068337   \n",
       "3                   0.125595            0.869266                  0.100615   \n",
       "4                   0.101091            0.830721                  0.000000   \n",
       "\n",
       "   away_last40_GF_per_min_pp  away_Rating.A.Pre  home_last_5_xGF%_5v5  \\\n",
       "0                   0.139885            1500.66             51.663405   \n",
       "1                   0.115864            1535.17             46.860987   \n",
       "2                   0.116830            1496.85             60.180542   \n",
       "3                   0.103208            1496.86             52.571429   \n",
       "4                   0.121801            1545.81             50.929752   \n",
       "\n",
       "   away_last_5_SH%  home_Rating.A.Pre  home_last5_xGF_per_min_pp  \\\n",
       "0         6.967375            1495.03                   0.079714   \n",
       "1        11.358025            1577.10                   0.143856   \n",
       "2         9.286882            1522.11                   0.113316   \n",
       "3         6.524847            1525.37                   0.118615   \n",
       "4         7.311321            1521.29                   0.098885   \n",
       "\n",
       "   away_last_40_xGF%_5v5  home_last5_GA_per_min_pk  away_last5_GF_per_min_pp  \\\n",
       "0              49.339386                  0.054152                  0.101810   \n",
       "1              52.486645                  0.225564                  0.100000   \n",
       "2              49.136336                  0.132159                  0.166090   \n",
       "3              50.855171                  0.125962                  0.115979   \n",
       "4              50.381002                  0.036720                  0.065934   \n",
       "\n",
       "   away_last_40_GF%_5v5  away_last_40_SH%  away_last_5_FF%_5v5  \\\n",
       "0             51.399425          8.124451            52.562502   \n",
       "1             58.184556          8.420932            46.882217   \n",
       "2             50.499508          7.879167            43.520998   \n",
       "3             45.246898          5.932286            51.909534   \n",
       "4             52.122642          7.885816            47.102597   \n",
       "\n",
       "   home_Goalie_FenwickSV%  away_Goalie_HDCSV%  away_last40_xGA_per_min_pk  \\\n",
       "0                0.937294            0.873171                    0.133976   \n",
       "1                0.941904            0.864516                    0.097844   \n",
       "2                0.942492            0.878613                    0.107127   \n",
       "3                0.934447            0.848000                    0.093779   \n",
       "4                0.933383            0.839117                    0.102718   \n",
       "\n",
       "   home_last_5_SH%  away_last5_xGA_per_min_pk  home_last_40_FF%_5v5  \\\n",
       "0         9.426112                   0.074267             48.803377   \n",
       "1        12.093988                   0.109128             50.828439   \n",
       "2         8.478124                   0.112415             50.407241   \n",
       "3         9.804628                   0.086864             52.890654   \n",
       "4         5.518246                   0.107438             55.762037   \n",
       "\n",
       "   away_Goalie_FenwickSV%  away_last_40_FF%_5v5  home_last40_GF_per_min_pp  \\\n",
       "0                0.942516             49.991679                   0.117297   \n",
       "1                0.941294             50.633643                   0.138139   \n",
       "2                0.938246             50.595552                   0.149493   \n",
       "3                0.938305             51.197815                   0.099407   \n",
       "4                0.939698             51.309591                   0.189644   \n",
       "\n",
       "   away_last40_GA_per_min_pk  \n",
       "0                   0.121145  \n",
       "1                   0.086229  \n",
       "2                   0.106067  \n",
       "3                   0.131951  \n",
       "4                   0.128468  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numeric_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:32.232877Z",
     "start_time": "2021-05-10T13:47:32.229983Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['neg_log_loss', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:33.891827Z",
     "start_time": "2021-05-10T13:47:33.888608Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:35.464512Z",
     "start_time": "2021-05-10T13:47:35.459880Z"
    }
   },
   "outputs": [],
   "source": [
    "log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.00001, .0001, .001, .01, .05, 0.1],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv = GridSearchCV(log_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:41.683906Z",
     "start_time": "2021-05-10T13:47:37.562200Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                   0.05, 0.1],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:44.487257Z",
     "start_time": "2021-05-10T13:47:44.482601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6754370089204439"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:47:46.211489Z",
     "start_time": "2021-05-10T13:47:46.187325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671673</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673921</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673923</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678653</td>\n",
       "      <td>-0.672743</td>\n",
       "      <td>-0.678873</td>\n",
       "      <td>-0.676277</td>\n",
       "      <td>-0.675154</td>\n",
       "      <td>-0.676340</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.619247</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.587378</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677641</td>\n",
       "      <td>-0.668417</td>\n",
       "      <td>-0.680201</td>\n",
       "      <td>-0.678592</td>\n",
       "      <td>-0.676997</td>\n",
       "      <td>-0.676369</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.025948</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677863</td>\n",
       "      <td>-0.668443</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679093</td>\n",
       "      <td>-0.676975</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677864</td>\n",
       "      <td>-0.668444</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679094</td>\n",
       "      <td>-0.676973</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.678657</td>\n",
       "      <td>-0.671507</td>\n",
       "      <td>-0.677803</td>\n",
       "      <td>-0.679101</td>\n",
       "      <td>-0.675922</td>\n",
       "      <td>-0.676598</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.022879</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677719</td>\n",
       "      <td>-0.669127</td>\n",
       "      <td>-0.678905</td>\n",
       "      <td>-0.679826</td>\n",
       "      <td>-0.677734</td>\n",
       "      <td>-0.676662</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.573417</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677728</td>\n",
       "      <td>-0.669121</td>\n",
       "      <td>-0.681685</td>\n",
       "      <td>-0.681348</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.677963</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.599721</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575648</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677767</td>\n",
       "      <td>-0.669153</td>\n",
       "      <td>-0.681584</td>\n",
       "      <td>-0.681528</td>\n",
       "      <td>-0.679915</td>\n",
       "      <td>-0.677990</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       0.014230      0.000881         0.008953        0.000246   \n",
       "17       0.022448      0.000838         0.009748        0.000274   \n",
       "15       0.014360      0.000209         0.008002        0.000113   \n",
       "21       0.019311      0.001301         0.008871        0.000578   \n",
       "23       0.025948      0.001959         0.008886        0.000504   \n",
       "22       0.020201      0.001397         0.009166        0.000786   \n",
       "24       0.018809      0.001569         0.008565        0.000657   \n",
       "30       0.022879      0.003440         0.008905        0.000758   \n",
       "27       0.024693      0.000996         0.009416        0.000581   \n",
       "28       0.023362      0.000928         0.009284        0.000269   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "16                       0.001                                   None   \n",
       "17                       0.001                                   None   \n",
       "15                       0.001                                   None   \n",
       "21                        0.01                                   None   \n",
       "23                        0.01                                   None   \n",
       "22                        0.01                                   None   \n",
       "24                        0.05                                   None   \n",
       "30                         0.1                                   None   \n",
       "27                        0.05                                   None   \n",
       "28                        0.05                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "16                                l2                            lbfgs   \n",
       "17                                l2                        newton-cg   \n",
       "15                                l2                        liblinear   \n",
       "21                                l2                        liblinear   \n",
       "23                                l2                        newton-cg   \n",
       "22                                l2                            lbfgs   \n",
       "24                                l1                        liblinear   \n",
       "30                                l1                        liblinear   \n",
       "27                                l2                        liblinear   \n",
       "28                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "16  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "17  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "15  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "21  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "23  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "22  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "24  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "30  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "27  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "28  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "16                 -0.678374                 -0.671673   \n",
       "17                 -0.678374                 -0.671674   \n",
       "15                 -0.678653                 -0.672743   \n",
       "21                 -0.677641                 -0.668417   \n",
       "23                 -0.677863                 -0.668443   \n",
       "22                 -0.677864                 -0.668444   \n",
       "24                 -0.678657                 -0.671507   \n",
       "30                 -0.677719                 -0.669127   \n",
       "27                 -0.677728                 -0.669121   \n",
       "28                 -0.677767                 -0.669153   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "16                 -0.677392                 -0.675825   \n",
       "17                 -0.677392                 -0.675825   \n",
       "15                 -0.678873                 -0.676277   \n",
       "21                 -0.680201                 -0.678592   \n",
       "23                 -0.679819                 -0.679093   \n",
       "22                 -0.679819                 -0.679094   \n",
       "24                 -0.677803                 -0.679101   \n",
       "30                 -0.678905                 -0.679826   \n",
       "27                 -0.681685                 -0.681348   \n",
       "28                 -0.681584                 -0.681528   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "16                 -0.673921               -0.675437               0.002411   \n",
       "17                 -0.673923               -0.675437               0.002410   \n",
       "15                 -0.675154               -0.676340               0.002285   \n",
       "21                 -0.676997               -0.676369               0.004120   \n",
       "23                 -0.676975               -0.676439               0.004116   \n",
       "22                 -0.676973               -0.676439               0.004116   \n",
       "24                 -0.675922               -0.676598               0.002769   \n",
       "30                 -0.677734               -0.676662               0.003849   \n",
       "27                 -0.679935               -0.677963               0.004635   \n",
       "28                 -0.679915               -0.677990               0.004632   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "16                       1              0.566248              0.592748   \n",
       "17                       2              0.566248              0.592748   \n",
       "15                       3              0.567643              0.619247   \n",
       "21                       4              0.584379              0.598326   \n",
       "23                       5              0.585774              0.594142   \n",
       "22                       6              0.585774              0.594142   \n",
       "24                       7              0.567643              0.588563   \n",
       "30                       8              0.570432              0.596932   \n",
       "27                       9              0.581590              0.599721   \n",
       "28                      10              0.577406              0.598326   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "16              0.594972              0.571229              0.578212   \n",
       "17              0.594972              0.571229              0.578212   \n",
       "15              0.594972              0.585196              0.569832   \n",
       "21              0.587989              0.565642              0.565642   \n",
       "23              0.587989              0.557263              0.569832   \n",
       "22              0.587989              0.557263              0.569832   \n",
       "24              0.596369              0.561453              0.575419   \n",
       "30              0.585196              0.561453              0.553073   \n",
       "27              0.579609              0.561453              0.555866   \n",
       "28              0.581006              0.562849              0.555866   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "16            0.580682           0.011433                   2  \n",
       "17            0.580682           0.011433                   2  \n",
       "15            0.587378           0.018843                   1  \n",
       "21            0.580396           0.012887                   4  \n",
       "23            0.579000           0.013510                   6  \n",
       "22            0.579000           0.013510                   6  \n",
       "24            0.577889           0.012936                   8  \n",
       "30            0.573417           0.015860                  13  \n",
       "27            0.575648           0.015642                  10  \n",
       "28            0.575091           0.014830                  11  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results = pd.DataFrame(log_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:48:32.159751Z",
     "start_time": "2021-05-10T13:48:32.154979Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25, 50],\n",
    "         'ada__learning_rate': [.1, 1, 10, 20],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv = GridSearchCV(ada_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:32:32.965248Z",
     "start_time": "2021-05-10T13:48:33.819662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.1, 1, 10, 20],\n",
       "                         'ada__n_estimators': [25, 50]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:32:34.771257Z",
     "start_time": "2021-05-10T14:32:34.762427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6799356834363997"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:32:36.359413Z",
     "start_time": "2021-05-10T14:32:36.326747Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.276222</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>2.560906</td>\n",
       "      <td>0.079277</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683174</td>\n",
       "      <td>-0.675307</td>\n",
       "      <td>-0.681271</td>\n",
       "      <td>-0.681280</td>\n",
       "      <td>-0.678648</td>\n",
       "      <td>-0.679936</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.574536</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.279606</td>\n",
       "      <td>0.927575</td>\n",
       "      <td>2.506164</td>\n",
       "      <td>0.064214</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682536</td>\n",
       "      <td>-0.679752</td>\n",
       "      <td>-0.682087</td>\n",
       "      <td>-0.681354</td>\n",
       "      <td>-0.681490</td>\n",
       "      <td>-0.681444</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>2</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.560020</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.684842</td>\n",
       "      <td>0.986084</td>\n",
       "      <td>2.675247</td>\n",
       "      <td>0.181274</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684677</td>\n",
       "      <td>-0.678135</td>\n",
       "      <td>-0.684233</td>\n",
       "      <td>-0.682375</td>\n",
       "      <td>-0.680141</td>\n",
       "      <td>-0.681912</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>3</td>\n",
       "      <td>0.552301</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.566440</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126325</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684109</td>\n",
       "      <td>-0.681523</td>\n",
       "      <td>-0.684027</td>\n",
       "      <td>-0.682690</td>\n",
       "      <td>-0.682635</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.157681</td>\n",
       "      <td>11.129491</td>\n",
       "      <td>4.957148</td>\n",
       "      <td>0.868651</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684681</td>\n",
       "      <td>-0.689051</td>\n",
       "      <td>-0.682996</td>\n",
       "      <td>-0.683049</td>\n",
       "      <td>-0.680393</td>\n",
       "      <td>-0.684034</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>5</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.568963</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.538823</td>\n",
       "      <td>1.743496</td>\n",
       "      <td>4.931413</td>\n",
       "      <td>0.173630</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685212</td>\n",
       "      <td>-0.683904</td>\n",
       "      <td>-0.684925</td>\n",
       "      <td>-0.684599</td>\n",
       "      <td>-0.684942</td>\n",
       "      <td>-0.684716</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.542434</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.672341</td>\n",
       "      <td>4.427197</td>\n",
       "      <td>4.250342</td>\n",
       "      <td>0.344274</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.686891</td>\n",
       "      <td>-0.682469</td>\n",
       "      <td>-0.685481</td>\n",
       "      <td>-0.686313</td>\n",
       "      <td>-0.684238</td>\n",
       "      <td>-0.685078</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.562064</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.547456</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.228802</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.023327</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.686993</td>\n",
       "      <td>-0.685253</td>\n",
       "      <td>-0.687152</td>\n",
       "      <td>-0.686154</td>\n",
       "      <td>-0.686353</td>\n",
       "      <td>-0.686381</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.582634</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.399376</td>\n",
       "      <td>0.317740</td>\n",
       "      <td>2.152855</td>\n",
       "      <td>0.039304</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688148</td>\n",
       "      <td>-0.688114</td>\n",
       "      <td>-0.687842</td>\n",
       "      <td>-0.688028</td>\n",
       "      <td>-0.687648</td>\n",
       "      <td>-0.687956</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.962821</td>\n",
       "      <td>1.963881</td>\n",
       "      <td>4.055349</td>\n",
       "      <td>0.116078</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688860</td>\n",
       "      <td>-0.688524</td>\n",
       "      <td>-0.688807</td>\n",
       "      <td>-0.688775</td>\n",
       "      <td>-0.688475</td>\n",
       "      <td>-0.688688</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      42.276222      0.342722         2.560906        0.079277   \n",
       "0      44.279606      0.927575         2.506164        0.064214   \n",
       "6      44.684842      0.986084         2.675247        0.181274   \n",
       "8       0.126325      0.005333         0.016162        0.000574   \n",
       "5      83.157681     11.129491         4.957148        0.868651   \n",
       "1      83.538823      1.743496         4.931413        0.173630   \n",
       "7      79.672341      4.427197         4.250342        0.344274   \n",
       "9       0.228802      0.003782         0.023327        0.000595   \n",
       "2      36.399376      0.317740         2.152855        0.039304   \n",
       "3      68.962821      1.963881         4.055349        0.116078   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "4  SVC(kernel='linear', probability=True)                       10   \n",
       "0  SVC(kernel='linear', probability=True)                      0.1   \n",
       "6  SVC(kernel='linear', probability=True)                       20   \n",
       "8                    LogisticRegression()                      0.1   \n",
       "5  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "7  SVC(kernel='linear', probability=True)                       20   \n",
       "9                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "3  SVC(kernel='linear', probability=True)                        1   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "4                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "8                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "5                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "7                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "9                      50  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "3                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.683174                 -0.675307   \n",
       "0                 -0.682536                 -0.679752   \n",
       "6                 -0.684677                 -0.678135   \n",
       "8                 -0.684109                 -0.681523   \n",
       "5                 -0.684681                 -0.689051   \n",
       "1                 -0.685212                 -0.683904   \n",
       "7                 -0.686891                 -0.682469   \n",
       "9                 -0.686993                 -0.685253   \n",
       "2                 -0.688148                 -0.688114   \n",
       "3                 -0.688860                 -0.688524   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.681271                 -0.681280   \n",
       "0                 -0.682087                 -0.681354   \n",
       "6                 -0.684233                 -0.682375   \n",
       "8                 -0.684027                 -0.682690   \n",
       "5                 -0.682996                 -0.683049   \n",
       "1                 -0.684925                 -0.684599   \n",
       "7                 -0.685481                 -0.686313   \n",
       "9                 -0.687152                 -0.686154   \n",
       "2                 -0.687842                 -0.688028   \n",
       "3                 -0.688807                 -0.688775   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.678648               -0.679936               0.002726   \n",
       "0                 -0.681490               -0.681444               0.000946   \n",
       "6                 -0.680141               -0.681912               0.002476   \n",
       "8                 -0.682635               -0.682997               0.000969   \n",
       "5                 -0.680393               -0.684034               0.002860   \n",
       "1                 -0.684942               -0.684716               0.000450   \n",
       "7                 -0.684238               -0.685078               0.001580   \n",
       "9                 -0.686353               -0.686381               0.000677   \n",
       "2                 -0.687648               -0.687956               0.000187   \n",
       "3                 -0.688475               -0.688688               0.000157   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.564854              0.595537   \n",
       "0                       2              0.557880              0.571827   \n",
       "6                       3              0.552301              0.592748   \n",
       "8                       4              0.564854              0.594142   \n",
       "5                       5              0.569038              0.543933   \n",
       "1                       6              0.543933              0.543933   \n",
       "7                       7              0.543933              0.562064   \n",
       "9                       8              0.569038              0.602510   \n",
       "2                       9              0.543933              0.543933   \n",
       "3                      10              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.582402              0.560056              0.569832   \n",
       "0              0.562849              0.551676              0.555866   \n",
       "6              0.551676              0.564246              0.571229   \n",
       "8              0.597765              0.569832              0.581006   \n",
       "5              0.586592              0.579609              0.565642   \n",
       "1              0.539106              0.540503              0.544693   \n",
       "7              0.540503              0.543296              0.547486   \n",
       "9              0.597765              0.572626              0.571229   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "3              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.574536           0.012872                   3  \n",
       "0            0.560020           0.006912                   8  \n",
       "6            0.566440           0.015085                   7  \n",
       "8            0.581520           0.012945                   2  \n",
       "5            0.568963           0.014572                   6  \n",
       "1            0.542434           0.002209                  12  \n",
       "7            0.547456           0.007635                   9  \n",
       "9            0.582634           0.014416                   1  \n",
       "2            0.543830           0.000517                  10  \n",
       "3            0.543830           0.000517                  10  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(ada_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:32:37.987314Z",
     "start_time": "2021-05-10T14:32:37.980345Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "gb_params = {'gb__n_estimators': [200, 400],\n",
    "         'gb__learning_rate': [.001,.01],\n",
    "         'gb__max_depth' : [3,5]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipeline, param_grid=gb_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:39:34.605835Z",
     "start_time": "2021-05-10T14:32:39.816757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last5_GF_per_min_pp',\n",
       "                                                                          'away_last_40_GF%_5v5',\n",
       "                                                                          'away_last_40_SH%',\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('gb', GradientBoostingClassifier())]),\n",
       "             param_grid={'gb__learning_rate': [0.001, 0.01],\n",
       "                         'gb__max_depth': [3, 5],\n",
       "                         'gb__n_estimators': [200, 400]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:39:36.124194Z",
     "start_time": "2021-05-10T14:39:36.121037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6813251696169567"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:39:37.638320Z",
     "start_time": "2021-05-10T14:39:37.615251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.265635</td>\n",
       "      <td>0.096079</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682622</td>\n",
       "      <td>-0.679526</td>\n",
       "      <td>-0.684279</td>\n",
       "      <td>-0.680547</td>\n",
       "      <td>-0.679651</td>\n",
       "      <td>-0.681325</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.573986</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.673233</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682203</td>\n",
       "      <td>-0.681423</td>\n",
       "      <td>-0.686615</td>\n",
       "      <td>-0.682465</td>\n",
       "      <td>-0.681980</td>\n",
       "      <td>-0.682937</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>2</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.567288</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.427701</td>\n",
       "      <td>0.163069</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.684066</td>\n",
       "      <td>-0.680755</td>\n",
       "      <td>-0.688405</td>\n",
       "      <td>-0.682039</td>\n",
       "      <td>-0.684558</td>\n",
       "      <td>-0.683965</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>3</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.391733</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.020720</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685737</td>\n",
       "      <td>-0.683565</td>\n",
       "      <td>-0.686076</td>\n",
       "      <td>-0.685384</td>\n",
       "      <td>-0.684671</td>\n",
       "      <td>-0.685087</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538354</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.657891</td>\n",
       "      <td>0.049212</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685452</td>\n",
       "      <td>-0.682728</td>\n",
       "      <td>-0.689618</td>\n",
       "      <td>-0.685672</td>\n",
       "      <td>-0.684913</td>\n",
       "      <td>-0.685676</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535565</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.274320</td>\n",
       "      <td>0.161389</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686921</td>\n",
       "      <td>-0.685192</td>\n",
       "      <td>-0.688020</td>\n",
       "      <td>-0.688213</td>\n",
       "      <td>-0.685295</td>\n",
       "      <td>-0.686728</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>6</td>\n",
       "      <td>0.534170</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.550279</td>\n",
       "      <td>0.541598</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.221529</td>\n",
       "      <td>0.092727</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.687017</td>\n",
       "      <td>-0.686190</td>\n",
       "      <td>-0.687083</td>\n",
       "      <td>-0.687529</td>\n",
       "      <td>-0.686338</td>\n",
       "      <td>-0.686831</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.541875</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.611218</td>\n",
       "      <td>0.167446</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683452</td>\n",
       "      <td>-0.688025</td>\n",
       "      <td>-0.694803</td>\n",
       "      <td>-0.691262</td>\n",
       "      <td>-0.694313</td>\n",
       "      <td>-0.690371</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.565326</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       5.265635      0.096079         0.013914        0.001005   \n",
       "5      10.673233      0.076390         0.017061        0.001314   \n",
       "6       8.427701      0.163069         0.017259        0.000989   \n",
       "1      10.391733      0.082113         0.020720        0.000926   \n",
       "3      16.657891      0.049212         0.026395        0.001463   \n",
       "2       8.274320      0.161389         0.017821        0.001041   \n",
       "0       5.221529      0.092727         0.014165        0.000452   \n",
       "7      16.611218      0.167446         0.022752        0.000479   \n",
       "\n",
       "  param_gb__learning_rate param_gb__max_depth param_gb__n_estimators  \\\n",
       "4                    0.01                   3                    200   \n",
       "5                    0.01                   3                    400   \n",
       "6                    0.01                   5                    200   \n",
       "1                   0.001                   3                    400   \n",
       "3                   0.001                   5                    400   \n",
       "2                   0.001                   5                    200   \n",
       "0                   0.001                   3                    200   \n",
       "7                    0.01                   5                    400   \n",
       "\n",
       "                                              params  \\\n",
       "4  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "5  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "6  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "1  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "3  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "2  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "0  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "7  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.682622                 -0.679526   \n",
       "5                 -0.682203                 -0.681423   \n",
       "6                 -0.684066                 -0.680755   \n",
       "1                 -0.685737                 -0.683565   \n",
       "3                 -0.685452                 -0.682728   \n",
       "2                 -0.686921                 -0.685192   \n",
       "0                 -0.687017                 -0.686190   \n",
       "7                 -0.683452                 -0.688025   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.684279                 -0.680547   \n",
       "5                 -0.686615                 -0.682465   \n",
       "6                 -0.688405                 -0.682039   \n",
       "1                 -0.686076                 -0.685384   \n",
       "3                 -0.689618                 -0.685672   \n",
       "2                 -0.688020                 -0.688213   \n",
       "0                 -0.687083                 -0.687529   \n",
       "7                 -0.694803                 -0.691262   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.679651               -0.681325               0.001847   \n",
       "5                 -0.681980               -0.682937               0.001871   \n",
       "6                 -0.684558               -0.683965               0.002611   \n",
       "1                 -0.684671               -0.685087               0.000892   \n",
       "3                 -0.684913               -0.685676               0.002230   \n",
       "2                 -0.685295               -0.686728               0.001290   \n",
       "0                 -0.686338               -0.686831               0.000498   \n",
       "7                 -0.694313               -0.690371               0.004227   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.559275              0.570432   \n",
       "5                       2              0.549512              0.559275   \n",
       "6                       3              0.555091              0.567643   \n",
       "1                       4              0.538354              0.548117   \n",
       "3                       5              0.535565              0.560669   \n",
       "2                       6              0.534170              0.546722   \n",
       "0                       7              0.543933              0.543933   \n",
       "7                       8              0.569038              0.564854   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.590782              0.567039              0.582402   \n",
       "5              0.581006              0.572626              0.574022   \n",
       "6              0.572626              0.579609              0.561453   \n",
       "1              0.539106              0.551676              0.541899   \n",
       "3              0.526536              0.546089              0.547486   \n",
       "2              0.536313              0.540503              0.550279   \n",
       "0              0.536313              0.543296              0.541899   \n",
       "7              0.551676              0.575419              0.565642   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.573986           0.011227                   1  \n",
       "5            0.567288           0.011333                   2  \n",
       "6            0.567284           0.008524                   3  \n",
       "1            0.543831           0.005215                   5  \n",
       "3            0.543269           0.011557                   6  \n",
       "2            0.541598           0.006098                   8  \n",
       "0            0.541875           0.002878                   7  \n",
       "7            0.565326           0.007775                   4  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.DataFrame(gb_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "gb_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not seem that gradient boosting is producing good results for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:17:21.074710Z",
     "start_time": "2021-05-09T20:17:21.066087Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 12, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['sigmoid', 'hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 18, 24, 30, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3, 5],\n",
    "             'nn__dropout_rate' : [0.0,  0.3, 0.6, 0.9]}\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_cv = GridSearchCV(estimator=nn_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:01:23.976270Z",
     "start_time": "2021-05-09T23:01:23.937431Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>0.683245</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.104092</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.667990</td>\n",
       "      <td>-0.671304</td>\n",
       "      <td>-0.681146</td>\n",
       "      <td>-0.673480</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0.921380</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.104325</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671125</td>\n",
       "      <td>-0.671530</td>\n",
       "      <td>-0.678915</td>\n",
       "      <td>-0.673857</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.570352</td>\n",
       "      <td>0.585706</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0.678168</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.103484</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669233</td>\n",
       "      <td>-0.672437</td>\n",
       "      <td>-0.680127</td>\n",
       "      <td>-0.673932</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.593802</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.582635</td>\n",
       "      <td>0.018831</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>0.749562</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669233</td>\n",
       "      <td>-0.672677</td>\n",
       "      <td>-0.679914</td>\n",
       "      <td>-0.673941</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591290</td>\n",
       "      <td>0.589615</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.576494</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.874522</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.670200</td>\n",
       "      <td>-0.672712</td>\n",
       "      <td>-0.678995</td>\n",
       "      <td>-0.673969</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>5</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.572027</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1.246649</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.114459</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670564</td>\n",
       "      <td>-0.672294</td>\n",
       "      <td>-0.679264</td>\n",
       "      <td>-0.674041</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1.408697</td>\n",
       "      <td>0.335738</td>\n",
       "      <td>0.113080</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.671396</td>\n",
       "      <td>-0.671077</td>\n",
       "      <td>-0.679764</td>\n",
       "      <td>-0.674079</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>7</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.558626</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.939249</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.103511</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669046</td>\n",
       "      <td>-0.672297</td>\n",
       "      <td>-0.680904</td>\n",
       "      <td>-0.674082</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.106048</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670960</td>\n",
       "      <td>-0.671626</td>\n",
       "      <td>-0.680003</td>\n",
       "      <td>-0.674196</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>9</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.558626</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>0.871623</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.104613</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671955</td>\n",
       "      <td>-0.671238</td>\n",
       "      <td>-0.679398</td>\n",
       "      <td>-0.674197</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>10</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0.921179</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670706</td>\n",
       "      <td>-0.672330</td>\n",
       "      <td>-0.679629</td>\n",
       "      <td>-0.674222</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>11</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.589615</td>\n",
       "      <td>0.567002</td>\n",
       "      <td>0.579844</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>1.023331</td>\n",
       "      <td>0.320061</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.671041</td>\n",
       "      <td>-0.671874</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.674283</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>12</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1.178353</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.113529</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.672623</td>\n",
       "      <td>-0.671722</td>\n",
       "      <td>-0.678596</td>\n",
       "      <td>-0.674313</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.600503</td>\n",
       "      <td>0.554439</td>\n",
       "      <td>0.578448</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1.074261</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.110129</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670762</td>\n",
       "      <td>-0.672479</td>\n",
       "      <td>-0.679802</td>\n",
       "      <td>-0.674348</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>14</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1.212478</td>\n",
       "      <td>0.089578</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>-0.673103</td>\n",
       "      <td>-0.677960</td>\n",
       "      <td>-0.674359</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>15</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.556951</td>\n",
       "      <td>0.580960</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1.085747</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.671666</td>\n",
       "      <td>-0.679904</td>\n",
       "      <td>-0.674415</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.912594</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.125086</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.669985</td>\n",
       "      <td>-0.671224</td>\n",
       "      <td>-0.682035</td>\n",
       "      <td>-0.674415</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>17</td>\n",
       "      <td>0.593802</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.570352</td>\n",
       "      <td>0.586823</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>0.969764</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.104657</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670421</td>\n",
       "      <td>-0.672993</td>\n",
       "      <td>-0.679859</td>\n",
       "      <td>-0.674424</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>18</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.848925</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'sigmoid', 'nn__dropout_rat...</td>\n",
       "      <td>-0.670706</td>\n",
       "      <td>-0.671857</td>\n",
       "      <td>-0.680712</td>\n",
       "      <td>-0.674425</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>19</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.569514</td>\n",
       "      <td>0.582356</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1.126699</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.110831</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropou...</td>\n",
       "      <td>-0.670583</td>\n",
       "      <td>-0.671629</td>\n",
       "      <td>-0.681087</td>\n",
       "      <td>-0.674433</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>20</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.584869</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1648       0.683245      0.006266         0.104092        0.001678   \n",
       "1732       0.921380      0.005455         0.104325        0.000706   \n",
       "1828       0.678168      0.001133         0.103484        0.001109   \n",
       "1683       0.749562      0.003505         0.103456        0.001720   \n",
       "1147       0.874522      0.008508         0.112667        0.000833   \n",
       "1967       1.246649      0.069900         0.114459        0.003921   \n",
       "1249       1.408697      0.335738         0.113080        0.001698   \n",
       "1757       0.939249      0.004742         0.103511        0.000758   \n",
       "1916       0.996610      0.017258         0.106048        0.002964   \n",
       "1873       0.871623      0.010311         0.104613        0.000707   \n",
       "1733       0.921179      0.003043         0.103079        0.000449   \n",
       "932        1.023331      0.320061         0.112998        0.002264   \n",
       "1965       1.178353      0.028323         0.113529        0.008736   \n",
       "1934       1.074261      0.022438         0.110129        0.001621   \n",
       "1958       1.212478      0.089578         0.120485        0.016126   \n",
       "1977       1.085747      0.011293         0.104824        0.001167   \n",
       "790        0.912594      0.043003         0.125086        0.012163   \n",
       "1728       0.969764      0.006170         0.104657        0.001410   \n",
       "26         0.848925      0.012358         0.117771        0.003938   \n",
       "1247       1.126699      0.007119         0.110831        0.001022   \n",
       "\n",
       "     param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "1648               linear                    0.3                8   \n",
       "1732               linear                    0.3               15   \n",
       "1828               linear                    0.6                8   \n",
       "1683               linear                    0.3               10   \n",
       "1147         hard_sigmoid                    0.6               10   \n",
       "1967               linear                    0.6               18   \n",
       "1249         hard_sigmoid                    0.6               18   \n",
       "1757               linear                    0.3               15   \n",
       "1916               linear                    0.6               15   \n",
       "1873               linear                    0.6               12   \n",
       "1733               linear                    0.3               15   \n",
       "932          hard_sigmoid                    0.3                8   \n",
       "1965               linear                    0.6               18   \n",
       "1934               linear                    0.6               15   \n",
       "1958               linear                    0.6               18   \n",
       "1977               linear                    0.6               18   \n",
       "790          hard_sigmoid                      0               10   \n",
       "1728               linear                    0.3               15   \n",
       "26                sigmoid                      0                8   \n",
       "1247         hard_sigmoid                    0.6               18   \n",
       "\n",
       "     param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "1648                36                Adam                           3   \n",
       "1732                12                Adam                           3   \n",
       "1828                36                Adam                           3   \n",
       "1683                36                Adam                           1   \n",
       "1147                40             RMSprop                           3   \n",
       "1967                30                Adam                           5   \n",
       "1249                36             RMSprop                           3   \n",
       "1757                36                Adam                           5   \n",
       "1916                18             RMSprop                           5   \n",
       "1873                12             RMSprop                           3   \n",
       "1733                12                Adam                           5   \n",
       "932                 40             RMSprop                           5   \n",
       "1965                30                Adam                           1   \n",
       "1934                36             RMSprop                           5   \n",
       "1958                24             RMSprop                           5   \n",
       "1977                40                Adam                           1   \n",
       "790                 40                Adam                           3   \n",
       "1728                12             RMSprop                           1   \n",
       "26                  36             RMSprop                           5   \n",
       "1247                30                Adam                           5   \n",
       "\n",
       "                                                 params  \\\n",
       "1648  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1732  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1828  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1683  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1147  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1967  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1249  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1757  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1916  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1873  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1733  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "932   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1965  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1934  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1958  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1977  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "790   {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "1728  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "26    {'nn__activation': 'sigmoid', 'nn__dropout_rat...   \n",
       "1247  {'nn__activation': 'hard_sigmoid', 'nn__dropou...   \n",
       "\n",
       "      split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1648                 -0.667990                 -0.671304   \n",
       "1732                 -0.671125                 -0.671530   \n",
       "1828                 -0.669233                 -0.672437   \n",
       "1683                 -0.669233                 -0.672677   \n",
       "1147                 -0.670200                 -0.672712   \n",
       "1967                 -0.670564                 -0.672294   \n",
       "1249                 -0.671396                 -0.671077   \n",
       "1757                 -0.669046                 -0.672297   \n",
       "1916                 -0.670960                 -0.671626   \n",
       "1873                 -0.671955                 -0.671238   \n",
       "1733                 -0.670706                 -0.672330   \n",
       "932                  -0.671041                 -0.671874   \n",
       "1965                 -0.672623                 -0.671722   \n",
       "1934                 -0.670762                 -0.672479   \n",
       "1958                 -0.672012                 -0.673103   \n",
       "1977                 -0.671674                 -0.671666   \n",
       "790                  -0.669985                 -0.671224   \n",
       "1728                 -0.670421                 -0.672993   \n",
       "26                   -0.670706                 -0.671857   \n",
       "1247                 -0.670583                 -0.671629   \n",
       "\n",
       "      split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1648                 -0.681146               -0.673480               0.005587   \n",
       "1732                 -0.678915               -0.673857               0.003580   \n",
       "1828                 -0.680127               -0.673932               0.004571   \n",
       "1683                 -0.679914               -0.673941               0.004451   \n",
       "1147                 -0.678995               -0.673969               0.003699   \n",
       "1967                 -0.679264               -0.674041               0.003760   \n",
       "1249                 -0.679764               -0.674079               0.004022   \n",
       "1757                 -0.680904               -0.674082               0.005003   \n",
       "1916                 -0.680003               -0.674196               0.004115   \n",
       "1873                 -0.679398               -0.674197               0.003689   \n",
       "1733                 -0.679629               -0.674222               0.003881   \n",
       "932                  -0.679935               -0.674283               0.004011   \n",
       "1965                 -0.678596               -0.674313               0.003050   \n",
       "1934                 -0.679802               -0.674348               0.003920   \n",
       "1958                 -0.677960               -0.674359               0.002586   \n",
       "1977                 -0.679904               -0.674415               0.003882   \n",
       "790                  -0.682035               -0.674415               0.005412   \n",
       "1728                 -0.679859               -0.674424               0.003984   \n",
       "26                   -0.680712               -0.674425               0.004470   \n",
       "1247                 -0.681087               -0.674433               0.004724   \n",
       "\n",
       "      rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1648                       1              0.592965              0.582077   \n",
       "1732                       2              0.587940              0.598827   \n",
       "1828                       3              0.597990              0.593802   \n",
       "1683                       4              0.591290              0.589615   \n",
       "1147                       5              0.588777              0.592965   \n",
       "1967                       6              0.578727              0.586265   \n",
       "1249                       7              0.583752              0.601340   \n",
       "1757                       8              0.596315              0.597152   \n",
       "1916                       9              0.598827              0.598827   \n",
       "1873                      10              0.582915              0.599665   \n",
       "1733                      11              0.582915              0.589615   \n",
       "932                       12              0.587102              0.596315   \n",
       "1965                      13              0.580402              0.600503   \n",
       "1934                      14              0.596315              0.601340   \n",
       "1958                      15              0.584590              0.601340   \n",
       "1977                      16              0.587940              0.599665   \n",
       "790                       17              0.593802              0.596315   \n",
       "1728                      18              0.588777              0.595477   \n",
       "26                        19              0.580402              0.597152   \n",
       "1247                      20              0.587102              0.603015   \n",
       "\n",
       "      split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "1648              0.568677            0.581240           0.009933   \n",
       "1732              0.570352            0.585706           0.011732   \n",
       "1828              0.556114            0.582635           0.018831   \n",
       "1683              0.548576            0.576494           0.019752   \n",
       "1147              0.572027            0.584590           0.009046   \n",
       "1967              0.560302            0.575098           0.010906   \n",
       "1249              0.558626            0.581240           0.017528   \n",
       "1757              0.555276            0.582915           0.019546   \n",
       "1916              0.558626            0.585427           0.018951   \n",
       "1873              0.557789            0.580123           0.017209   \n",
       "1733              0.567002            0.579844           0.009484   \n",
       "932               0.562814            0.582077           0.014131   \n",
       "1965              0.554439            0.578448           0.018856   \n",
       "1934              0.556114            0.584590           0.020240   \n",
       "1958              0.556951            0.580960           0.018302   \n",
       "1977              0.557789            0.581798           0.017639   \n",
       "790               0.570352            0.586823           0.011692   \n",
       "1728              0.560302            0.581519           0.015250   \n",
       "26                0.569514            0.582356           0.011368   \n",
       "1247              0.564489            0.584869           0.015807   \n",
       "\n",
       "      rank_test_accuracy  \n",
       "1648                 572  \n",
       "1732                  48  \n",
       "1828                 333  \n",
       "1683                1258  \n",
       "1147                 112  \n",
       "1967                1375  \n",
       "1249                 549  \n",
       "1757                 292  \n",
       "1916                  66  \n",
       "1873                 738  \n",
       "1733                 780  \n",
       "932                  451  \n",
       "1965                1011  \n",
       "1934                 112  \n",
       "1958                 591  \n",
       "1977                 472  \n",
       "790                   19  \n",
       "1728                 514  \n",
       "26                   389  \n",
       "1247                  96  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results = pd.DataFrame(nn_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Game Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run some models using only the rolling 40 game team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:06:30.173387Z",
     "start_time": "2021-05-10T16:06:30.139688Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:15:37.795210Z",
     "start_time": "2021-05-09T23:15:37.792018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
       "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
       "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
       "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
       "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
       "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
       "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
       "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
       "       'home_Rating.A.Pre', 'away_Rating.A.Pre', 'B2B_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:06:32.047164Z",
     "start_time": "2021-05-10T16:06:32.044136Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features =['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
    "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
    "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
    "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
    "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
    "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
    "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
    "       'home_Rating.A.Pre', 'away_Rating.A.Pre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.004644Z",
     "start_time": "2021-05-07T22:20:04.999111Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:05.572777Z",
     "start_time": "2021-05-07T22:20:05.569772Z"
    }
   },
   "outputs": [],
   "source": [
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 1, 10],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv_40 = GridSearchCV(log_40_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:09.679038Z",
     "start_time": "2021-05-07T22:20:06.429450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T14:45:09.584511Z",
     "start_time": "2021-05-10T14:45:09.555515Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677897</td>\n",
       "      <td>-0.667774</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>-0.677850</td>\n",
       "      <td>-0.669169</td>\n",
       "      <td>-0.674249</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562064</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.593575</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020442</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.678123</td>\n",
       "      <td>-0.667782</td>\n",
       "      <td>-0.678179</td>\n",
       "      <td>-0.678294</td>\n",
       "      <td>-0.669174</td>\n",
       "      <td>-0.674311</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014846</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.678123</td>\n",
       "      <td>-0.667785</td>\n",
       "      <td>-0.678179</td>\n",
       "      <td>-0.678293</td>\n",
       "      <td>-0.669174</td>\n",
       "      <td>-0.674311</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>3</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017185</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677613</td>\n",
       "      <td>-0.668763</td>\n",
       "      <td>-0.677168</td>\n",
       "      <td>-0.679307</td>\n",
       "      <td>-0.671782</td>\n",
       "      <td>-0.674927</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677746</td>\n",
       "      <td>-0.668233</td>\n",
       "      <td>-0.680027</td>\n",
       "      <td>-0.679900</td>\n",
       "      <td>-0.670958</td>\n",
       "      <td>-0.675373</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>5</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677759</td>\n",
       "      <td>-0.668236</td>\n",
       "      <td>-0.679981</td>\n",
       "      <td>-0.679990</td>\n",
       "      <td>-0.670951</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>6</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.572302</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677763</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>-0.679982</td>\n",
       "      <td>-0.679991</td>\n",
       "      <td>-0.670953</td>\n",
       "      <td>-0.675387</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.572023</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677904</td>\n",
       "      <td>-0.668691</td>\n",
       "      <td>-0.680210</td>\n",
       "      <td>-0.680296</td>\n",
       "      <td>-0.671408</td>\n",
       "      <td>-0.675702</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>8</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.569788</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.016982</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677739</td>\n",
       "      <td>-0.668911</td>\n",
       "      <td>-0.680817</td>\n",
       "      <td>-0.680721</td>\n",
       "      <td>-0.671601</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>9</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.569509</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.026711</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677740</td>\n",
       "      <td>-0.668912</td>\n",
       "      <td>-0.680813</td>\n",
       "      <td>-0.680733</td>\n",
       "      <td>-0.671600</td>\n",
       "      <td>-0.675960</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>10</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.569509</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.013546      0.000548         0.008087        0.000554   \n",
       "5        0.020442      0.000386         0.007603        0.000155   \n",
       "4        0.014846      0.000243         0.008650        0.002275   \n",
       "6        0.017185      0.001476         0.007465        0.000029   \n",
       "9        0.014779      0.000584         0.007444        0.000062   \n",
       "10       0.019531      0.000411         0.007489        0.000063   \n",
       "11       0.025096      0.000453         0.007748        0.000268   \n",
       "12       0.029974      0.005265         0.007823        0.000163   \n",
       "15       0.016982      0.000966         0.008524        0.000234   \n",
       "17       0.026711      0.001629         0.007940        0.000586   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "3                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "4                         0.01                                   None   \n",
       "6                          0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "12                           1                                   None   \n",
       "15                           1                                   None   \n",
       "17                           1                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "3                                 l2                        liblinear   \n",
       "5                                 l2                        newton-cg   \n",
       "4                                 l2                            lbfgs   \n",
       "6                                 l1                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "12                                l1                        liblinear   \n",
       "15                                l2                        liblinear   \n",
       "17                                l2                        newton-cg   \n",
       "\n",
       "                                               params  \\\n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "3                  -0.677897                 -0.667774   \n",
       "5                  -0.678123                 -0.667782   \n",
       "4                  -0.678123                 -0.667785   \n",
       "6                  -0.677613                 -0.668763   \n",
       "9                  -0.677746                 -0.668233   \n",
       "10                 -0.677759                 -0.668236   \n",
       "11                 -0.677763                 -0.668245   \n",
       "12                 -0.677904                 -0.668691   \n",
       "15                 -0.677739                 -0.668911   \n",
       "17                 -0.677740                 -0.668912   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "3                  -0.678553                 -0.677850   \n",
       "5                  -0.678179                 -0.678294   \n",
       "4                  -0.678179                 -0.678293   \n",
       "6                  -0.677168                 -0.679307   \n",
       "9                  -0.680027                 -0.679900   \n",
       "10                 -0.679981                 -0.679990   \n",
       "11                 -0.679982                 -0.679991   \n",
       "12                 -0.680210                 -0.680296   \n",
       "15                 -0.680817                 -0.680721   \n",
       "17                 -0.680813                 -0.680733   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "3                  -0.669169               -0.674249               0.004744   \n",
       "5                  -0.669174               -0.674311               0.004783   \n",
       "4                  -0.669174               -0.674311               0.004782   \n",
       "6                  -0.671782               -0.674927               0.003983   \n",
       "9                  -0.670958               -0.675373               0.004863   \n",
       "10                 -0.670951               -0.675383               0.004873   \n",
       "11                 -0.670953               -0.675387               0.004871   \n",
       "12                 -0.671408               -0.675702               0.004772   \n",
       "15                 -0.671601               -0.675958               0.004860   \n",
       "17                 -0.671600               -0.675960               0.004862   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "3                        1              0.562064              0.595537   \n",
       "5                        2              0.564854              0.589958   \n",
       "4                        3              0.564854              0.589958   \n",
       "6                        4              0.567643              0.587169   \n",
       "9                        5              0.573222              0.587169   \n",
       "10                       6              0.573222              0.587169   \n",
       "11                       7              0.571827              0.587169   \n",
       "12                       8              0.571827              0.587169   \n",
       "15                       9              0.570432              0.585774   \n",
       "17                      10              0.570432              0.585774   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "3               0.593575              0.568436              0.574022   \n",
       "5               0.594972              0.571229              0.574022   \n",
       "4               0.594972              0.571229              0.574022   \n",
       "6               0.608939              0.554469              0.576816   \n",
       "9               0.585196              0.551676              0.565642   \n",
       "10              0.585196              0.551676              0.564246   \n",
       "11              0.585196              0.551676              0.564246   \n",
       "12              0.579609              0.546089              0.564246   \n",
       "15              0.579609              0.548883              0.562849   \n",
       "17              0.579609              0.548883              0.562849   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "3             0.578727           0.013481                   4  \n",
       "5             0.579007           0.011493                   1  \n",
       "4             0.579007           0.011493                   1  \n",
       "6             0.579007           0.018431                   1  \n",
       "9             0.572581           0.013096                   5  \n",
       "10            0.572302           0.013255                   6  \n",
       "11            0.572023           0.013247                   7  \n",
       "12            0.569788           0.014107                   8  \n",
       "15            0.569509           0.012940                  10  \n",
       "17            0.569509           0.012940                  10  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_results = pd.DataFrame(log_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:20:30.131508Z",
     "start_time": "2021-05-07T22:20:30.124084Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "ada_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [.01, .1, 1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv_40 = GridSearchCV(ada_40_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:18.508263Z",
     "start_time": "2021-05-07T22:20:30.956755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                          'home_Rating.A.Pre',\n",
       "                                                                          'away_Rating.A.Pre']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.01, 0.1, 1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.103033Z",
     "start_time": "2021-05-07T22:34:19.075177Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.925709</td>\n",
       "      <td>0.638357</td>\n",
       "      <td>2.145070</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.678507</td>\n",
       "      <td>-0.672283</td>\n",
       "      <td>-0.677155</td>\n",
       "      <td>-0.678249</td>\n",
       "      <td>-0.672888</td>\n",
       "      <td>-0.675816</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.599162</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.573707</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.680541</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-0.678631</td>\n",
       "      <td>-0.675985</td>\n",
       "      <td>-0.678217</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.575654</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.559270</td>\n",
       "      <td>0.155653</td>\n",
       "      <td>2.273125</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.681224</td>\n",
       "      <td>-0.674573</td>\n",
       "      <td>-0.677922</td>\n",
       "      <td>-0.680711</td>\n",
       "      <td>-0.676703</td>\n",
       "      <td>-0.678227</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.204704</td>\n",
       "      <td>0.113358</td>\n",
       "      <td>2.208953</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682440</td>\n",
       "      <td>-0.679579</td>\n",
       "      <td>-0.682155</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.679784</td>\n",
       "      <td>-0.681057</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.574616</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.567559</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.681519</td>\n",
       "      <td>-0.684073</td>\n",
       "      <td>-0.683125</td>\n",
       "      <td>-0.681574</td>\n",
       "      <td>-0.682894</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.579847</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.212874</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>1.813163</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688093</td>\n",
       "      <td>-0.687867</td>\n",
       "      <td>-0.688317</td>\n",
       "      <td>-0.688659</td>\n",
       "      <td>-0.686559</td>\n",
       "      <td>-0.687899</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.057093</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691571</td>\n",
       "      <td>-0.691189</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>-0.691591</td>\n",
       "      <td>-0.691297</td>\n",
       "      <td>-0.691459</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.575376</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691897</td>\n",
       "      <td>-0.691110</td>\n",
       "      <td>-0.702624</td>\n",
       "      <td>-0.690811</td>\n",
       "      <td>-0.691471</td>\n",
       "      <td>-0.693583</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>8</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      37.925709      0.638357         2.145070        0.033783   \n",
       "4       0.112370      0.003209         0.015125        0.000329   \n",
       "3      37.559270      0.155653         2.273125        0.004889   \n",
       "1      38.204704      0.113358         2.208953        0.011606   \n",
       "5       0.114122      0.000884         0.014839        0.000070   \n",
       "2      31.212874      0.111837         1.813163        0.012767   \n",
       "6       0.122421      0.057093         0.015021        0.000210   \n",
       "7       0.232039      0.006414         0.015102        0.000146   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0  SVC(kernel='linear', probability=True)                     0.01   \n",
       "4                    LogisticRegression()                     0.01   \n",
       "3  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "6                    LogisticRegression()                        1   \n",
       "7                    LogisticRegression()                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "4                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "3                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "7                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.678507                 -0.672283   \n",
       "4                 -0.680541                 -0.676259   \n",
       "3                 -0.681224                 -0.674573   \n",
       "1                 -0.682440                 -0.679579   \n",
       "5                 -0.684177                 -0.681519   \n",
       "2                 -0.688093                 -0.687867   \n",
       "6                 -0.691571                 -0.691189   \n",
       "7                 -0.691897                 -0.691110   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.677155                 -0.678249   \n",
       "4                 -0.679670                 -0.678631   \n",
       "3                 -0.677922                 -0.680711   \n",
       "1                 -0.682155                 -0.681328   \n",
       "5                 -0.684073                 -0.683125   \n",
       "2                 -0.688317                 -0.688659   \n",
       "6                 -0.691649                 -0.691591   \n",
       "7                 -0.702624                 -0.690811   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.672888               -0.675816               0.002684   \n",
       "4                 -0.675985               -0.678217               0.001817   \n",
       "3                 -0.676703               -0.678227               0.002487   \n",
       "1                 -0.679784               -0.681057               0.001183   \n",
       "5                 -0.681574               -0.682894               0.001160   \n",
       "2                 -0.686559               -0.687899               0.000719   \n",
       "6                 -0.691297               -0.691459               0.000182   \n",
       "7                 -0.691471               -0.693583               0.004535   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.550907              0.577406   \n",
       "4                       2              0.569038              0.588563   \n",
       "3                       3              0.567643              0.595537   \n",
       "1                       4              0.564854              0.574616   \n",
       "5                       5              0.560669              0.588563   \n",
       "2                       6              0.543933              0.543933   \n",
       "6                       7              0.559275              0.594142   \n",
       "7                       8              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.599162              0.561453              0.579609   \n",
       "4              0.569832              0.567039              0.583799   \n",
       "3              0.608939              0.571229              0.572626   \n",
       "1              0.564246              0.568436              0.565642   \n",
       "5              0.597765              0.569832              0.582402   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "6              0.589385              0.564246              0.569832   \n",
       "7              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.573707           0.016532                   5  \n",
       "4            0.575654           0.008774                   3  \n",
       "3            0.583195           0.016198                   1  \n",
       "1            0.567559           0.003809                   6  \n",
       "5            0.579847           0.013203                   2  \n",
       "2            0.543830           0.000517                   7  \n",
       "6            0.575376           0.013873                   4  \n",
       "7            0.543830           0.000517                   7  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_40_results = pd.DataFrame(ada_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:18:56.039191Z",
     "start_time": "2021-05-09T23:18:56.029168Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=28, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_40_cv = GridSearchCV(estimator=nn_40_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T23:32:08.418829Z",
     "start_time": "2021-05-09T23:18:57.501826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd1f51841c0>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['RMSprop', 'Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:52:58.508400Z",
     "start_time": "2021-05-10T16:52:58.479278Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.026956</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.313454</td>\n",
       "      <td>0.299331</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.670244</td>\n",
       "      <td>-0.670506</td>\n",
       "      <td>-0.677651</td>\n",
       "      <td>-0.672800</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.594640</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.714656</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 8, 'nn__neurons': 36, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}</td>\n",
       "      <td>-0.669582</td>\n",
       "      <td>-0.671819</td>\n",
       "      <td>-0.677286</td>\n",
       "      <td>-0.672896</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>2</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.602178</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.017466</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.036484</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.110218</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropout_rate': 0.3, 'nn__epochs': 15, 'nn__neurons': 40, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}</td>\n",
       "      <td>-0.669712</td>\n",
       "      <td>-0.670576</td>\n",
       "      <td>-0.678738</td>\n",
       "      <td>-0.673009</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.573702</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.004689</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 24, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.669191</td>\n",
       "      <td>-0.671065</td>\n",
       "      <td>-0.678912</td>\n",
       "      <td>-0.673056</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>4</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.580681</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.841163</td>\n",
       "      <td>0.297668</td>\n",
       "      <td>0.101427</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 8, 'nn__neurons': 12, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.671780</td>\n",
       "      <td>-0.669664</td>\n",
       "      <td>-0.677814</td>\n",
       "      <td>-0.673086</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>5</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.563652</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1.156157</td>\n",
       "      <td>0.303291</td>\n",
       "      <td>0.103092</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 15, 'nn__neurons': 24, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.669714</td>\n",
       "      <td>-0.670462</td>\n",
       "      <td>-0.679106</td>\n",
       "      <td>-0.673094</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>6</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.580960</td>\n",
       "      <td>0.017784</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.954173</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 12, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.670004</td>\n",
       "      <td>-0.671762</td>\n",
       "      <td>-0.677552</td>\n",
       "      <td>-0.673106</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>7</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.107433</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.109486</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'hard_sigmoid', 'nn__dropout_rate': 0.6, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}</td>\n",
       "      <td>-0.670246</td>\n",
       "      <td>-0.670674</td>\n",
       "      <td>-0.678426</td>\n",
       "      <td>-0.673115</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>8</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.566164</td>\n",
       "      <td>0.578169</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.733315</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}</td>\n",
       "      <td>-0.669381</td>\n",
       "      <td>-0.670897</td>\n",
       "      <td>-0.679089</td>\n",
       "      <td>-0.673122</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>9</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.770164</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.313379</td>\n",
       "      <td>0.301552</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 12, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}</td>\n",
       "      <td>-0.670948</td>\n",
       "      <td>-0.670709</td>\n",
       "      <td>-0.677717</td>\n",
       "      <td>-0.673125</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>10</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.554439</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "186       1.026956      0.006196         0.313454        0.299331   \n",
       "201       0.714656      0.003949         0.099995        0.000245   \n",
       "45        1.036484      0.007792         0.110218        0.000721   \n",
       "182       1.004689      0.007679         0.100871        0.001236   \n",
       "130       0.841163      0.297668         0.101427        0.001652   \n",
       "228       1.156157      0.303291         0.103092        0.001277   \n",
       "178       0.954173      0.001785         0.100213        0.001110   \n",
       "123       1.107433      0.005035         0.109486        0.000659   \n",
       "155       0.733315      0.002264         0.100377        0.000298   \n",
       "144       0.770164      0.000856         0.313379        0.301552   \n",
       "\n",
       "    param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "186               linear                    0.3               18   \n",
       "201               linear                    0.6                8   \n",
       "45          hard_sigmoid                    0.3               15   \n",
       "182               linear                    0.3               18   \n",
       "130               linear                    0.3                8   \n",
       "228               linear                    0.6               15   \n",
       "178               linear                    0.3               18   \n",
       "123         hard_sigmoid                    0.6               18   \n",
       "155               linear                    0.3               10   \n",
       "144               linear                    0.3               10   \n",
       "\n",
       "    param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "186                36                Adam                           1   \n",
       "201                36             RMSprop                           3   \n",
       "45                 40             RMSprop                           3   \n",
       "182                24                Adam                           1   \n",
       "130                12                Adam                           1   \n",
       "228                24             RMSprop                           1   \n",
       "178                12                Adam                           1   \n",
       "123                36                Adam                           3   \n",
       "155                36                Adam                           3   \n",
       "144                12             RMSprop                           1   \n",
       "\n",
       "                                                                                                                                                       params  \\\n",
       "186           {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}   \n",
       "201         {'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 8, 'nn__neurons': 36, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}   \n",
       "45   {'nn__activation': 'hard_sigmoid', 'nn__dropout_rate': 0.3, 'nn__epochs': 15, 'nn__neurons': 40, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}   \n",
       "182           {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 24, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}   \n",
       "130            {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 8, 'nn__neurons': 12, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}   \n",
       "228        {'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 15, 'nn__neurons': 24, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}   \n",
       "178           {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 12, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}   \n",
       "123     {'nn__activation': 'hard_sigmoid', 'nn__dropout_rate': 0.6, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}   \n",
       "155           {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}   \n",
       "144        {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 12, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}   \n",
       "\n",
       "     split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "186                 -0.670244                 -0.670506   \n",
       "201                 -0.669582                 -0.671819   \n",
       "45                  -0.669712                 -0.670576   \n",
       "182                 -0.669191                 -0.671065   \n",
       "130                 -0.671780                 -0.669664   \n",
       "228                 -0.669714                 -0.670462   \n",
       "178                 -0.670004                 -0.671762   \n",
       "123                 -0.670246                 -0.670674   \n",
       "155                 -0.669381                 -0.670897   \n",
       "144                 -0.670948                 -0.670709   \n",
       "\n",
       "     split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "186                 -0.677651               -0.672800               0.003431   \n",
       "201                 -0.677286               -0.672896               0.003236   \n",
       "45                  -0.678738               -0.673009               0.004066   \n",
       "182                 -0.678912               -0.673056               0.004211   \n",
       "130                 -0.677814               -0.673086               0.003453   \n",
       "228                 -0.679106               -0.673094               0.004262   \n",
       "178                 -0.677552               -0.673106               0.003225   \n",
       "123                 -0.678426               -0.673115               0.003759   \n",
       "155                 -0.679089               -0.673122               0.004264   \n",
       "144                 -0.677717               -0.673125               0.003249   \n",
       "\n",
       "     rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "186                       1              0.585427              0.594640   \n",
       "201                       2              0.582915              0.602178   \n",
       "45                        3              0.574539              0.595477   \n",
       "182                       4              0.585427              0.592127   \n",
       "130                       5              0.576214              0.583752   \n",
       "228                       6              0.580402              0.603015   \n",
       "178                       7              0.582077              0.595477   \n",
       "123                       8              0.572864              0.595477   \n",
       "155                       9              0.592127              0.592127   \n",
       "144                      10              0.586265              0.597152   \n",
       "\n",
       "     split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "186              0.564489            0.581519           0.012615   \n",
       "201              0.559464            0.581519           0.017466   \n",
       "45               0.573702            0.581240           0.010073   \n",
       "182              0.564489            0.580681           0.011772   \n",
       "130              0.563652            0.574539           0.008291   \n",
       "228              0.559464            0.580960           0.017784   \n",
       "178              0.567839            0.581798           0.011285   \n",
       "123              0.566164            0.578169           0.012541   \n",
       "155              0.564489            0.582915           0.013029   \n",
       "144              0.554439            0.579285           0.018123   \n",
       "\n",
       "     rank_test_accuracy  \n",
       "186                  66  \n",
       "201                  66  \n",
       "45                   79  \n",
       "182                  91  \n",
       "130                 220  \n",
       "228                  84  \n",
       "178                  61  \n",
       "123                 142  \n",
       "155                  37  \n",
       "144                 120  "
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_results = pd.DataFrame(nn_40_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Rolling Game Features With Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:19.696296Z",
     "start_time": "2021-05-07T22:34:19.667544Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T23:42:10.436891Z",
     "start_time": "2021-05-05T23:42:10.432366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 104)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:20.363708Z",
     "start_time": "2021-05-07T22:34:20.359232Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "rfecv = RFECV(estimator= LogisticRegression(max_iter =10000, penalty = 'l2', solver='liblinear', C=.1), step=1, scoring='accuracy')\n",
    "rfecv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:21.913288Z",
     "start_time": "2021-05-07T22:34:21.029546Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_last_40_FF%_5v5',\n",
       "                                                   'home_last_40_GF%_5v5',\n",
       "                                                   'home_last_40_xGF%_5v5',\n",
       "                                                   'home_last_40_SH%',\n",
       "                                                   'home_last40_xGF_per_min_pp',\n",
       "                                                   'home_last40_GF_per_min_pp',\n",
       "                                                   'home_last40_xGA_per_min_pk',\n",
       "                                                   'home_last40_GA_per_min_pk',\n",
       "                                                   'away_last_40_FF%_5v5',\n",
       "                                                   'away_...\n",
       "                                                   'home_Goalie_FenwickSV%',\n",
       "                                                   'home_Goalie_GSAx/60',\n",
       "                                                   'home_Goalie_HDCSV%',\n",
       "                                                   'away_Goalie_FenwickSV%',\n",
       "                                                   'away_Goalie_GSAx/60',\n",
       "                                                   'away_Goalie_HDCSV%',\n",
       "                                                   'home_Rating.A.Pre',\n",
       "                                                   'away_Rating.A.Pre']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['B2B_Status'])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(estimator=LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:22.591913Z",
     "start_time": "2021-05-07T22:34:22.588917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:23.322200Z",
     "start_time": "2021-05-07T22:34:23.318966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 13,  8, 18, 14,  9,  6,  2, 20, 17,  7, 10, 12, 16, 15,  1,\n",
       "        1,  5, 19, 11,  4,  1,  1,  1,  1,  1,  3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.000125Z",
     "start_time": "2021-05-07T22:34:23.992070Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last3_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>home_last_20_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_last_30_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_Rating.A.Pre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_last_10_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_last10_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_last_40_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_last40_GF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  Ranking\n",
       "0    home_last3_xGF_per_min_pp        1\n",
       "1       home_Goalie_FenwickSV%        1\n",
       "25        home_last_20_GF%_5v5        1\n",
       "24        away_last_30_GF%_5v5        1\n",
       "23           away_Rating.A.Pre        1\n",
       "22        home_last_10_FF%_5v5        1\n",
       "17  away_last10_xGF_per_min_pp        1\n",
       "16       home_last_40_xGF%_5v5        1\n",
       "26   away_last40_GF_per_min_pp        1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_results = pd.DataFrame(list(zip(X_train.columns, rfecv_pipeline[1].ranking_)), columns = ['Feature', 'Ranking']).sort_values('Ranking')\n",
    "rfecv_results.head(rfecv_pipeline[1].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:24.669318Z",
     "start_time": "2021-05-07T22:34:24.665437Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_last3_xGF_per_min_pp',\n",
       " 'home_Goalie_FenwickSV%',\n",
       " 'home_last_20_GF%_5v5',\n",
       " 'away_last_30_GF%_5v5',\n",
       " 'away_Rating.A.Pre',\n",
       " 'home_last_10_FF%_5v5',\n",
       " 'away_last10_xGF_per_min_pp',\n",
       " 'home_last_40_xGF%_5v5',\n",
       " 'away_last40_GF_per_min_pp']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = list(rfecv_results.iloc[:rfecv_pipeline[1].n_features_,0])\n",
    "rfecv_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.349708Z",
     "start_time": "2021-05-07T22:34:25.324672Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:25.925726Z",
     "start_time": "2021-05-07T22:34:25.921927Z"
    }
   },
   "outputs": [],
   "source": [
    "log_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None]}\n",
    "\n",
    "log_cv_all = GridSearchCV(log_rfecv_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:27.929642Z",
     "start_time": "2021-05-07T22:34:26.511858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_all.fit(X_train[rfecv_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:28.552604Z",
     "start_time": "2021-05-07T22:34:28.528948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.676186</td>\n",
       "      <td>-0.674550</td>\n",
       "      <td>-0.672781</td>\n",
       "      <td>-0.673968</td>\n",
       "      <td>-0.676196</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550907</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.575661</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682996</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>-0.675241</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>-0.673949</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.676232</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>3</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.682877</td>\n",
       "      <td>-0.675304</td>\n",
       "      <td>-0.675674</td>\n",
       "      <td>-0.674005</td>\n",
       "      <td>-0.673641</td>\n",
       "      <td>-0.676300</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.576497</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676038</td>\n",
       "      <td>-0.675903</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673425</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>5</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684044</td>\n",
       "      <td>-0.676037</td>\n",
       "      <td>-0.675902</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>-0.673426</td>\n",
       "      <td>-0.676503</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.684022</td>\n",
       "      <td>-0.676034</td>\n",
       "      <td>-0.675904</td>\n",
       "      <td>-0.673109</td>\n",
       "      <td>-0.673453</td>\n",
       "      <td>-0.676504</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>7</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684239</td>\n",
       "      <td>-0.676227</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>-0.672984</td>\n",
       "      <td>-0.673468</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>8</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.577057</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 20, 'logisticregress...</td>\n",
       "      <td>-0.684245</td>\n",
       "      <td>-0.676233</td>\n",
       "      <td>-0.675967</td>\n",
       "      <td>-0.672985</td>\n",
       "      <td>-0.673465</td>\n",
       "      <td>-0.676579</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>9</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576778</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>-0.684249</td>\n",
       "      <td>-0.676236</td>\n",
       "      <td>-0.675975</td>\n",
       "      <td>-0.672987</td>\n",
       "      <td>-0.673460</td>\n",
       "      <td>-0.676582</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>10</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.576499</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        0.006220      0.000130         0.003461        0.000075   \n",
       "4        0.007108      0.000076         0.003425        0.000014   \n",
       "5        0.013248      0.001218         0.004097        0.000478   \n",
       "3        0.005481      0.000175         0.003253        0.000013   \n",
       "10       0.007337      0.000301         0.003419        0.000033   \n",
       "11       0.011399      0.000528         0.003445        0.000016   \n",
       "9        0.005766      0.000048         0.003394        0.000016   \n",
       "12       0.006644      0.000130         0.003406        0.000029   \n",
       "18       0.006527      0.000311         0.003445        0.000019   \n",
       "16       0.007279      0.000221         0.003613        0.000365   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "6                          0.1                                   None   \n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "3                         0.01                                   None   \n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "12                          10                                   None   \n",
       "18                          20                                   None   \n",
       "16                          10                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "6                                 l1                        liblinear   \n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "3                                 l2                        liblinear   \n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "9                                 l2                        liblinear   \n",
       "12                                l1                        liblinear   \n",
       "18                                l1                        liblinear   \n",
       "16                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 20, 'logisticregress...   \n",
       "16  {'logisticregression__C': 10, 'logisticregress...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "6                  -0.683493                 -0.676186   \n",
       "4                  -0.682996                 -0.675241   \n",
       "5                  -0.682997                 -0.675241   \n",
       "3                  -0.682877                 -0.675304   \n",
       "10                 -0.684044                 -0.676038   \n",
       "11                 -0.684044                 -0.676037   \n",
       "9                  -0.684022                 -0.676034   \n",
       "12                 -0.684239                 -0.676227   \n",
       "18                 -0.684245                 -0.676233   \n",
       "16                 -0.684249                 -0.676236   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "6                  -0.674550                 -0.672781   \n",
       "4                  -0.675597                 -0.673949   \n",
       "5                  -0.675597                 -0.673949   \n",
       "3                  -0.675674                 -0.674005   \n",
       "10                 -0.675903                 -0.673108   \n",
       "11                 -0.675902                 -0.673108   \n",
       "9                  -0.675904                 -0.673109   \n",
       "12                 -0.675958                 -0.672984   \n",
       "18                 -0.675967                 -0.672985   \n",
       "16                 -0.675975                 -0.672987   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "6                  -0.673968               -0.676196               0.003810   \n",
       "4                  -0.673375               -0.676232               0.003479   \n",
       "5                  -0.673375               -0.676232               0.003479   \n",
       "3                  -0.673641               -0.676300               0.003376   \n",
       "10                 -0.673425               -0.676503               0.003961   \n",
       "11                 -0.673426               -0.676503               0.003961   \n",
       "9                  -0.673453               -0.676504               0.003948   \n",
       "12                 -0.673468               -0.676575               0.004045   \n",
       "18                 -0.673465               -0.676579               0.004046   \n",
       "16                 -0.673460               -0.676582               0.004048   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "6                        1              0.550907              0.581590   \n",
       "4                        2              0.546722              0.585774   \n",
       "5                        3              0.546722              0.585774   \n",
       "3                        4              0.555091              0.584379   \n",
       "10                       5              0.549512              0.585774   \n",
       "11                       6              0.549512              0.585774   \n",
       "9                        7              0.546722              0.585774   \n",
       "12                       8              0.549512              0.585774   \n",
       "18                       9              0.548117              0.585774   \n",
       "16                      10              0.548117              0.584379   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "6               0.594972              0.574022              0.576816   \n",
       "4               0.596369              0.565642              0.581006   \n",
       "5               0.596369              0.565642              0.581006   \n",
       "3               0.587989              0.575419              0.579609   \n",
       "10              0.592179              0.578212              0.581006   \n",
       "11              0.592179              0.578212              0.581006   \n",
       "9               0.589385              0.579609              0.581006   \n",
       "12              0.589385              0.579609              0.581006   \n",
       "18              0.590782              0.578212              0.581006   \n",
       "16              0.590782              0.578212              0.581006   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "6             0.575661           0.014317                  17  \n",
       "4             0.575103           0.017297                  18  \n",
       "5             0.575103           0.017297                  18  \n",
       "3             0.576497           0.011518                  16  \n",
       "10            0.577337           0.014696                   1  \n",
       "11            0.577337           0.014696                   1  \n",
       "9             0.576499           0.015289                   5  \n",
       "12            0.577057           0.014204                   3  \n",
       "18            0.576778           0.014956                   4  \n",
       "16            0.576499           0.014798                   5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_all_results = pd.DataFrame(log_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.189755Z",
     "start_time": "2021-05-07T22:34:29.164773Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:34:29.784811Z",
     "start_time": "2021-05-07T22:34:29.780602Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [ .1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression(max_iter =10000, C=.01, penalty = 'l1', solver = 'liblinear')],}\n",
    "\n",
    "ada_cv_all = GridSearchCV(ada_rfecv_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:10.420059Z",
     "start_time": "2021-05-07T22:34:30.382762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression(C=0.01,\n",
       "                                                                    max_iter=10000,\n",
       "                                                                    penalty='l1',\n",
       "                                                                    solver='liblinear')],\n",
       "                         'ada__learning_rate': [0.1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:41:11.046731Z",
     "start_time": "2021-05-07T22:41:11.023674Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.347400</td>\n",
       "      <td>0.550717</td>\n",
       "      <td>2.137133</td>\n",
       "      <td>0.103863</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683982</td>\n",
       "      <td>-0.678475</td>\n",
       "      <td>-0.679754</td>\n",
       "      <td>-0.682702</td>\n",
       "      <td>-0.681416</td>\n",
       "      <td>-0.681266</td>\n",
       "      <td>1.976734e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.567836</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.946891</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>2.113290</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684418</td>\n",
       "      <td>-0.682521</td>\n",
       "      <td>-0.682660</td>\n",
       "      <td>-0.681958</td>\n",
       "      <td>-0.682048</td>\n",
       "      <td>-0.682721</td>\n",
       "      <td>8.898324e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.560581</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      32.347400      0.550717         2.137133        0.103863   \n",
       "0      32.946891      0.287765         2.113290        0.028486   \n",
       "2       0.055528      0.000309         0.010574        0.000029   \n",
       "3       0.055622      0.000853         0.010454        0.000019   \n",
       "\n",
       "                           param_ada__base_estimator param_ada__learning_rate  \\\n",
       "1             SVC(kernel='linear', probability=True)                       10   \n",
       "0             SVC(kernel='linear', probability=True)                      0.1   \n",
       "2  LogisticRegression(C=0.01, max_iter=10000, pen...                      0.1   \n",
       "3  LogisticRegression(C=0.01, max_iter=10000, pen...                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "2                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "3                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1                 -0.683982                 -0.678475   \n",
       "0                 -0.684418                 -0.682521   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "1                 -0.679754                 -0.682702   \n",
       "0                 -0.682660                 -0.681958   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1                 -0.681416               -0.681266           1.976734e-03   \n",
       "0                 -0.682048               -0.682721           8.898324e-04   \n",
       "2                 -0.693147               -0.693147           8.599751e-17   \n",
       "3                 -0.693147               -0.693147           8.599751e-17   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1                       1              0.556485              0.591353   \n",
       "0                       2              0.553696              0.564854   \n",
       "2                       3              0.456067              0.456067   \n",
       "3                       3              0.456067              0.456067   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "1              0.574022              0.561453              0.555866   \n",
       "0              0.571229              0.553073              0.560056   \n",
       "2              0.456704              0.456704              0.455307   \n",
       "3              0.456704              0.456704              0.455307   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "1            0.567836           0.013448                   1  \n",
       "0            0.560581           0.006866                   2  \n",
       "2            0.456170           0.000517                   3  \n",
       "3            0.456170           0.000517                   3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_all_results = pd.DataFrame(ada_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:05:12.131674Z",
     "start_time": "2021-05-10T15:05:12.104136Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:05:19.035456Z",
     "start_time": "2021-05-10T15:05:19.032269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 9)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:06:56.158411Z",
     "start_time": "2021-05-10T15:06:56.146850Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='relu', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=9, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['Adam'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_all_pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_all_cv = GridSearchCV(estimator=nn_all_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:13:13.869219Z",
     "start_time": "2021-05-10T15:07:00.354032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('nn',\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd1f87d3340>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:18:05.054490Z",
     "start_time": "2021-05-10T15:18:05.031687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.728519</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.677029</td>\n",
       "      <td>-0.674050</td>\n",
       "      <td>-0.678228</td>\n",
       "      <td>-0.676436</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572027</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.573702</td>\n",
       "      <td>0.574819</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.018057</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.677144</td>\n",
       "      <td>-0.673260</td>\n",
       "      <td>-0.679239</td>\n",
       "      <td>-0.676547</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.015489</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.677608</td>\n",
       "      <td>-0.673404</td>\n",
       "      <td>-0.678655</td>\n",
       "      <td>-0.676556</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>3</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.569514</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.630642</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.096596</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.677097</td>\n",
       "      <td>-0.674750</td>\n",
       "      <td>-0.677836</td>\n",
       "      <td>-0.676561</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.574539</td>\n",
       "      <td>0.573423</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.017234</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.678790</td>\n",
       "      <td>-0.673118</td>\n",
       "      <td>-0.677963</td>\n",
       "      <td>-0.676624</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>5</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.589615</td>\n",
       "      <td>0.575377</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "108       0.728519      0.003397         0.097156        0.003177   \n",
       "125       1.018057      0.008765         0.096354        0.000784   \n",
       "124       1.015489      0.003671         0.095677        0.000542   \n",
       "102       0.630642      0.001822         0.096596        0.001702   \n",
       "92        1.017234      0.003919         0.095590        0.000813   \n",
       "\n",
       "    param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "108               linear                    0.6               10   \n",
       "125               linear                    0.6               18   \n",
       "124               linear                    0.6               18   \n",
       "102               linear                    0.6                8   \n",
       "92                linear                    0.3               18   \n",
       "\n",
       "    param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "108                36                Adam                           1   \n",
       "125                36                Adam                           3   \n",
       "124                36                Adam                           1   \n",
       "102                40                Adam                           1   \n",
       "92                 36                Adam                           1   \n",
       "\n",
       "                                                params  \\\n",
       "108  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "125  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "124  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "102  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "92   {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "\n",
       "     split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "108                 -0.677029                 -0.674050   \n",
       "125                 -0.677144                 -0.673260   \n",
       "124                 -0.677608                 -0.673404   \n",
       "102                 -0.677097                 -0.674750   \n",
       "92                  -0.678790                 -0.673118   \n",
       "\n",
       "     split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "108                 -0.678228               -0.676436               0.001756   \n",
       "125                 -0.679239               -0.676547               0.002477   \n",
       "124                 -0.678655               -0.676556               0.002269   \n",
       "102                 -0.677836               -0.676561               0.001316   \n",
       "92                  -0.677963               -0.676624               0.002502   \n",
       "\n",
       "     rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "108                       1              0.572027              0.578727   \n",
       "125                       2              0.574539              0.582077   \n",
       "124                       3              0.572864              0.576214   \n",
       "102                       4              0.564489              0.581240   \n",
       "92                        5              0.572864              0.589615   \n",
       "\n",
       "     split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "108              0.573702            0.574819           0.002847   \n",
       "125              0.568677            0.575098           0.005485   \n",
       "124              0.569514            0.572864           0.002735   \n",
       "102              0.574539            0.573423           0.006884   \n",
       "92               0.575377            0.579285           0.007376   \n",
       "\n",
       "     rank_test_accuracy  \n",
       "108                  37  \n",
       "125                  34  \n",
       "124                  64  \n",
       "102                  58  \n",
       "92                    6  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_results = pd.DataFrame(nn_all_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_all_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Models To Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will evaluate the best model iterations on the held out 2021 season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:13.753551Z",
     "start_time": "2021-05-10T16:50:13.749285Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {'Training Cross Validation Accuracy': {}, 'Training Cross Validation Log Loss': {}, 'Test Accuracy': {}, 'Test Log Loss':{}, 'Paramters':{}}\n",
    "accuracy_list = []\n",
    "log_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:15.658541Z",
     "start_time": "2021-05-10T16:50:15.618717Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, log_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, log_cv.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:17.414092Z",
     "start_time": "2021-05-10T16:50:17.373837Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_40 = log_cv_40.predict(X_test)\n",
    "\n",
    "test_probs_40 = log_cv_40.predict_proba(X_test)\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:19.152584Z",
     "start_time": "2021-05-10T16:50:19.119205Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "test_preds_rfecv = log_cv_all.predict(X_test)\n",
    "\n",
    "test_probs_rfecv = log_cv_all.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_rfecv))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_rfecv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:24.428439Z",
     "start_time": "2021-05-10T16:50:20.786664Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test,ada_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:29.522341Z",
     "start_time": "2021-05-10T16:50:26.211066Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv_40.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, ada_cv_40.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:31.309104Z",
     "start_time": "2021-05-10T16:50:31.202711Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:33.144563Z",
     "start_time": "2021-05-10T16:50:33.034152Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_40_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_40_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:50:34.982169Z",
     "start_time": "2021-05-10T16:50:34.872145Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_all_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_all_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:56:13.969878Z",
     "start_time": "2021-05-10T16:56:13.958150Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict['Test Accuracy'] = accuracy_list\n",
    "results_dict['Test Log Loss'] = log_loss_list\n",
    "models = ['5 and 40 Logistic Regression', \n",
    "          '40 Logistic Regression', \n",
    "          'rfecv Logistic Regression', \n",
    "          '5 and 40 AdaBoost', \n",
    "          '40 AdaBoost', \n",
    "          '5 and 40 Neural Network', \n",
    "          '40 Neural Network', \n",
    "          'rfecv Neural Network']\n",
    "results_dict['Training Cross Validation Accuracy'] = [log_results['mean_test_accuracy'][0], \n",
    "                               log_40_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               log_all_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               ada_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               ada_40_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               nn_results.loc[:,'mean_test_accuracy'].iloc[0],\n",
    "                              nn_40_results.loc[:,'mean_test_accuracy'].iloc[0],\n",
    "                              nn_all_results.loc[:,'mean_test_accuracy'].iloc[0]]\n",
    "results_dict['Training Cross Validation Log Loss'] = [log_cv.best_score_*-1, \n",
    "                               log_cv_40.best_score_*-1, \n",
    "                               log_cv_all.best_score_*-1, \n",
    "                               ada_cv.best_score_*-1, \n",
    "                               ada_cv_40.best_score_*-1, \n",
    "                               nn_cv.best_score_*-1, \n",
    "                               nn_40_cv.best_score_*-1, \n",
    "                               nn_all_cv.best_score_*-1]\n",
    "\n",
    "results_dict['Paramters'] = [log_results.loc[:,'params'].iloc[0], \n",
    "                               log_40_results.loc[:,'params'].iloc[0], \n",
    "                               log_all_results.loc[:,'params'].iloc[0], \n",
    "                               ada_results.loc[:,'params'].iloc[0], \n",
    "                               ada_40_results.loc[:,'params'].iloc[0], \n",
    "                               nn_results.loc[:,'params'].iloc[0],\n",
    "                              nn_40_results.loc[:,'params'].iloc[0],\n",
    "                              nn_all_results.loc[:,'params'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:56:17.890704Z",
     "start_time": "2021-05-10T16:56:17.886912Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, index = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model which had the best training cross validation log loss and test log loss was the Neural Network on the rolling 40 game features. I will save the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T16:56:21.527190Z",
     "start_time": "2021-05-10T16:56:21.511829Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Cross Validation Accuracy</th>\n",
       "      <th>Training Cross Validation Log Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Log Loss</th>\n",
       "      <th>Paramters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40 Neural Network</th>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.672800</td>\n",
       "      <td>0.598780</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 Logistic Regression</th>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.674249</td>\n",
       "      <td>0.602439</td>\n",
       "      <td>0.656803</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 Neural Network</th>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.673480</td>\n",
       "      <td>0.591463</td>\n",
       "      <td>0.660135</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 8, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv Neural Network</th>\n",
       "      <td>0.574819</td>\n",
       "      <td>0.676436</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.661108</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv Logistic Regression</th>\n",
       "      <td>0.575661</td>\n",
       "      <td>0.676196</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>0.661188</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 AdaBoost</th>\n",
       "      <td>0.573707</td>\n",
       "      <td>0.675816</td>\n",
       "      <td>0.620732</td>\n",
       "      <td>0.661381</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 0.01, 'ada__n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 Logistic Regression</th>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.675437</td>\n",
       "      <td>0.598780</td>\n",
       "      <td>0.661808</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 AdaBoost</th>\n",
       "      <td>0.574536</td>\n",
       "      <td>0.679936</td>\n",
       "      <td>0.606098</td>\n",
       "      <td>0.670984</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 10, 'ada__n_estimators': 25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Training Cross Validation Accuracy  \\\n",
       "40 Neural Network                                       0.581519   \n",
       "40 Logistic Regression                                  0.578727   \n",
       "5 and 40 Neural Network                                 0.581240   \n",
       "rfecv Neural Network                                    0.574819   \n",
       "rfecv Logistic Regression                               0.575661   \n",
       "40 AdaBoost                                             0.573707   \n",
       "5 and 40 Logistic Regression                            0.456170   \n",
       "5 and 40 AdaBoost                                       0.574536   \n",
       "\n",
       "                              Training Cross Validation Log Loss  \\\n",
       "40 Neural Network                                       0.672800   \n",
       "40 Logistic Regression                                  0.674249   \n",
       "5 and 40 Neural Network                                 0.673480   \n",
       "rfecv Neural Network                                    0.676436   \n",
       "rfecv Logistic Regression                               0.676196   \n",
       "40 AdaBoost                                             0.675816   \n",
       "5 and 40 Logistic Regression                            0.675437   \n",
       "5 and 40 AdaBoost                                       0.679936   \n",
       "\n",
       "                              Test Accuracy  Test Log Loss  \\\n",
       "40 Neural Network                  0.598780       0.655967   \n",
       "40 Logistic Regression             0.602439       0.656803   \n",
       "5 and 40 Neural Network            0.591463       0.660135   \n",
       "rfecv Neural Network               0.609756       0.661108   \n",
       "rfecv Logistic Regression          0.613415       0.661188   \n",
       "40 AdaBoost                        0.620732       0.661381   \n",
       "5 and 40 Logistic Regression       0.598780       0.661808   \n",
       "5 and 40 AdaBoost                  0.606098       0.670984   \n",
       "\n",
       "                                                                                                                                                                              Paramters  \n",
       "40 Neural Network                       {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 18, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}  \n",
       "40 Logistic Regression        {'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}  \n",
       "5 and 40 Neural Network                  {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 8, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 3}  \n",
       "rfecv Neural Network                    {'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}  \n",
       "rfecv Logistic Regression      {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}  \n",
       "40 AdaBoost                                                        {'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 0.01, 'ada__n_estimators': 25}  \n",
       "5 and 40 Logistic Regression     {'logisticregression__C': 0.001, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}  \n",
       "5 and 40 AdaBoost                                                    {'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 10, 'ada__n_estimators': 25}  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results_df.sort_values('Test Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:20:09.697049Z",
     "start_time": "2021-05-10T17:20:09.559858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save predictions and probabilites for from best model\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "pred_df = df[df['Season'] == '2020-2021'].dropna().loc[:,['game_id',\n",
    " 'date',\n",
    " 'venue',\n",
    " 'home_team',\n",
    " 'away_team',\n",
    " 'start_time',\n",
    " 'home_score',\n",
    " 'away_score',\n",
    " 'status',\n",
    " 'Home_Team_Won',\n",
    " 'Home_Team_Key',\n",
    " 'Away_Team_Key', 'home_Game_Number','away_Game_Number','home_goalie',\n",
    " 'home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_goalie',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%','home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_pp_TOI_per_game',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_pk_TOI_per_game',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk','away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_pp_TOI_per_game',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_pk_TOI_per_game',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk',\n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']]\n",
    "\n",
    "preds = nn_40_cv.predict(X_test)\n",
    "probs = nn_40_cv.predict_proba(X_test)\n",
    "\n",
    "Predictions_2021 = pd.concat([pred_df, \n",
    "                             pd.DataFrame(preds, columns = ['Prediction'], index = y_test.index ),\n",
    "                             pd.DataFrame(probs, columns = ['Away Win Probability', 'Home Win Probability'], index = y_test.index)], \n",
    "                             axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:21:24.515508Z",
     "start_time": "2021-05-10T17:21:24.480925Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>start_time</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>status</th>\n",
       "      <th>Home_Team_Won</th>\n",
       "      <th>Home_Team_Key</th>\n",
       "      <th>Away_Team_Key</th>\n",
       "      <th>home_Game_Number</th>\n",
       "      <th>away_Game_Number</th>\n",
       "      <th>home_goalie</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_goalie</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_last40_pp_TOI_per_game</th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>home_last40_pk_TOI_per_game</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last40_pp_TOI_per_game</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_pk_TOI_per_game</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>B2B_Status</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Away Win Probability</th>\n",
       "      <th>Home Win Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>2020020838</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>TD Garden</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS_2021-05-06</td>\n",
       "      <td>NYR_2021-05-06</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Jeremy Swayman</td>\n",
       "      <td>0.935086</td>\n",
       "      <td>-0.255694</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>Igor Shesterkin</td>\n",
       "      <td>0.943293</td>\n",
       "      <td>0.221547</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>55.281007</td>\n",
       "      <td>54.929673</td>\n",
       "      <td>53.113745</td>\n",
       "      <td>7.448563</td>\n",
       "      <td>5.182500</td>\n",
       "      <td>0.087844</td>\n",
       "      <td>0.096479</td>\n",
       "      <td>5.401667</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>0.087936</td>\n",
       "      <td>48.264073</td>\n",
       "      <td>54.430227</td>\n",
       "      <td>48.777665</td>\n",
       "      <td>10.050150</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>0.135397</td>\n",
       "      <td>0.153974</td>\n",
       "      <td>4.960833</td>\n",
       "      <td>0.111876</td>\n",
       "      <td>0.100790</td>\n",
       "      <td>1569.72</td>\n",
       "      <td>1512.11</td>\n",
       "      <td>Away_only</td>\n",
       "      <td>1</td>\n",
       "      <td>0.389045</td>\n",
       "      <td>0.610955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>2020020839</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Nassau Veterans Memorial Coliseum</td>\n",
       "      <td>NYI</td>\n",
       "      <td>N.J</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Final</td>\n",
       "      <td>0</td>\n",
       "      <td>NYI_2021-05-06</td>\n",
       "      <td>N.J_2021-05-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Semyon Varlamov</td>\n",
       "      <td>0.945489</td>\n",
       "      <td>0.090302</td>\n",
       "      <td>0.881020</td>\n",
       "      <td>Mackenzie Blackwood</td>\n",
       "      <td>0.929299</td>\n",
       "      <td>-0.399936</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>50.241772</td>\n",
       "      <td>57.867228</td>\n",
       "      <td>53.050836</td>\n",
       "      <td>8.805727</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>0.112976</td>\n",
       "      <td>0.093659</td>\n",
       "      <td>4.164167</td>\n",
       "      <td>0.102181</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>48.503229</td>\n",
       "      <td>41.919777</td>\n",
       "      <td>48.218609</td>\n",
       "      <td>7.979786</td>\n",
       "      <td>5.086667</td>\n",
       "      <td>0.092202</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>4.442500</td>\n",
       "      <td>0.115419</td>\n",
       "      <td>0.135059</td>\n",
       "      <td>1549.32</td>\n",
       "      <td>1439.38</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305557</td>\n",
       "      <td>0.694443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>2020020842</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>PPG Paints Arena</td>\n",
       "      <td>PIT</td>\n",
       "      <td>BUF</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT_2021-05-06</td>\n",
       "      <td>BUF_2021-05-06</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Tristan Jarry</td>\n",
       "      <td>0.929605</td>\n",
       "      <td>-0.427560</td>\n",
       "      <td>0.843672</td>\n",
       "      <td>Michael Houser</td>\n",
       "      <td>0.935086</td>\n",
       "      <td>-0.255694</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>50.360590</td>\n",
       "      <td>58.253252</td>\n",
       "      <td>49.798658</td>\n",
       "      <td>9.041652</td>\n",
       "      <td>4.222500</td>\n",
       "      <td>0.123860</td>\n",
       "      <td>0.171699</td>\n",
       "      <td>4.520833</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>0.121659</td>\n",
       "      <td>43.706600</td>\n",
       "      <td>39.713487</td>\n",
       "      <td>43.700006</td>\n",
       "      <td>7.311708</td>\n",
       "      <td>4.217917</td>\n",
       "      <td>0.076993</td>\n",
       "      <td>0.082979</td>\n",
       "      <td>4.502917</td>\n",
       "      <td>0.123698</td>\n",
       "      <td>0.127695</td>\n",
       "      <td>1556.67</td>\n",
       "      <td>1416.17</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298490</td>\n",
       "      <td>0.701510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>2020020847</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Scotiabank Arena</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MTL</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>TOR_2021-05-06</td>\n",
       "      <td>MTL_2021-05-06</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Jack Campbell</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>-0.117228</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>Jake Allen</td>\n",
       "      <td>0.937289</td>\n",
       "      <td>-0.098128</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>52.425741</td>\n",
       "      <td>57.938580</td>\n",
       "      <td>57.199725</td>\n",
       "      <td>9.228362</td>\n",
       "      <td>4.385833</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>0.085503</td>\n",
       "      <td>3.714583</td>\n",
       "      <td>0.102703</td>\n",
       "      <td>0.134605</td>\n",
       "      <td>53.658068</td>\n",
       "      <td>46.852953</td>\n",
       "      <td>51.668374</td>\n",
       "      <td>6.754951</td>\n",
       "      <td>4.255417</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>4.325417</td>\n",
       "      <td>0.118775</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>1550.15</td>\n",
       "      <td>1485.59</td>\n",
       "      <td>Away_only</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361329</td>\n",
       "      <td>0.638671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>2020020593</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Rogers Place</td>\n",
       "      <td>EDM</td>\n",
       "      <td>VAN</td>\n",
       "      <td>2021-05-07 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Final</td>\n",
       "      <td>0</td>\n",
       "      <td>EDM_2021-05-06</td>\n",
       "      <td>VAN_2021-05-06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Mike Smith</td>\n",
       "      <td>0.943015</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>Thatcher Demko</td>\n",
       "      <td>0.933794</td>\n",
       "      <td>-0.096288</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>49.044109</td>\n",
       "      <td>53.663901</td>\n",
       "      <td>49.880668</td>\n",
       "      <td>9.351147</td>\n",
       "      <td>4.523333</td>\n",
       "      <td>0.128611</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>4.334167</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>46.485886</td>\n",
       "      <td>44.299738</td>\n",
       "      <td>45.089832</td>\n",
       "      <td>7.305675</td>\n",
       "      <td>4.430417</td>\n",
       "      <td>0.105464</td>\n",
       "      <td>0.112856</td>\n",
       "      <td>5.131667</td>\n",
       "      <td>0.111075</td>\n",
       "      <td>0.116921</td>\n",
       "      <td>1536.06</td>\n",
       "      <td>1462.38</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328182</td>\n",
       "      <td>0.671818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         game_id        date                              venue home_team  \\\n",
       "4442  2020020838  2021-05-06                          TD Garden       BOS   \n",
       "4443  2020020839  2021-05-06  Nassau Veterans Memorial Coliseum       NYI   \n",
       "4444  2020020842  2021-05-06                   PPG Paints Arena       PIT   \n",
       "4445  2020020847  2021-05-06                   Scotiabank Arena       TOR   \n",
       "4446  2020020593  2021-05-06                       Rogers Place       EDM   \n",
       "\n",
       "     away_team           start_time  home_score  away_score status  \\\n",
       "4442       NYR  2021-05-06 23:00:00           4           0  Final   \n",
       "4443       N.J  2021-05-06 23:00:00           1           2  Final   \n",
       "4444       BUF  2021-05-06 23:00:00           8           4  Final   \n",
       "4445       MTL  2021-05-06 23:00:00           5           2  Final   \n",
       "4446       VAN  2021-05-07 01:00:00           3           6  Final   \n",
       "\n",
       "      Home_Team_Won   Home_Team_Key   Away_Team_Key  home_Game_Number  \\\n",
       "4442              1  BOS_2021-05-06  NYR_2021-05-06              40.0   \n",
       "4443              0  NYI_2021-05-06  N.J_2021-05-06              43.0   \n",
       "4444              1  PIT_2021-05-06  BUF_2021-05-06              48.0   \n",
       "4445              1  TOR_2021-05-06  MTL_2021-05-06              42.0   \n",
       "4446              0  EDM_2021-05-06  VAN_2021-05-06              47.0   \n",
       "\n",
       "      away_Game_Number      home_goalie  home_Goalie_FenwickSV%  \\\n",
       "4442              38.0   Jeremy Swayman                0.935086   \n",
       "4443              46.0  Semyon Varlamov                0.945489   \n",
       "4444              49.0    Tristan Jarry                0.929605   \n",
       "4445              44.0    Jack Campbell                0.938931   \n",
       "4446              47.0       Mike Smith                0.943015   \n",
       "\n",
       "      home_Goalie_GSAx/60  home_Goalie_HDCSV%          away_goalie  \\\n",
       "4442            -0.255694            0.862060      Igor Shesterkin   \n",
       "4443             0.090302            0.881020  Mackenzie Blackwood   \n",
       "4444            -0.427560            0.843672       Michael Houser   \n",
       "4445            -0.117228            0.845000           Jake Allen   \n",
       "4446             0.055221            0.874687       Thatcher Demko   \n",
       "\n",
       "      away_Goalie_FenwickSV%  away_Goalie_GSAx/60  away_Goalie_HDCSV%  \\\n",
       "4442                0.943293             0.221547            0.893805   \n",
       "4443                0.929299            -0.399936            0.837209   \n",
       "4444                0.935086            -0.255694            0.862060   \n",
       "4445                0.937289            -0.098128            0.878049   \n",
       "4446                0.933794            -0.096288            0.854626   \n",
       "\n",
       "      home_last_40_FF%_5v5  home_last_40_GF%_5v5  home_last_40_xGF%_5v5  \\\n",
       "4442             55.281007             54.929673              53.113745   \n",
       "4443             50.241772             57.867228              53.050836   \n",
       "4444             50.360590             58.253252              49.798658   \n",
       "4445             52.425741             57.938580              57.199725   \n",
       "4446             49.044109             53.663901              49.880668   \n",
       "\n",
       "      home_last_40_SH%  home_last40_pp_TOI_per_game  \\\n",
       "4442          7.448563                     5.182500   \n",
       "4443          8.805727                     4.270833   \n",
       "4444          9.041652                     4.222500   \n",
       "4445          9.228362                     4.385833   \n",
       "4446          9.351147                     4.523333   \n",
       "\n",
       "      home_last40_xGF_per_min_pp  home_last40_GF_per_min_pp  \\\n",
       "4442                    0.087844                   0.096479   \n",
       "4443                    0.112976                   0.093659   \n",
       "4444                    0.123860                   0.171699   \n",
       "4445                    0.125119                   0.085503   \n",
       "4446                    0.128611                   0.171334   \n",
       "\n",
       "      home_last40_pk_TOI_per_game  home_last40_xGA_per_min_pk  \\\n",
       "4442                     5.401667                    0.084094   \n",
       "4443                     4.164167                    0.102181   \n",
       "4444                     4.520833                    0.095945   \n",
       "4445                     3.714583                    0.102703   \n",
       "4446                     4.334167                    0.116055   \n",
       "\n",
       "      home_last40_GA_per_min_pk  away_last_40_FF%_5v5  away_last_40_GF%_5v5  \\\n",
       "4442                   0.087936             48.264073             54.430227   \n",
       "4443                   0.090054             48.503229             41.919777   \n",
       "4444                   0.121659             43.706600             39.713487   \n",
       "4445                   0.134605             53.658068             46.852953   \n",
       "4446                   0.092290             46.485886             44.299738   \n",
       "\n",
       "      away_last_40_xGF%_5v5  away_last_40_SH%  away_last40_pp_TOI_per_game  \\\n",
       "4442              48.777665         10.050150                     5.033333   \n",
       "4443              48.218609          7.979786                     5.086667   \n",
       "4444              43.700006          7.311708                     4.217917   \n",
       "4445              51.668374          6.754951                     4.255417   \n",
       "4446              45.089832          7.305675                     4.430417   \n",
       "\n",
       "      away_last40_xGF_per_min_pp  away_last40_GF_per_min_pp  \\\n",
       "4442                    0.135397                   0.153974   \n",
       "4443                    0.092202                   0.078637   \n",
       "4444                    0.076993                   0.082979   \n",
       "4445                    0.085714                   0.111622   \n",
       "4446                    0.105464                   0.112856   \n",
       "\n",
       "      away_last40_pk_TOI_per_game  away_last40_xGA_per_min_pk  \\\n",
       "4442                     4.960833                    0.111876   \n",
       "4443                     4.442500                    0.115419   \n",
       "4444                     4.502917                    0.123698   \n",
       "4445                     4.325417                    0.118775   \n",
       "4446                     5.131667                    0.111075   \n",
       "\n",
       "      away_last40_GA_per_min_pk  home_Rating.A.Pre  away_Rating.A.Pre  \\\n",
       "4442                   0.100790            1569.72            1512.11   \n",
       "4443                   0.135059            1549.32            1439.38   \n",
       "4444                   0.127695            1556.67            1416.17   \n",
       "4445                   0.138715            1550.15            1485.59   \n",
       "4446                   0.116921            1536.06            1462.38   \n",
       "\n",
       "     B2B_Status  Prediction  Away Win Probability  Home Win Probability  \n",
       "4442  Away_only           1              0.389045              0.610955  \n",
       "4443    Neither           1              0.305557              0.694443  \n",
       "4444    Neither           1              0.298490              0.701510  \n",
       "4445  Away_only           1              0.361329              0.638671  \n",
       "4446    Neither           1              0.328182              0.671818  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:24:55.752646Z",
     "start_time": "2021-05-10T17:24:55.697224Z"
    }
   },
   "outputs": [],
   "source": [
    "Predictions_2021.to_csv('data/Predictions_2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To further improve the models I would like to take the following next steps\n",
    "\n",
    "- Implement voting classifier\n",
    "- Try linear weightings in rolling features\n",
    "- Build bottom up model using player statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
