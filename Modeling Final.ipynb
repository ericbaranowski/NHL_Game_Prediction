{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Game Prediction Modeling\n",
    "by Gary Schwaeber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sports betting becoming increasingly popular and mainstream I believe that data science can be used to make superior decisions over gut intuitions. Unlike in Football or Basketball where the betting against the spread is the most popular type of betting, the moneyline is king in the NHL due to lower scoring games. When betting the moneyline, the way to gain an edge is if you know the truer probability of the game outcome then the implied odds from the moneyline. Over the course of the season, if your internally derived game probabilities are superior to the book's, you can be profitable. \n",
    "\n",
    "In this notebook I will attempt to train logistic regression, ada boost, gradient boosting, and neural network models in an attempt to make the best possible game prediction model. I will train my models and tune model hyperparemetres using game results from seasons '2017-2018', '2018-2019', '2019-2020'. Then I will predict on held out games from the current 2021 season and evaluate my model. \n",
    "\n",
    "Log loss is the score which I will use to optimize and judge the models. Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value (0 or 1 in case of binary classification). The more the predicted probability diverges from the actual value, the higher is the log-loss value, [Source](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a). There are currently a handful of public models whose log loss on the current season's games is being [tracked](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/) on which I can compare the quality of my model to.   I will also review accuracy scores due to their interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.018841Z",
     "start_time": "2021-05-11T21:51:46.824094Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import hockey_scraper\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#for the Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.154857Z",
     "start_time": "2021-05-11T21:51:53.020680Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_games_multirolling_SVA_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.160892Z",
     "start_time": "2021-05-11T21:51:53.156938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4447, 155)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.171083Z",
     "start_time": "2021-05-11T21:51:53.162887Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature columns for different rolling intervals\n",
    "\n",
    "common = ['home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%', \n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']\n",
    "\n",
    "r3 = ['home_last_3_FF%_5v5',\n",
    " 'home_last_3_GF%_5v5',\n",
    " 'home_last_3_xGF%_5v5',\n",
    " 'home_last_3_SH%',\n",
    " 'home_last3_xGF_per_min_pp',\n",
    " 'home_last3_GF_per_min_pp',\n",
    " 'home_last3_xGA_per_min_pk',\n",
    " 'home_last3_GA_per_min_pk',\n",
    " 'away_last_3_FF%_5v5',\n",
    " 'away_last_3_GF%_5v5',\n",
    " 'away_last_3_xGF%_5v5',\n",
    " 'away_last_3_SH%',\n",
    " 'away_last3_xGF_per_min_pp',\n",
    " 'away_last3_GF_per_min_pp',\n",
    " 'away_last3_xGA_per_min_pk',\n",
    " 'away_last3_GA_per_min_pk'] + common\n",
    "\n",
    "r5 =['home_last_5_FF%_5v5',\n",
    " 'home_last_5_GF%_5v5',\n",
    " 'home_last_5_xGF%_5v5',\n",
    " 'home_last_5_SH%',\n",
    " 'home_last5_xGF_per_min_pp',\n",
    " 'home_last5_GF_per_min_pp',\n",
    " 'home_last5_xGA_per_min_pk',\n",
    " 'home_last5_GA_per_min_pk',\n",
    " 'away_last_5_FF%_5v5',\n",
    " 'away_last_5_GF%_5v5',\n",
    " 'away_last_5_xGF%_5v5',\n",
    " 'away_last_5_SH%',\n",
    " 'away_last5_xGF_per_min_pp',\n",
    " 'away_last5_GF_per_min_pp',\n",
    " 'away_last5_xGA_per_min_pk',\n",
    " 'away_last5_GA_per_min_pk'] + common\n",
    "\n",
    "r10 =['home_last_10_FF%_5v5',\n",
    " 'home_last_10_GF%_5v5',\n",
    " 'home_last_10_xGF%_5v5',\n",
    " 'home_last_10_SH%',\n",
    " 'home_last10_xGF_per_min_pp',\n",
    " 'home_last10_GF_per_min_pp',\n",
    " 'home_last10_xGA_per_min_pk',\n",
    " 'home_last10_GA_per_min_pk',\n",
    "  'away_last_10_FF%_5v5',\n",
    " 'away_last_10_GF%_5v5',\n",
    " 'away_last_10_xGF%_5v5',\n",
    " 'away_last_10_SH%',\n",
    " 'away_last10_xGF_per_min_pp',\n",
    " 'away_last10_GF_per_min_pp',\n",
    " 'away_last10_xGA_per_min_pk',\n",
    " 'away_last10_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "r20 = ['home_last_20_FF%_5v5',\n",
    " 'home_last_20_GF%_5v5',\n",
    " 'home_last_20_xGF%_5v5',\n",
    " 'home_last_20_SH%',\n",
    " 'home_last20_xGF_per_min_pp',\n",
    " 'home_last20_GF_per_min_pp',\n",
    " 'home_last20_xGA_per_min_pk',\n",
    " 'home_last20_GA_per_min_pk',\n",
    " 'away_last_20_FF%_5v5',\n",
    " 'away_last_20_GF%_5v5',\n",
    " 'away_last_20_xGF%_5v5',\n",
    " 'away_last_20_SH%',\n",
    " 'away_last20_xGF_per_min_pp',\n",
    " 'away_last20_GF_per_min_pp',\n",
    " 'away_last20_xGA_per_min_pk',\n",
    " 'away_last20_GA_per_min_pk'] +common\n",
    "\n",
    "r30 = ['home_last_30_FF%_5v5',\n",
    " 'home_last_30_GF%_5v5',\n",
    " 'home_last_30_xGF%_5v5',\n",
    " 'home_last_30_SH%',\n",
    " 'home_last30_xGF_per_min_pp',\n",
    " 'home_last30_GF_per_min_pp',\n",
    " 'home_last30_xGA_per_min_pk',\n",
    " 'home_last30_GA_per_min_pk',\n",
    " 'away_last_30_FF%_5v5',\n",
    " 'away_last_30_GF%_5v5',\n",
    " 'away_last_30_xGF%_5v5',\n",
    " 'away_last_30_SH%',\n",
    " 'away_last30_xGF_per_min_pp',\n",
    " 'away_last30_GF_per_min_pp',\n",
    " 'away_last30_xGA_per_min_pk',\n",
    " 'away_last30_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "r40 = ['home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk',\n",
    " 'away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk'] + common\n",
    "\n",
    "\n",
    "all_r = list(set(r3+r5+r10+r20+r30+r40)) \n",
    "\n",
    "r3_30 =list(set(r3+r30))\n",
    "r_5_40 = list(set(r5+r40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model will predict that every home team wins their game and that the probability of that is the ratio of games the home team has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.400042Z",
     "start_time": "2021-05-11T21:51:53.172537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.541714\n",
       "0    0.458286\n",
       "Name: Home_Team_Won, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Home_Team_Won'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.406451Z",
     "start_time": "2021-05-11T21:51:53.401623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417135147290308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = np.ones(df.shape[0])\n",
    "accuracy_score(df['Home_Team_Won'],baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.414523Z",
     "start_time": "2021-05-11T21:51:53.407929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896630977766495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_probs = np.repeat(df['Home_Team_Won'].value_counts(normalize=True)[1], df.shape[0])\n",
    "\n",
    "log_loss(df['Home_Team_Won'], baseline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need to beat an accuracy score of 54.17% and a log loss of .6897, otherwise they are no better than just predicting the home team will win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling 5 and 40 game features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first set of models I will attempt using 5 and 40 game rolling features. These seemed like a good set based on the feature selection notebook. 40 games is the longest rolling runway I have for the team statistics. The 40 games stats intuitively provide the most smoothing of team data over the course of the season, while the 5 game stats may provide some insight on any streakiness or may cover recent developments that would affect short term team performances such as player injuries, trades coaching changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.443482Z",
     "start_time": "2021-05-11T21:51:53.417280Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.449497Z",
     "start_time": "2021-05-11T21:51:53.446081Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_Goalie_GSAx/60', 'home_last5_GF_per_min_pp',\n",
       "       'away_last_5_GF%_5v5', 'away_last5_GF_per_min_pp',\n",
       "       'away_last5_xGF_per_min_pp', 'away_last_40_xGF%_5v5', 'away_last_5_SH%',\n",
       "       'home_last5_xGF_per_min_pp', 'away_last5_xGA_per_min_pk',\n",
       "       'away_last_40_SH%', 'away_Rating.A.Pre', 'home_last_5_xGF%_5v5',\n",
       "       'home_last40_xGF_per_min_pp', 'home_Goalie_HDCSV%',\n",
       "       'away_last40_GF_per_min_pp', 'home_last40_GF_per_min_pp',\n",
       "       'home_last40_GA_per_min_pk', 'away_last_40_GF%_5v5',\n",
       "       'home_last_40_xGF%_5v5', 'away_last_5_FF%_5v5', 'home_last_5_SH%',\n",
       "       'away_last40_xGA_per_min_pk', 'away_last_5_xGF%_5v5',\n",
       "       'home_last40_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
       "       'away_Goalie_GSAx/60', 'away_last40_GA_per_min_pk',\n",
       "       'away_last5_GA_per_min_pk', 'home_Goalie_FenwickSV%',\n",
       "       'away_last40_xGF_per_min_pp', 'home_last_5_GF%_5v5',\n",
       "       'away_Goalie_HDCSV%', 'home_last5_GA_per_min_pk',\n",
       "       'home_last_40_GF%_5v5', 'home_Rating.A.Pre', 'away_last_40_FF%_5v5',\n",
       "       'away_Goalie_FenwickSV%', 'B2B_Status', 'home_last_5_FF%_5v5',\n",
       "       'home_last5_xGA_per_min_pk', 'home_last_40_SH%'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.453840Z",
     "start_time": "2021-05-11T21:51:53.451068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 41)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.458735Z",
     "start_time": "2021-05-11T21:51:53.455401Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['home_last40_xGF_per_min_pp', 'away_last_5_xGF%_5v5',\n",
    "       'home_last_40_GF%_5v5',\n",
    "       'home_last40_xGA_per_min_pk', 'home_last5_xGA_per_min_pk',\n",
    "       'home_last_40_SH%', \n",
    "       'home_Goalie_GSAx/60',\n",
    "        'away_Goalie_GSAx/60',\n",
    "       'away_last_5_GF%_5v5', \n",
    "       'home_last_40_xGF%_5v5', \n",
    "     'home_last5_GF_per_min_pp',\n",
    "       'home_last_5_GF%_5v5', 'home_last_5_FF%_5v5',\n",
    "       'away_last5_xGF_per_min_pp', 'away_last40_xGF_per_min_pp',\n",
    "       'home_last40_GA_per_min_pk', 'home_Goalie_HDCSV%',\n",
    "       'away_last5_GA_per_min_pk', 'away_last40_GF_per_min_pp',\n",
    "       'away_Rating.A.Pre', 'home_last_5_xGF%_5v5', 'away_last_5_SH%',\n",
    "       'home_Rating.A.Pre', 'home_last5_xGF_per_min_pp',\n",
    "       'away_last_40_xGF%_5v5', 'home_last5_GA_per_min_pk',\n",
    "     'away_last5_GF_per_min_pp',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_SH%', 'away_last_5_FF%_5v5',\n",
    "       'home_Goalie_FenwickSV%', 'away_Goalie_HDCSV%',\n",
    "       'away_last40_xGA_per_min_pk', 'home_last_5_SH%',\n",
    "       'away_last5_xGA_per_min_pk', 'home_last_40_FF%_5v5',\n",
    "       'away_Goalie_FenwickSV%', 'away_last_40_FF%_5v5',\n",
    "       'home_last40_GF_per_min_pp', 'away_last40_GA_per_min_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.495986Z",
     "start_time": "2021-05-11T21:51:53.460126Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last_5_xGF%_5v5</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_last_5_GF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GF_per_min_pp</th>\n",
       "      <th>home_last_5_GF%_5v5</th>\n",
       "      <th>home_last_5_FF%_5v5</th>\n",
       "      <th>away_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_last5_GA_per_min_pk</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>home_last_5_xGF%_5v5</th>\n",
       "      <th>away_last_5_SH%</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>home_last5_xGF_per_min_pp</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>home_last5_GA_per_min_pk</th>\n",
       "      <th>away_last5_GF_per_min_pp</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last_5_FF%_5v5</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last_5_SH%</th>\n",
       "      <th>away_last5_xGA_per_min_pk</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112699</td>\n",
       "      <td>48.770492</td>\n",
       "      <td>50.127801</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>9.025236</td>\n",
       "      <td>-0.202922</td>\n",
       "      <td>0.082345</td>\n",
       "      <td>45.937500</td>\n",
       "      <td>48.992719</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>57.080799</td>\n",
       "      <td>52.399869</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.195440</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>1500.66</td>\n",
       "      <td>51.663405</td>\n",
       "      <td>6.967375</td>\n",
       "      <td>1495.03</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>49.339386</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>51.399425</td>\n",
       "      <td>8.124451</td>\n",
       "      <td>52.562502</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>9.426112</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>48.803377</td>\n",
       "      <td>0.942516</td>\n",
       "      <td>49.991679</td>\n",
       "      <td>0.117297</td>\n",
       "      <td>0.121145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124909</td>\n",
       "      <td>51.204482</td>\n",
       "      <td>56.868932</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>9.060588</td>\n",
       "      <td>0.169541</td>\n",
       "      <td>-0.239655</td>\n",
       "      <td>49.927641</td>\n",
       "      <td>51.954595</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>59.064609</td>\n",
       "      <td>42.564205</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1535.17</td>\n",
       "      <td>46.860987</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>1577.10</td>\n",
       "      <td>0.143856</td>\n",
       "      <td>52.486645</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>58.184556</td>\n",
       "      <td>8.420932</td>\n",
       "      <td>46.882217</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>12.093988</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>50.828439</td>\n",
       "      <td>0.941294</td>\n",
       "      <td>50.633643</td>\n",
       "      <td>0.138139</td>\n",
       "      <td>0.086229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132248</td>\n",
       "      <td>40.305523</td>\n",
       "      <td>56.575634</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>9.025460</td>\n",
       "      <td>0.302087</td>\n",
       "      <td>-0.097423</td>\n",
       "      <td>45.427286</td>\n",
       "      <td>49.851785</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>58.385392</td>\n",
       "      <td>60.511924</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>0.120843</td>\n",
       "      <td>0.112194</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.116830</td>\n",
       "      <td>1496.85</td>\n",
       "      <td>60.180542</td>\n",
       "      <td>9.286882</td>\n",
       "      <td>1522.11</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>49.136336</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>7.879167</td>\n",
       "      <td>43.520998</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>8.478124</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>50.407241</td>\n",
       "      <td>0.938246</td>\n",
       "      <td>50.595552</td>\n",
       "      <td>0.149493</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105738</td>\n",
       "      <td>49.941995</td>\n",
       "      <td>53.260259</td>\n",
       "      <td>0.120913</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>7.970138</td>\n",
       "      <td>-0.164139</td>\n",
       "      <td>-0.080476</td>\n",
       "      <td>56.272661</td>\n",
       "      <td>52.809227</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>57.771883</td>\n",
       "      <td>54.316401</td>\n",
       "      <td>0.137242</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0.869266</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.103208</td>\n",
       "      <td>1496.86</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>6.524847</td>\n",
       "      <td>1525.37</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>50.855171</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.115979</td>\n",
       "      <td>45.246898</td>\n",
       "      <td>5.932286</td>\n",
       "      <td>51.909534</td>\n",
       "      <td>0.934447</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.093779</td>\n",
       "      <td>9.804628</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>52.890654</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>51.197815</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.131951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129293</td>\n",
       "      <td>43.637300</td>\n",
       "      <td>48.882718</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>7.303942</td>\n",
       "      <td>-0.310233</td>\n",
       "      <td>-0.346771</td>\n",
       "      <td>52.130045</td>\n",
       "      <td>54.871795</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>48.959081</td>\n",
       "      <td>52.400715</td>\n",
       "      <td>0.142088</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121801</td>\n",
       "      <td>1545.81</td>\n",
       "      <td>50.929752</td>\n",
       "      <td>7.311321</td>\n",
       "      <td>1521.29</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>50.381002</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>52.122642</td>\n",
       "      <td>7.885816</td>\n",
       "      <td>47.102597</td>\n",
       "      <td>0.933383</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>5.518246</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>55.762037</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>51.309591</td>\n",
       "      <td>0.189644</td>\n",
       "      <td>0.128468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_last40_xGF_per_min_pp  away_last_5_xGF%_5v5  home_last_40_GF%_5v5  \\\n",
       "0                    0.112699             48.770492             50.127801   \n",
       "1                    0.124909             51.204482             56.868932   \n",
       "2                    0.132248             40.305523             56.575634   \n",
       "3                    0.105738             49.941995             53.260259   \n",
       "4                    0.129293             43.637300             48.882718   \n",
       "\n",
       "   home_last40_xGA_per_min_pk  home_last5_xGA_per_min_pk  home_last_40_SH%  \\\n",
       "0                    0.104858                   0.098556          9.025236   \n",
       "1                    0.129028                   0.153383          9.060588   \n",
       "2                    0.116445                   0.131278          9.025460   \n",
       "3                    0.120913                   0.137299          7.970138   \n",
       "4                    0.084868                   0.067197          7.303942   \n",
       "\n",
       "   home_Goalie_GSAx/60  away_Goalie_GSAx/60  away_last_5_GF%_5v5  \\\n",
       "0            -0.202922             0.082345            45.937500   \n",
       "1             0.169541            -0.239655            49.927641   \n",
       "2             0.302087            -0.097423            45.427286   \n",
       "3            -0.164139            -0.080476            56.272661   \n",
       "4            -0.310233            -0.346771            52.130045   \n",
       "\n",
       "   home_last_40_xGF%_5v5  home_last5_GF_per_min_pp  home_last_5_GF%_5v5  \\\n",
       "0              48.992719                  0.095465            57.080799   \n",
       "1              51.954595                  0.299700            59.064609   \n",
       "2              49.851785                  0.190981            58.385392   \n",
       "3              52.809227                  0.043290            57.771883   \n",
       "4              54.871795                  0.297398            48.959081   \n",
       "\n",
       "   home_last_5_FF%_5v5  away_last5_xGF_per_min_pp  away_last40_xGF_per_min_pp  \\\n",
       "0            52.399869                   0.069910                    0.122400   \n",
       "1            42.564205                   0.096000                    0.102018   \n",
       "2            60.511924                   0.153218                    0.120843   \n",
       "3            54.316401                   0.137242                    0.143998   \n",
       "4            52.400715                   0.142088                    0.087855   \n",
       "\n",
       "   home_last40_GA_per_min_pk  home_Goalie_HDCSV%  away_last5_GA_per_min_pk  \\\n",
       "0                   0.137102            0.858462                  0.195440   \n",
       "1                   0.104730            0.877358                  0.040268   \n",
       "2                   0.112194            0.897778                  0.068337   \n",
       "3                   0.125595            0.869266                  0.100615   \n",
       "4                   0.101091            0.830721                  0.000000   \n",
       "\n",
       "   away_last40_GF_per_min_pp  away_Rating.A.Pre  home_last_5_xGF%_5v5  \\\n",
       "0                   0.139885            1500.66             51.663405   \n",
       "1                   0.115864            1535.17             46.860987   \n",
       "2                   0.116830            1496.85             60.180542   \n",
       "3                   0.103208            1496.86             52.571429   \n",
       "4                   0.121801            1545.81             50.929752   \n",
       "\n",
       "   away_last_5_SH%  home_Rating.A.Pre  home_last5_xGF_per_min_pp  \\\n",
       "0         6.967375            1495.03                   0.079714   \n",
       "1        11.358025            1577.10                   0.143856   \n",
       "2         9.286882            1522.11                   0.113316   \n",
       "3         6.524847            1525.37                   0.118615   \n",
       "4         7.311321            1521.29                   0.098885   \n",
       "\n",
       "   away_last_40_xGF%_5v5  home_last5_GA_per_min_pk  away_last5_GF_per_min_pp  \\\n",
       "0              49.339386                  0.054152                  0.101810   \n",
       "1              52.486645                  0.225564                  0.100000   \n",
       "2              49.136336                  0.132159                  0.166090   \n",
       "3              50.855171                  0.125962                  0.115979   \n",
       "4              50.381002                  0.036720                  0.065934   \n",
       "\n",
       "   away_last_40_GF%_5v5  away_last_40_SH%  away_last_5_FF%_5v5  \\\n",
       "0             51.399425          8.124451            52.562502   \n",
       "1             58.184556          8.420932            46.882217   \n",
       "2             50.499508          7.879167            43.520998   \n",
       "3             45.246898          5.932286            51.909534   \n",
       "4             52.122642          7.885816            47.102597   \n",
       "\n",
       "   home_Goalie_FenwickSV%  away_Goalie_HDCSV%  away_last40_xGA_per_min_pk  \\\n",
       "0                0.937294            0.873171                    0.133976   \n",
       "1                0.941904            0.864516                    0.097844   \n",
       "2                0.942492            0.878613                    0.107127   \n",
       "3                0.934447            0.848000                    0.093779   \n",
       "4                0.933383            0.839117                    0.102718   \n",
       "\n",
       "   home_last_5_SH%  away_last5_xGA_per_min_pk  home_last_40_FF%_5v5  \\\n",
       "0         9.426112                   0.074267             48.803377   \n",
       "1        12.093988                   0.109128             50.828439   \n",
       "2         8.478124                   0.112415             50.407241   \n",
       "3         9.804628                   0.086864             52.890654   \n",
       "4         5.518246                   0.107438             55.762037   \n",
       "\n",
       "   away_Goalie_FenwickSV%  away_last_40_FF%_5v5  home_last40_GF_per_min_pp  \\\n",
       "0                0.942516             49.991679                   0.117297   \n",
       "1                0.941294             50.633643                   0.138139   \n",
       "2                0.938246             50.595552                   0.149493   \n",
       "3                0.938305             51.197815                   0.099407   \n",
       "4                0.939698             51.309591                   0.189644   \n",
       "\n",
       "   away_last40_GA_per_min_pk  \n",
       "0                   0.121145  \n",
       "1                   0.086229  \n",
       "2                   0.106067  \n",
       "3                   0.131951  \n",
       "4                   0.128468  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numeric_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.500379Z",
     "start_time": "2021-05-11T21:51:53.497890Z"
    }
   },
   "outputs": [],
   "source": [
    "# this scoring variable will be used on all models.\n",
    "#The grid search results will output both scores but ultimately will use the best log loss\n",
    "scoring = ['neg_log_loss', 'accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:53.508569Z",
     "start_time": "2021-05-11T21:51:53.502244Z"
    }
   },
   "outputs": [],
   "source": [
    "#establish transformer objects for scaling the numerical features and one hot encoding the categorical feature\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "#paramters to test with the grid search\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.00001, .0001, .001, .01, .05, 0.1],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv = GridSearchCV(log_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:57.949287Z",
     "start_time": "2021-05-11T21:51:53.510128Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                   0.05, 0.1],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:57.954603Z",
     "start_time": "2021-05-11T21:51:57.951187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6754370089204439"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:57.984279Z",
     "start_time": "2021-05-11T21:51:57.956307Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012243</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671673</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673921</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.021892</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678374</td>\n",
       "      <td>-0.671674</td>\n",
       "      <td>-0.677392</td>\n",
       "      <td>-0.675825</td>\n",
       "      <td>-0.673923</td>\n",
       "      <td>-0.675437</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.592748</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>-0.678653</td>\n",
       "      <td>-0.672743</td>\n",
       "      <td>-0.678873</td>\n",
       "      <td>-0.676277</td>\n",
       "      <td>-0.675154</td>\n",
       "      <td>-0.676340</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.619247</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.587378</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.017590</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.007908</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677641</td>\n",
       "      <td>-0.668417</td>\n",
       "      <td>-0.680201</td>\n",
       "      <td>-0.678592</td>\n",
       "      <td>-0.676997</td>\n",
       "      <td>-0.676369</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.025329</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677863</td>\n",
       "      <td>-0.668443</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679093</td>\n",
       "      <td>-0.676975</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>5</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677864</td>\n",
       "      <td>-0.668444</td>\n",
       "      <td>-0.679819</td>\n",
       "      <td>-0.679094</td>\n",
       "      <td>-0.676973</td>\n",
       "      <td>-0.676439</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016978</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.678657</td>\n",
       "      <td>-0.671509</td>\n",
       "      <td>-0.677805</td>\n",
       "      <td>-0.679101</td>\n",
       "      <td>-0.675920</td>\n",
       "      <td>-0.676598</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.023284</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677721</td>\n",
       "      <td>-0.669128</td>\n",
       "      <td>-0.678904</td>\n",
       "      <td>-0.679827</td>\n",
       "      <td>-0.677732</td>\n",
       "      <td>-0.676662</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.573417</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.023851</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677728</td>\n",
       "      <td>-0.669121</td>\n",
       "      <td>-0.681685</td>\n",
       "      <td>-0.681348</td>\n",
       "      <td>-0.679935</td>\n",
       "      <td>-0.677963</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.599721</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575648</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.025571</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.05, 'logisticregre...</td>\n",
       "      <td>-0.677767</td>\n",
       "      <td>-0.669153</td>\n",
       "      <td>-0.681584</td>\n",
       "      <td>-0.681528</td>\n",
       "      <td>-0.679915</td>\n",
       "      <td>-0.677990</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       0.012243      0.000233         0.007874        0.000153   \n",
       "17       0.021892      0.001702         0.008688        0.000791   \n",
       "15       0.014150      0.000190         0.007921        0.000177   \n",
       "21       0.017590      0.000723         0.007908        0.000089   \n",
       "23       0.025329      0.003175         0.008586        0.001297   \n",
       "22       0.027196      0.008879         0.011265        0.002490   \n",
       "24       0.016978      0.000739         0.007928        0.000102   \n",
       "30       0.023284      0.002756         0.007912        0.000094   \n",
       "27       0.023851      0.001142         0.008310        0.000487   \n",
       "28       0.025571      0.001457         0.009660        0.000528   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "16                       0.001                                   None   \n",
       "17                       0.001                                   None   \n",
       "15                       0.001                                   None   \n",
       "21                        0.01                                   None   \n",
       "23                        0.01                                   None   \n",
       "22                        0.01                                   None   \n",
       "24                        0.05                                   None   \n",
       "30                         0.1                                   None   \n",
       "27                        0.05                                   None   \n",
       "28                        0.05                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "16                                l2                            lbfgs   \n",
       "17                                l2                        newton-cg   \n",
       "15                                l2                        liblinear   \n",
       "21                                l2                        liblinear   \n",
       "23                                l2                        newton-cg   \n",
       "22                                l2                            lbfgs   \n",
       "24                                l1                        liblinear   \n",
       "30                                l1                        liblinear   \n",
       "27                                l2                        liblinear   \n",
       "28                                l2                            lbfgs   \n",
       "\n",
       "                                               params  \\\n",
       "16  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "17  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "15  {'logisticregression__C': 0.001, 'logisticregr...   \n",
       "21  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "23  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "22  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "24  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "30  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "27  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "28  {'logisticregression__C': 0.05, 'logisticregre...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "16                 -0.678374                 -0.671673   \n",
       "17                 -0.678374                 -0.671674   \n",
       "15                 -0.678653                 -0.672743   \n",
       "21                 -0.677641                 -0.668417   \n",
       "23                 -0.677863                 -0.668443   \n",
       "22                 -0.677864                 -0.668444   \n",
       "24                 -0.678657                 -0.671509   \n",
       "30                 -0.677721                 -0.669128   \n",
       "27                 -0.677728                 -0.669121   \n",
       "28                 -0.677767                 -0.669153   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "16                 -0.677392                 -0.675825   \n",
       "17                 -0.677392                 -0.675825   \n",
       "15                 -0.678873                 -0.676277   \n",
       "21                 -0.680201                 -0.678592   \n",
       "23                 -0.679819                 -0.679093   \n",
       "22                 -0.679819                 -0.679094   \n",
       "24                 -0.677805                 -0.679101   \n",
       "30                 -0.678904                 -0.679827   \n",
       "27                 -0.681685                 -0.681348   \n",
       "28                 -0.681584                 -0.681528   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "16                 -0.673921               -0.675437               0.002411   \n",
       "17                 -0.673923               -0.675437               0.002410   \n",
       "15                 -0.675154               -0.676340               0.002285   \n",
       "21                 -0.676997               -0.676369               0.004120   \n",
       "23                 -0.676975               -0.676439               0.004116   \n",
       "22                 -0.676973               -0.676439               0.004116   \n",
       "24                 -0.675920               -0.676598               0.002769   \n",
       "30                 -0.677732               -0.676662               0.003849   \n",
       "27                 -0.679935               -0.677963               0.004635   \n",
       "28                 -0.679915               -0.677990               0.004632   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "16                       1              0.566248              0.592748   \n",
       "17                       2              0.566248              0.592748   \n",
       "15                       3              0.567643              0.619247   \n",
       "21                       4              0.584379              0.598326   \n",
       "23                       5              0.585774              0.594142   \n",
       "22                       6              0.585774              0.594142   \n",
       "24                       7              0.567643              0.588563   \n",
       "30                       8              0.570432              0.596932   \n",
       "27                       9              0.581590              0.599721   \n",
       "28                      10              0.577406              0.598326   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "16              0.594972              0.571229              0.578212   \n",
       "17              0.594972              0.571229              0.578212   \n",
       "15              0.594972              0.585196              0.569832   \n",
       "21              0.587989              0.565642              0.565642   \n",
       "23              0.587989              0.557263              0.569832   \n",
       "22              0.587989              0.557263              0.569832   \n",
       "24              0.596369              0.561453              0.575419   \n",
       "30              0.585196              0.561453              0.553073   \n",
       "27              0.579609              0.561453              0.555866   \n",
       "28              0.581006              0.562849              0.555866   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "16            0.580682           0.011433                   2  \n",
       "17            0.580682           0.011433                   2  \n",
       "15            0.587378           0.018843                   1  \n",
       "21            0.580396           0.012887                   4  \n",
       "23            0.579000           0.013510                   6  \n",
       "22            0.579000           0.013510                   6  \n",
       "24            0.577889           0.012936                   8  \n",
       "30            0.573417           0.015860                  13  \n",
       "27            0.575648           0.015642                  10  \n",
       "28            0.575091           0.014830                  11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_results = pd.DataFrame(log_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:51:57.990164Z",
     "start_time": "2021-05-11T21:51:57.986012Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25, 50],\n",
    "         'ada__learning_rate': [.1, 1, 10, 20],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv = GridSearchCV(ada_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:35:01.717024Z",
     "start_time": "2021-05-11T21:51:57.991896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.1, 1, 10, 20],\n",
       "                         'ada__n_estimators': [25, 50]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:35:01.721325Z",
     "start_time": "2021-05-11T22:35:01.718484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6798578897026044"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier iterations of the Ada Boost grid search tried using decision trees as a base estimator, however those models performed very poorly. Support Vector machines as the base estimator perform very well. Although the Logistic Regression models have generally been performing best so far, the Ada Boost models with Support Vector Machines as a base estimator are still outputting competitive results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:35:01.753234Z",
     "start_time": "2021-05-11T22:35:01.722794Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.614577</td>\n",
       "      <td>0.222443</td>\n",
       "      <td>2.521270</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.683102</td>\n",
       "      <td>-0.674955</td>\n",
       "      <td>-0.681145</td>\n",
       "      <td>-0.681154</td>\n",
       "      <td>-0.678933</td>\n",
       "      <td>-0.679858</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563459</td>\n",
       "      <td>0.598326</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.577608</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.737666</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>2.405483</td>\n",
       "      <td>0.165740</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684937</td>\n",
       "      <td>-0.676536</td>\n",
       "      <td>-0.682238</td>\n",
       "      <td>-0.683349</td>\n",
       "      <td>-0.680360</td>\n",
       "      <td>-0.681484</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.571190</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.630049</td>\n",
       "      <td>1.223703</td>\n",
       "      <td>2.601340</td>\n",
       "      <td>0.084959</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682767</td>\n",
       "      <td>-0.679747</td>\n",
       "      <td>-0.682376</td>\n",
       "      <td>-0.681655</td>\n",
       "      <td>-0.681343</td>\n",
       "      <td>-0.681578</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>3</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.560858</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82.776386</td>\n",
       "      <td>1.669668</td>\n",
       "      <td>4.909572</td>\n",
       "      <td>0.272084</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.684551</td>\n",
       "      <td>-0.676798</td>\n",
       "      <td>-0.682961</td>\n",
       "      <td>-0.684091</td>\n",
       "      <td>-0.680342</td>\n",
       "      <td>-0.681749</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.591353</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.570907</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684109</td>\n",
       "      <td>-0.681523</td>\n",
       "      <td>-0.684027</td>\n",
       "      <td>-0.682690</td>\n",
       "      <td>-0.682635</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.608645</td>\n",
       "      <td>1.396454</td>\n",
       "      <td>4.729361</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.685449</td>\n",
       "      <td>-0.683975</td>\n",
       "      <td>-0.684934</td>\n",
       "      <td>-0.684928</td>\n",
       "      <td>-0.684876</td>\n",
       "      <td>-0.684832</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.543551</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73.453790</td>\n",
       "      <td>3.892666</td>\n",
       "      <td>3.899523</td>\n",
       "      <td>0.248024</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.686929</td>\n",
       "      <td>-0.684355</td>\n",
       "      <td>-0.686312</td>\n",
       "      <td>-0.685958</td>\n",
       "      <td>-0.684266</td>\n",
       "      <td>-0.685564</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.544389</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.244384</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.025143</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.686993</td>\n",
       "      <td>-0.685253</td>\n",
       "      <td>-0.687152</td>\n",
       "      <td>-0.686154</td>\n",
       "      <td>-0.686353</td>\n",
       "      <td>-0.686381</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.582634</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.225959</td>\n",
       "      <td>0.817533</td>\n",
       "      <td>2.105014</td>\n",
       "      <td>0.071245</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688253</td>\n",
       "      <td>-0.688205</td>\n",
       "      <td>-0.688302</td>\n",
       "      <td>-0.688179</td>\n",
       "      <td>-0.687902</td>\n",
       "      <td>-0.688168</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>9</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.708771</td>\n",
       "      <td>0.226974</td>\n",
       "      <td>4.001605</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.689027</td>\n",
       "      <td>-0.688601</td>\n",
       "      <td>-0.688762</td>\n",
       "      <td>-0.688496</td>\n",
       "      <td>-0.688619</td>\n",
       "      <td>-0.688701</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      42.614577      0.222443         2.521270        0.012169   \n",
       "6      40.737666      0.997575         2.405483        0.165740   \n",
       "0      45.630049      1.223703         2.601340        0.084959   \n",
       "5      82.776386      1.669668         4.909572        0.272084   \n",
       "8       0.143607      0.019959         0.017970        0.003430   \n",
       "1      82.608645      1.396454         4.729361        0.080904   \n",
       "7      73.453790      3.892666         3.899523        0.248024   \n",
       "9       0.244384      0.015480         0.025143        0.002342   \n",
       "2      36.225959      0.817533         2.105014        0.071245   \n",
       "3      68.708771      0.226974         4.001605        0.033344   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "4  SVC(kernel='linear', probability=True)                       10   \n",
       "6  SVC(kernel='linear', probability=True)                       20   \n",
       "0  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5  SVC(kernel='linear', probability=True)                       10   \n",
       "8                    LogisticRegression()                      0.1   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "7  SVC(kernel='linear', probability=True)                       20   \n",
       "9                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "3  SVC(kernel='linear', probability=True)                        1   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "4                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "8                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "1                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "7                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "9                      50  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "3                      50  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.683102                 -0.674955   \n",
       "6                 -0.684937                 -0.676536   \n",
       "0                 -0.682767                 -0.679747   \n",
       "5                 -0.684551                 -0.676798   \n",
       "8                 -0.684109                 -0.681523   \n",
       "1                 -0.685449                 -0.683975   \n",
       "7                 -0.686929                 -0.684355   \n",
       "9                 -0.686993                 -0.685253   \n",
       "2                 -0.688253                 -0.688205   \n",
       "3                 -0.689027                 -0.688601   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.681145                 -0.681154   \n",
       "6                 -0.682238                 -0.683349   \n",
       "0                 -0.682376                 -0.681655   \n",
       "5                 -0.682961                 -0.684091   \n",
       "8                 -0.684027                 -0.682690   \n",
       "1                 -0.684934                 -0.684928   \n",
       "7                 -0.686312                 -0.685958   \n",
       "9                 -0.687152                 -0.686154   \n",
       "2                 -0.688302                 -0.688179   \n",
       "3                 -0.688762                 -0.688496   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.678933               -0.679858               0.002784   \n",
       "6                 -0.680360               -0.681484               0.002889   \n",
       "0                 -0.681343               -0.681578               0.001045   \n",
       "5                 -0.680342               -0.681749               0.002874   \n",
       "8                 -0.682635               -0.682997               0.000969   \n",
       "1                 -0.684876               -0.684832               0.000477   \n",
       "7                 -0.684266               -0.685564               0.001070   \n",
       "9                 -0.686353               -0.686381               0.000677   \n",
       "2                 -0.687902               -0.688168               0.000139   \n",
       "3                 -0.688619               -0.688701               0.000184   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.563459              0.598326   \n",
       "6                       2              0.545328              0.594142   \n",
       "0                       3              0.556485              0.573222   \n",
       "5                       4              0.560669              0.591353   \n",
       "8                       5              0.564854              0.594142   \n",
       "1                       6              0.543933              0.543933   \n",
       "7                       7              0.543933              0.542538   \n",
       "9                       8              0.569038              0.602510   \n",
       "2                       9              0.543933              0.543933   \n",
       "3                      10              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.586592              0.565642              0.574022   \n",
       "6              0.585196              0.564246              0.567039   \n",
       "0              0.562849              0.555866              0.555866   \n",
       "5              0.579609              0.554469              0.568436   \n",
       "8              0.597765              0.569832              0.581006   \n",
       "1              0.541899              0.541899              0.546089   \n",
       "7              0.543296              0.543296              0.548883   \n",
       "9              0.597765              0.572626              0.571229   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "3              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.577608           0.013162                   3  \n",
       "6            0.571190           0.017072                   6  \n",
       "0            0.560858           0.006720                   8  \n",
       "5            0.570907           0.013228                   7  \n",
       "8            0.581520           0.012945                   2  \n",
       "1            0.543551           0.001561                  12  \n",
       "7            0.544389           0.002290                   9  \n",
       "9            0.582634           0.014416                   1  \n",
       "2            0.543830           0.000517                  10  \n",
       "3            0.543830           0.000517                  10  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results = pd.DataFrame(ada_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:35:01.757963Z",
     "start_time": "2021-05-11T22:35:01.754730Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "gb_params = {'gb__n_estimators': [200, 400],\n",
    "         'gb__learning_rate': [.001,.01],\n",
    "         'gb__max_depth' : [3,5]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb_pipeline, param_grid=gb_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:41:48.153194Z",
     "start_time": "2021-05-11T22:35:01.763338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                                                          'away_last5_GF_per_min_pp',\n",
       "                                                                          'away_last_40_GF%_5v5',\n",
       "                                                                          'away_last_40_SH%',\n",
       "                                                                          'away_last_5_FF%_5v5', ...]),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('gb', GradientBoostingClassifier())]),\n",
       "             param_grid={'gb__learning_rate': [0.001, 0.01],\n",
       "                         'gb__max_depth': [3, 5],\n",
       "                         'gb__n_estimators': [200, 400]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:41:48.159782Z",
     "start_time": "2021-05-11T22:41:48.157064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6813146498639139"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting results are generally very poor. It seems like models decision trees as a base estimator do not work well for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:41:48.183395Z",
     "start_time": "2021-05-11T22:41:48.161248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.039086</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682641</td>\n",
       "      <td>-0.679400</td>\n",
       "      <td>-0.684327</td>\n",
       "      <td>-0.680537</td>\n",
       "      <td>-0.679668</td>\n",
       "      <td>-0.681315</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.574265</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.178907</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 3...</td>\n",
       "      <td>-0.682245</td>\n",
       "      <td>-0.681441</td>\n",
       "      <td>-0.686649</td>\n",
       "      <td>-0.682670</td>\n",
       "      <td>-0.682056</td>\n",
       "      <td>-0.683012</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>2</td>\n",
       "      <td>0.549512</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.567288</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.131786</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.684019</td>\n",
       "      <td>-0.680469</td>\n",
       "      <td>-0.688348</td>\n",
       "      <td>-0.682150</td>\n",
       "      <td>-0.684828</td>\n",
       "      <td>-0.683963</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557880</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.567563</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.385874</td>\n",
       "      <td>0.181404</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685737</td>\n",
       "      <td>-0.683565</td>\n",
       "      <td>-0.686076</td>\n",
       "      <td>-0.685384</td>\n",
       "      <td>-0.684671</td>\n",
       "      <td>-0.685087</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538354</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.069403</td>\n",
       "      <td>0.104621</td>\n",
       "      <td>0.025809</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.685429</td>\n",
       "      <td>-0.682733</td>\n",
       "      <td>-0.689635</td>\n",
       "      <td>-0.685681</td>\n",
       "      <td>-0.684922</td>\n",
       "      <td>-0.685680</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535565</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.542990</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.247091</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.686931</td>\n",
       "      <td>-0.685201</td>\n",
       "      <td>-0.688013</td>\n",
       "      <td>-0.688221</td>\n",
       "      <td>-0.685264</td>\n",
       "      <td>-0.686726</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>6</td>\n",
       "      <td>0.534170</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.550279</td>\n",
       "      <td>0.541598</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.242151</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__learning_rate': 0.001, 'gb__max_depth': ...</td>\n",
       "      <td>-0.687017</td>\n",
       "      <td>-0.686190</td>\n",
       "      <td>-0.687083</td>\n",
       "      <td>-0.687529</td>\n",
       "      <td>-0.686338</td>\n",
       "      <td>-0.686831</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>7</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.541875</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.548913</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'gb__learning_rate': 0.01, 'gb__max_depth': 5...</td>\n",
       "      <td>-0.683310</td>\n",
       "      <td>-0.688120</td>\n",
       "      <td>-0.695060</td>\n",
       "      <td>-0.690875</td>\n",
       "      <td>-0.694274</td>\n",
       "      <td>-0.690328</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.565048</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       5.039086      0.007850         0.013047        0.000277   \n",
       "5      10.178907      0.012010         0.016022        0.000314   \n",
       "6       8.131786      0.028058         0.016273        0.000238   \n",
       "1      10.385874      0.181404         0.020259        0.001276   \n",
       "3      16.069403      0.104621         0.025809        0.001443   \n",
       "2       8.247091      0.097229         0.016837        0.000760   \n",
       "0       5.242151      0.042042         0.014054        0.000876   \n",
       "7      16.548913      0.027711         0.022408        0.000389   \n",
       "\n",
       "  param_gb__learning_rate param_gb__max_depth param_gb__n_estimators  \\\n",
       "4                    0.01                   3                    200   \n",
       "5                    0.01                   3                    400   \n",
       "6                    0.01                   5                    200   \n",
       "1                   0.001                   3                    400   \n",
       "3                   0.001                   5                    400   \n",
       "2                   0.001                   5                    200   \n",
       "0                   0.001                   3                    200   \n",
       "7                    0.01                   5                    400   \n",
       "\n",
       "                                              params  \\\n",
       "4  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "5  {'gb__learning_rate': 0.01, 'gb__max_depth': 3...   \n",
       "6  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "1  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "3  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "2  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "0  {'gb__learning_rate': 0.001, 'gb__max_depth': ...   \n",
       "7  {'gb__learning_rate': 0.01, 'gb__max_depth': 5...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "4                 -0.682641                 -0.679400   \n",
       "5                 -0.682245                 -0.681441   \n",
       "6                 -0.684019                 -0.680469   \n",
       "1                 -0.685737                 -0.683565   \n",
       "3                 -0.685429                 -0.682733   \n",
       "2                 -0.686931                 -0.685201   \n",
       "0                 -0.687017                 -0.686190   \n",
       "7                 -0.683310                 -0.688120   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "4                 -0.684327                 -0.680537   \n",
       "5                 -0.686649                 -0.682670   \n",
       "6                 -0.688348                 -0.682150   \n",
       "1                 -0.686076                 -0.685384   \n",
       "3                 -0.689635                 -0.685681   \n",
       "2                 -0.688013                 -0.688221   \n",
       "0                 -0.687083                 -0.687529   \n",
       "7                 -0.695060                 -0.690875   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "4                 -0.679668               -0.681315               0.001888   \n",
       "5                 -0.682056               -0.683012               0.001861   \n",
       "6                 -0.684828               -0.683963               0.002664   \n",
       "1                 -0.684671               -0.685087               0.000892   \n",
       "3                 -0.684922               -0.685680               0.002234   \n",
       "2                 -0.685264               -0.686726               0.001296   \n",
       "0                 -0.686338               -0.686831               0.000498   \n",
       "7                 -0.694274               -0.690328               0.004298   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "4                       1              0.559275              0.570432   \n",
       "5                       2              0.549512              0.559275   \n",
       "6                       3              0.557880              0.567643   \n",
       "1                       4              0.538354              0.548117   \n",
       "3                       5              0.535565              0.559275   \n",
       "2                       6              0.534170              0.546722   \n",
       "0                       7              0.543933              0.543933   \n",
       "7                       8              0.569038              0.560669   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "4              0.590782              0.568436              0.582402   \n",
       "5              0.581006              0.572626              0.574022   \n",
       "6              0.568436              0.581006              0.562849   \n",
       "1              0.539106              0.551676              0.541899   \n",
       "3              0.526536              0.546089              0.547486   \n",
       "2              0.536313              0.540503              0.550279   \n",
       "0              0.536313              0.543296              0.541899   \n",
       "7              0.548883              0.575419              0.571229   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "4            0.574265           0.011067                   1  \n",
       "5            0.567288           0.011333                   3  \n",
       "6            0.567563           0.007713                   2  \n",
       "1            0.543831           0.005215                   5  \n",
       "3            0.542990           0.011143                   6  \n",
       "2            0.541598           0.006098                   8  \n",
       "0            0.541875           0.002878                   7  \n",
       "7            0.565048           0.009404                   4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.DataFrame(gb_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "gb_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:41:48.192669Z",
     "start_time": "2021-05-11T22:41:48.184746Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='linear', neurons = 36, dropout_rate=0.3, weight_constraint=3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=44, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# define the grid search parameters\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 12, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['sigmoid', 'hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 18, 24, 30, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3, 5],\n",
    "             'nn__dropout_rate' : [0.0,  0.3, 0.6, 0.9]}\n",
    "\n",
    "#wrap neural network in scikit learn wrapper\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_cv = GridSearchCV(estimator=nn_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.674308Z",
     "start_time": "2021-05-11T22:41:48.194146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2160 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last40_xGF_per_min_pp',\n",
       "                                                                          'away_last_5_xGF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last5_xGA_per_min_pk',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_Goalie_GSAx/60',\n",
       "                                                                          'away_Goalie_GSAx/60',\n",
       "                                                                          'away_las...\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f860dabbbe0>)]),\n",
       "             param_grid={'nn__activation': ['sigmoid', 'hard_sigmoid',\n",
       "                                            'linear'],\n",
       "                         'nn__dropout_rate': [0.0, 0.3, 0.6, 0.9],\n",
       "                         'nn__epochs': [8, 10, 12, 15, 18],\n",
       "                         'nn__neurons': [12, 18, 24, 30, 36, 40],\n",
       "                         'nn__optimizer': ['RMSprop', 'Adam'],\n",
       "                         'nn__weight_constraint': [1, 3, 5]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized Neural Network model is showing the most promising results of the 4 models. with log loss of 0.673480 compared to 0.675437 for the Logistic Regression, 0.679936 for Ada Boost , and 0.681325 for Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.698072Z",
     "start_time": "2021-05-12T00:32:11.675896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>1.083388</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.106423</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670084</td>\n",
       "      <td>-0.672037</td>\n",
       "      <td>-0.678660</td>\n",
       "      <td>-0.673594</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.561977</td>\n",
       "      <td>0.584310</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1.173387</td>\n",
       "      <td>0.142763</td>\n",
       "      <td>0.105134</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669859</td>\n",
       "      <td>-0.671422</td>\n",
       "      <td>-0.680451</td>\n",
       "      <td>-0.673911</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.551926</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0.984559</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671357</td>\n",
       "      <td>-0.670923</td>\n",
       "      <td>-0.679546</td>\n",
       "      <td>-0.673942</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>3</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>0.763118</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670359</td>\n",
       "      <td>-0.672176</td>\n",
       "      <td>-0.679355</td>\n",
       "      <td>-0.673963</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.556951</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.104931</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.672181</td>\n",
       "      <td>-0.670628</td>\n",
       "      <td>-0.679445</td>\n",
       "      <td>-0.674084</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.598827</td>\n",
       "      <td>0.565327</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1956       1.083388      0.003374         0.106423        0.000459   \n",
       "1766       1.173387      0.142763         0.105134        0.001061   \n",
       "1922       0.984559      0.003750         0.107558        0.000770   \n",
       "1656       0.763118      0.000977         0.099721        0.000794   \n",
       "1935       0.954143      0.001307         0.104931        0.000327   \n",
       "\n",
       "     param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "1956               linear                    0.6               18   \n",
       "1766               linear                    0.3               18   \n",
       "1922               linear                    0.6               15   \n",
       "1656               linear                    0.3               10   \n",
       "1935               linear                    0.6               15   \n",
       "\n",
       "     param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "1956                24             RMSprop                           1   \n",
       "1766                12             RMSprop                           5   \n",
       "1922                24             RMSprop                           5   \n",
       "1656                12             RMSprop                           1   \n",
       "1935                36                Adam                           1   \n",
       "\n",
       "                                                 params  \\\n",
       "1956  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1766  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1922  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1656  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "1935  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "\n",
       "      split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "1956                 -0.670084                 -0.672037   \n",
       "1766                 -0.669859                 -0.671422   \n",
       "1922                 -0.671357                 -0.670923   \n",
       "1656                 -0.670359                 -0.672176   \n",
       "1935                 -0.672181                 -0.670628   \n",
       "\n",
       "      split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "1956                 -0.678660               -0.673594               0.003670   \n",
       "1766                 -0.680451               -0.673911               0.004669   \n",
       "1922                 -0.679546               -0.673942               0.003967   \n",
       "1656                 -0.679355               -0.673963               0.003884   \n",
       "1935                 -0.679445               -0.674084               0.003843   \n",
       "\n",
       "      rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "1956                       1              0.587940              0.603015   \n",
       "1766                       2              0.588777              0.599665   \n",
       "1922                       3              0.592127              0.597152   \n",
       "1656                       4              0.588777              0.597990   \n",
       "1935                       5              0.587102              0.598827   \n",
       "\n",
       "      split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "1956              0.561977            0.584310           0.016949   \n",
       "1766              0.551926            0.580123           0.020427   \n",
       "1922              0.556114            0.581798           0.018277   \n",
       "1656              0.556951            0.581240           0.017581   \n",
       "1935              0.565327            0.583752           0.013880   \n",
       "\n",
       "      rank_test_accuracy  \n",
       "1956                 181  \n",
       "1766                 744  \n",
       "1922                 467  \n",
       "1656                 581  \n",
       "1935                 254  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results = pd.DataFrame(nn_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 Game Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run some models using only the rolling 40 game team stats. In the feautre selection notebook, using only 40 game rolling team stats had the best scoring using a basic Logisitic Regression model. Although the idea that including a shorter rolling period may provide the streakiness factor, it is possible that only modeling with longer term smoothing of team performance may be the most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.724866Z",
     "start_time": "2021-05-12T00:32:11.699653Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.729649Z",
     "start_time": "2021-05-12T00:32:11.726275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
       "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
       "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
       "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
       "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
       "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
       "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
       "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
       "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
       "       'home_Rating.A.Pre', 'away_Rating.A.Pre', 'B2B_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.733701Z",
     "start_time": "2021-05-12T00:32:11.731060Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features =['home_last_40_FF%_5v5', 'home_last_40_GF%_5v5', 'home_last_40_xGF%_5v5',\n",
    "       'home_last_40_SH%', 'home_last40_xGF_per_min_pp',\n",
    "       'home_last40_GF_per_min_pp', 'home_last40_xGA_per_min_pk',\n",
    "       'home_last40_GA_per_min_pk', 'away_last_40_FF%_5v5',\n",
    "       'away_last_40_GF%_5v5', 'away_last_40_xGF%_5v5', 'away_last_40_SH%',\n",
    "       'away_last40_xGF_per_min_pp', 'away_last40_GF_per_min_pp',\n",
    "       'away_last40_xGA_per_min_pk', 'away_last40_GA_per_min_pk',\n",
    "       'home_Goalie_FenwickSV%', 'home_Goalie_GSAx/60', 'home_Goalie_HDCSV%',\n",
    "       'away_Goalie_FenwickSV%', 'away_Goalie_GSAx/60', 'away_Goalie_HDCSV%',\n",
    "       'home_Rating.A.Pre', 'away_Rating.A.Pre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.739083Z",
     "start_time": "2021-05-12T00:32:11.735336Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "log_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:11.743707Z",
     "start_time": "2021-05-12T00:32:11.740529Z"
    }
   },
   "outputs": [],
   "source": [
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 1, 10],\n",
    "                'logisticregression__class_weight': [None] }\n",
    "\n",
    "log_cv_40 = GridSearchCV(log_40_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:15.054290Z",
     "start_time": "2021-05-12T00:32:11.745188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:15.085838Z",
     "start_time": "2021-05-12T00:32:15.056337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.677897</td>\n",
       "      <td>-0.667774</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>-0.677850</td>\n",
       "      <td>-0.669169</td>\n",
       "      <td>-0.674249</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562064</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.593575</td>\n",
       "      <td>0.568436</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.678123</td>\n",
       "      <td>-0.667782</td>\n",
       "      <td>-0.678179</td>\n",
       "      <td>-0.678294</td>\n",
       "      <td>-0.669174</td>\n",
       "      <td>-0.674311</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017624</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.678123</td>\n",
       "      <td>-0.667785</td>\n",
       "      <td>-0.678179</td>\n",
       "      <td>-0.678293</td>\n",
       "      <td>-0.669174</td>\n",
       "      <td>-0.674311</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>3</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.571229</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677617</td>\n",
       "      <td>-0.668766</td>\n",
       "      <td>-0.677167</td>\n",
       "      <td>-0.679306</td>\n",
       "      <td>-0.671783</td>\n",
       "      <td>-0.674928</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.579007</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677746</td>\n",
       "      <td>-0.668233</td>\n",
       "      <td>-0.680027</td>\n",
       "      <td>-0.679900</td>\n",
       "      <td>-0.670958</td>\n",
       "      <td>-0.675373</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>5</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020239</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677759</td>\n",
       "      <td>-0.668236</td>\n",
       "      <td>-0.679981</td>\n",
       "      <td>-0.679990</td>\n",
       "      <td>-0.670951</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>6</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.572302</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025984</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.677763</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>-0.679982</td>\n",
       "      <td>-0.679991</td>\n",
       "      <td>-0.670953</td>\n",
       "      <td>-0.675387</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.572023</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677890</td>\n",
       "      <td>-0.668705</td>\n",
       "      <td>-0.680209</td>\n",
       "      <td>-0.680259</td>\n",
       "      <td>-0.671406</td>\n",
       "      <td>-0.675694</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>8</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.546089</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.570067</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.016365</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677739</td>\n",
       "      <td>-0.668911</td>\n",
       "      <td>-0.680817</td>\n",
       "      <td>-0.680721</td>\n",
       "      <td>-0.671601</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>9</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.569509</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.027231</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>-0.677740</td>\n",
       "      <td>-0.668912</td>\n",
       "      <td>-0.680813</td>\n",
       "      <td>-0.680733</td>\n",
       "      <td>-0.671600</td>\n",
       "      <td>-0.675960</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>10</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.548883</td>\n",
       "      <td>0.562849</td>\n",
       "      <td>0.569509</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.015797      0.000464         0.009378        0.000589   \n",
       "5        0.021412      0.000807         0.007937        0.000286   \n",
       "4        0.017624      0.001365         0.009272        0.001054   \n",
       "6        0.019279      0.002509         0.008176        0.000784   \n",
       "9        0.015628      0.000473         0.008149        0.000324   \n",
       "10       0.020239      0.000497         0.007967        0.000537   \n",
       "11       0.025984      0.001622         0.007845        0.000375   \n",
       "12       0.027255      0.004471         0.009229        0.001175   \n",
       "15       0.016365      0.001007         0.007827        0.000251   \n",
       "17       0.027231      0.001503         0.007969        0.000218   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "3                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "4                         0.01                                   None   \n",
       "6                          0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "12                           1                                   None   \n",
       "15                           1                                   None   \n",
       "17                           1                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "3                                 l2                        liblinear   \n",
       "5                                 l2                        newton-cg   \n",
       "4                                 l2                            lbfgs   \n",
       "6                                 l1                        liblinear   \n",
       "9                                 l2                        liblinear   \n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "12                                l1                        liblinear   \n",
       "15                                l2                        liblinear   \n",
       "17                                l2                        newton-cg   \n",
       "\n",
       "                                               params  \\\n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "12  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "3                  -0.677897                 -0.667774   \n",
       "5                  -0.678123                 -0.667782   \n",
       "4                  -0.678123                 -0.667785   \n",
       "6                  -0.677617                 -0.668766   \n",
       "9                  -0.677746                 -0.668233   \n",
       "10                 -0.677759                 -0.668236   \n",
       "11                 -0.677763                 -0.668245   \n",
       "12                 -0.677890                 -0.668705   \n",
       "15                 -0.677739                 -0.668911   \n",
       "17                 -0.677740                 -0.668912   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "3                  -0.678553                 -0.677850   \n",
       "5                  -0.678179                 -0.678294   \n",
       "4                  -0.678179                 -0.678293   \n",
       "6                  -0.677167                 -0.679306   \n",
       "9                  -0.680027                 -0.679900   \n",
       "10                 -0.679981                 -0.679990   \n",
       "11                 -0.679982                 -0.679991   \n",
       "12                 -0.680209                 -0.680259   \n",
       "15                 -0.680817                 -0.680721   \n",
       "17                 -0.680813                 -0.680733   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "3                  -0.669169               -0.674249               0.004744   \n",
       "5                  -0.669174               -0.674311               0.004783   \n",
       "4                  -0.669174               -0.674311               0.004782   \n",
       "6                  -0.671783               -0.674928               0.003982   \n",
       "9                  -0.670958               -0.675373               0.004863   \n",
       "10                 -0.670951               -0.675383               0.004873   \n",
       "11                 -0.670953               -0.675387               0.004871   \n",
       "12                 -0.671406               -0.675694               0.004760   \n",
       "15                 -0.671601               -0.675958               0.004860   \n",
       "17                 -0.671600               -0.675960               0.004862   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "3                        1              0.562064              0.595537   \n",
       "5                        2              0.564854              0.589958   \n",
       "4                        3              0.564854              0.589958   \n",
       "6                        4              0.567643              0.587169   \n",
       "9                        5              0.573222              0.587169   \n",
       "10                       6              0.573222              0.587169   \n",
       "11                       7              0.571827              0.587169   \n",
       "12                       8              0.573222              0.587169   \n",
       "15                       9              0.570432              0.585774   \n",
       "17                      10              0.570432              0.585774   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "3               0.593575              0.568436              0.574022   \n",
       "5               0.594972              0.571229              0.574022   \n",
       "4               0.594972              0.571229              0.574022   \n",
       "6               0.608939              0.554469              0.576816   \n",
       "9               0.585196              0.551676              0.565642   \n",
       "10              0.585196              0.551676              0.564246   \n",
       "11              0.585196              0.551676              0.564246   \n",
       "12              0.579609              0.546089              0.564246   \n",
       "15              0.579609              0.548883              0.562849   \n",
       "17              0.579609              0.548883              0.562849   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "3             0.578727           0.013481                   4  \n",
       "5             0.579007           0.011493                   1  \n",
       "4             0.579007           0.011493                   1  \n",
       "6             0.579007           0.018431                   1  \n",
       "9             0.572581           0.013096                   5  \n",
       "10            0.572302           0.013255                   6  \n",
       "11            0.572023           0.013247                   7  \n",
       "12            0.570067           0.014158                   8  \n",
       "15            0.569509           0.012940                   9  \n",
       "17            0.569509           0.012940                   9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_40_results = pd.DataFrame(log_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:32:15.093391Z",
     "start_time": "2021-05-12T00:32:15.087677Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "ada_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [.01, .1, 1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression()],}\n",
    "\n",
    "ada_cv_40 = GridSearchCV(ada_40_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:46:43.651407Z",
     "start_time": "2021-05-12T00:32:15.095226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                                                          'home_Rating.A.Pre',\n",
       "                                                                          'away_Rating.A.Pre']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder())]),\n",
       "                                                                         ['B2B_Status'])])),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression()],\n",
       "                         'ada__learning_rate': [0.01, 0.1, 1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_40.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:46:43.681221Z",
     "start_time": "2021-05-12T00:46:43.652954Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.230205</td>\n",
       "      <td>0.071301</td>\n",
       "      <td>2.247906</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.678544</td>\n",
       "      <td>-0.672591</td>\n",
       "      <td>-0.677178</td>\n",
       "      <td>-0.677964</td>\n",
       "      <td>-0.672798</td>\n",
       "      <td>-0.675815</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.580195</td>\n",
       "      <td>0.594972</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.572311</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119884</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.680541</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-0.678631</td>\n",
       "      <td>-0.675985</td>\n",
       "      <td>-0.678217</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.575654</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.694361</td>\n",
       "      <td>0.119665</td>\n",
       "      <td>2.402361</td>\n",
       "      <td>0.015123</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.681482</td>\n",
       "      <td>-0.677015</td>\n",
       "      <td>-0.677408</td>\n",
       "      <td>-0.680627</td>\n",
       "      <td>-0.676307</td>\n",
       "      <td>-0.678568</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>3</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.579566</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.214163</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>2.327299</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682364</td>\n",
       "      <td>-0.679555</td>\n",
       "      <td>-0.681843</td>\n",
       "      <td>-0.681452</td>\n",
       "      <td>-0.679591</td>\n",
       "      <td>-0.680961</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.565884</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.123238</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.681519</td>\n",
       "      <td>-0.684073</td>\n",
       "      <td>-0.683125</td>\n",
       "      <td>-0.681574</td>\n",
       "      <td>-0.682894</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>0.579847</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.865977</td>\n",
       "      <td>0.141314</td>\n",
       "      <td>1.908890</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.688404</td>\n",
       "      <td>-0.687679</td>\n",
       "      <td>-0.687998</td>\n",
       "      <td>-0.688574</td>\n",
       "      <td>-0.688222</td>\n",
       "      <td>-0.688176</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.098325</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691571</td>\n",
       "      <td>-0.691189</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>-0.691591</td>\n",
       "      <td>-0.691297</td>\n",
       "      <td>-0.691459</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559275</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.575376</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.247690</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(), ...</td>\n",
       "      <td>-0.691897</td>\n",
       "      <td>-0.691110</td>\n",
       "      <td>-0.702624</td>\n",
       "      <td>-0.690811</td>\n",
       "      <td>-0.691471</td>\n",
       "      <td>-0.693583</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>8</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.543296</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.543830</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      39.230205      0.071301         2.247906        0.005976   \n",
       "4       0.119884      0.003862         0.016288        0.000970   \n",
       "3      39.694361      0.119665         2.402361        0.015123   \n",
       "1      40.214163      0.039122         2.327299        0.006262   \n",
       "5       0.123238      0.004518         0.016054        0.000404   \n",
       "2      32.865977      0.141314         1.908890        0.004267   \n",
       "6       0.098325      0.005258         0.016114        0.000747   \n",
       "7       0.247690      0.005661         0.016178        0.000848   \n",
       "\n",
       "                param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0  SVC(kernel='linear', probability=True)                     0.01   \n",
       "4                    LogisticRegression()                     0.01   \n",
       "3  SVC(kernel='linear', probability=True)                       10   \n",
       "1  SVC(kernel='linear', probability=True)                      0.1   \n",
       "5                    LogisticRegression()                      0.1   \n",
       "2  SVC(kernel='linear', probability=True)                        1   \n",
       "6                    LogisticRegression()                        1   \n",
       "7                    LogisticRegression()                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "4                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "3                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "5                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "2                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "6                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "7                      25  {'ada__base_estimator': LogisticRegression(), ...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.678544                 -0.672591   \n",
       "4                 -0.680541                 -0.676259   \n",
       "3                 -0.681482                 -0.677015   \n",
       "1                 -0.682364                 -0.679555   \n",
       "5                 -0.684177                 -0.681519   \n",
       "2                 -0.688404                 -0.687679   \n",
       "6                 -0.691571                 -0.691189   \n",
       "7                 -0.691897                 -0.691110   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.677178                 -0.677964   \n",
       "4                 -0.679670                 -0.678631   \n",
       "3                 -0.677408                 -0.680627   \n",
       "1                 -0.681843                 -0.681452   \n",
       "5                 -0.684073                 -0.683125   \n",
       "2                 -0.687998                 -0.688574   \n",
       "6                 -0.691649                 -0.691591   \n",
       "7                 -0.702624                 -0.690811   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.672798               -0.675815               0.002585   \n",
       "4                 -0.675985               -0.678217               0.001817   \n",
       "3                 -0.676307               -0.678568               0.002078   \n",
       "1                 -0.679591               -0.680961               0.001170   \n",
       "5                 -0.681574               -0.682894               0.001160   \n",
       "2                 -0.688222               -0.688176               0.000313   \n",
       "6                 -0.691297               -0.691459               0.000182   \n",
       "7                 -0.691471               -0.693583               0.004535   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.548117              0.580195   \n",
       "4                       2              0.569038              0.588563   \n",
       "3                       3              0.566248              0.585774   \n",
       "1                       4              0.564854              0.570432   \n",
       "5                       5              0.560669              0.588563   \n",
       "2                       6              0.543933              0.543933   \n",
       "6                       7              0.559275              0.594142   \n",
       "7                       8              0.543933              0.543933   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.594972              0.561453              0.576816   \n",
       "4              0.569832              0.567039              0.583799   \n",
       "3              0.596369              0.576816              0.572626   \n",
       "1              0.569832              0.560056              0.564246   \n",
       "5              0.597765              0.569832              0.582402   \n",
       "2              0.543296              0.543296              0.544693   \n",
       "6              0.589385              0.564246              0.569832   \n",
       "7              0.543296              0.543296              0.544693   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.572311           0.016120                   5  \n",
       "4            0.575654           0.008774                   3  \n",
       "3            0.579566           0.010526                   2  \n",
       "1            0.565884           0.003847                   6  \n",
       "5            0.579847           0.013203                   1  \n",
       "2            0.543830           0.000517                   7  \n",
       "6            0.575376           0.013873                   4  \n",
       "7            0.543830           0.000517                   7  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_40_results = pd.DataFrame(ada_cv_40.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:46:43.690409Z",
     "start_time": "2021-05-12T00:46:43.682855Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='relu', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=28, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['RMSprop', 'Adam'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_40_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_40_cv = GridSearchCV(estimator=nn_40_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.266675Z",
     "start_time": "2021-05-12T00:46:43.692304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['home_last_40_FF%_5v5',\n",
       "                                                                          'home_last_40_GF%_5v5',\n",
       "                                                                          'home_last_40_xGF%_5v5',\n",
       "                                                                          'home_last_40_SH%',\n",
       "                                                                          'home_last40_xGF_per_min_pp',\n",
       "                                                                          'home_last40_GF_per_min_pp',\n",
       "                                                                          'home_last40_xGA_per_min_pk',\n",
       "                                                                          'home_last40_GA_per_min_pk',\n",
       "                                                                          '...\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8617cce100>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['RMSprop', 'Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.293347Z",
     "start_time": "2021-05-12T01:00:24.268636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.025458</td>\n",
       "      <td>0.301492</td>\n",
       "      <td>0.112389</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669314</td>\n",
       "      <td>-0.671602</td>\n",
       "      <td>-0.676991</td>\n",
       "      <td>-0.672635</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1.092319</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.105952</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669903</td>\n",
       "      <td>-0.671140</td>\n",
       "      <td>-0.677077</td>\n",
       "      <td>-0.672707</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>2</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.561139</td>\n",
       "      <td>0.579564</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.955958</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.104754</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670733</td>\n",
       "      <td>-0.669889</td>\n",
       "      <td>-0.678207</td>\n",
       "      <td>-0.672943</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.591290</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.577610</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.691614</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.105344</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670418</td>\n",
       "      <td>-0.671872</td>\n",
       "      <td>-0.676542</td>\n",
       "      <td>-0.672944</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>4</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.587102</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.575656</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>0.107056</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669908</td>\n",
       "      <td>-0.671856</td>\n",
       "      <td>-0.677075</td>\n",
       "      <td>-0.672946</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>5</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.561139</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.881473</td>\n",
       "      <td>0.148928</td>\n",
       "      <td>0.108441</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.669646</td>\n",
       "      <td>-0.670802</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>-0.673000</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.596315</td>\n",
       "      <td>0.571189</td>\n",
       "      <td>0.584310</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.090879</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.104656</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670306</td>\n",
       "      <td>-0.671497</td>\n",
       "      <td>-0.677247</td>\n",
       "      <td>-0.673017</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>7</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.564489</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.093323</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.103517</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670147</td>\n",
       "      <td>-0.670897</td>\n",
       "      <td>-0.678094</td>\n",
       "      <td>-0.673046</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>8</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.594640</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.578169</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.749521</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.106040</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.668565</td>\n",
       "      <td>-0.671806</td>\n",
       "      <td>-0.678798</td>\n",
       "      <td>-0.673056</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>9</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>0.561977</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.050796</td>\n",
       "      <td>0.136331</td>\n",
       "      <td>0.106393</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.670279</td>\n",
       "      <td>-0.671920</td>\n",
       "      <td>-0.677174</td>\n",
       "      <td>-0.673124</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>10</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.561139</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "153       1.025458      0.301492         0.112389        0.010358   \n",
       "252       1.092319      0.007639         0.105952        0.001877   \n",
       "174       0.955958      0.003744         0.104754        0.001062   \n",
       "143       0.691614      0.006337         0.105344        0.000454   \n",
       "155       0.785075      0.007942         0.107056        0.001952   \n",
       "154       0.881473      0.148928         0.108441        0.001316   \n",
       "248       1.090879      0.001805         0.104656        0.000764   \n",
       "185       1.093323      0.010162         0.103517        0.001971   \n",
       "133       0.749521      0.003655         0.106040        0.000566   \n",
       "170       1.050796      0.136331         0.106393        0.002591   \n",
       "\n",
       "    param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "153               linear                    0.3               10   \n",
       "252               linear                    0.6               18   \n",
       "174               linear                    0.3               15   \n",
       "143               linear                    0.3                8   \n",
       "155               linear                    0.3               10   \n",
       "154               linear                    0.3               10   \n",
       "248               linear                    0.6               18   \n",
       "185               linear                    0.3               18   \n",
       "133               linear                    0.3                8   \n",
       "170               linear                    0.3               15   \n",
       "\n",
       "    param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "153                36             RMSprop                           3   \n",
       "252                40             RMSprop                           1   \n",
       "174                40                Adam                           1   \n",
       "143                40                Adam                           3   \n",
       "155                36                Adam                           3   \n",
       "154                36                Adam                           1   \n",
       "248                36             RMSprop                           1   \n",
       "185                36             RMSprop                           3   \n",
       "133                24             RMSprop                           3   \n",
       "170                36                Adam                           1   \n",
       "\n",
       "                                                params  \\\n",
       "153  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "252  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "174  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "143  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "155  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "154  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "248  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "185  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "133  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "170  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "\n",
       "     split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "153                 -0.669314                 -0.671602   \n",
       "252                 -0.669903                 -0.671140   \n",
       "174                 -0.670733                 -0.669889   \n",
       "143                 -0.670418                 -0.671872   \n",
       "155                 -0.669908                 -0.671856   \n",
       "154                 -0.669646                 -0.670802   \n",
       "248                 -0.670306                 -0.671497   \n",
       "185                 -0.670147                 -0.670897   \n",
       "133                 -0.668565                 -0.671806   \n",
       "170                 -0.670279                 -0.671920   \n",
       "\n",
       "     split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "153                 -0.676991               -0.672635               0.003218   \n",
       "252                 -0.677077               -0.672707               0.003132   \n",
       "174                 -0.678207               -0.672943               0.003738   \n",
       "143                 -0.676542               -0.672944               0.002613   \n",
       "155                 -0.677075               -0.672946               0.003026   \n",
       "154                 -0.678553               -0.673000               0.003955   \n",
       "248                 -0.677247               -0.673017               0.003031   \n",
       "185                 -0.678094               -0.673046               0.003583   \n",
       "133                 -0.678798               -0.673056               0.004270   \n",
       "170                 -0.677174               -0.673124               0.002941   \n",
       "\n",
       "     rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "153                       1              0.583752              0.597152   \n",
       "252                       2              0.585427              0.592127   \n",
       "174                       3              0.583752              0.591290   \n",
       "143                       4              0.580402              0.587102   \n",
       "155                       5              0.584590              0.586265   \n",
       "154                       6              0.585427              0.596315   \n",
       "248                       7              0.582077              0.599665   \n",
       "185                       8              0.580402              0.594640   \n",
       "133                       9              0.583752              0.599665   \n",
       "170                      10              0.583752              0.595477   \n",
       "\n",
       "     split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "153              0.551089            0.577331           0.019346   \n",
       "252              0.561139            0.579564           0.013313   \n",
       "174              0.557789            0.577610           0.014350   \n",
       "143              0.559464            0.575656           0.011772   \n",
       "155              0.561139            0.577331           0.011470   \n",
       "154              0.571189            0.584310           0.010288   \n",
       "248              0.564489            0.582077           0.014360   \n",
       "185              0.559464            0.578169           0.014447   \n",
       "133              0.561977            0.581798           0.015448   \n",
       "170              0.561139            0.580123           0.014252   \n",
       "\n",
       "     rank_test_accuracy  \n",
       "153                 173  \n",
       "252                 111  \n",
       "174                 167  \n",
       "143                 200  \n",
       "155                 173  \n",
       "154                  12  \n",
       "248                  48  \n",
       "185                 147  \n",
       "133                  57  \n",
       "170                  93  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_40_results = pd.DataFrame(nn_40_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_40_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the 40 game rolling features set has generally produced superior scoring in the models, with the Neural Network model on the 40 game rolling features scoring best on cross validation with a log loss of 0.672800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Rolling Game Features With Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now attempt using Recursive Feature Elimination on all different rolling game options (3,5,10,20,30,40) to see if there is some mix of features that the RFECV can find patterns for. I will then use those features for each of the models see if they produce more fruitful results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.321656Z",
     "start_time": "2021-05-12T01:00:24.294923Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,all_r]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,all_r]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.326183Z",
     "start_time": "2021-05-12T01:00:24.323150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 105)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.330654Z",
     "start_time": "2021-05-12T01:00:24.328286Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = all_r\n",
    "numeric_features.remove('B2B_Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:24.337110Z",
     "start_time": "2021-05-12T01:00:24.332197Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "rfecv = RFECV(estimator= LogisticRegression(max_iter =10000, penalty = 'l2', solver='liblinear', C=.1), step=1, scoring='accuracy')\n",
    "rfecv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.624260Z",
     "start_time": "2021-05-12T01:00:24.344382Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['home_last30_GF_per_min_pp',\n",
       "                                                   'home_last_30_FF%_5v5',\n",
       "                                                   'home_last30_xGF_per_min_pp',\n",
       "                                                   'away_last_20_xGF%_5v5',\n",
       "                                                   'home_last_3_GF%_5v5',\n",
       "                                                   'home_last3_GA_per_min_pk',\n",
       "                                                   'away_last_40_xGF%_5v5',\n",
       "                                                   'away_last_5_SH%',\n",
       "                                                   'home_last_20_SH%',\n",
       "                                                   'away_last_3_xGF%_...\n",
       "                                                   'home_last40_xGA_per_min_pk',\n",
       "                                                   'away_last40_GA_per_min_pk',\n",
       "                                                   'away_last5_GA_per_min_pk',\n",
       "                                                   'home_last_20_xGF%_5v5',\n",
       "                                                   'home_last_40_GF%_5v5',\n",
       "                                                   'home_last30_GA_per_min_pk',\n",
       "                                                   'away_last_40_FF%_5v5', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['B2B_Status'])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(estimator=LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.629092Z",
     "start_time": "2021-05-12T01:00:46.625782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.633476Z",
     "start_time": "2021-05-12T01:00:46.630490Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  2,  1, 40, 16,  3, 10,  1, 60,  1,  1, 32,  5, 56, 12, 70,\n",
       "       59,  1, 38, 34,  1, 39,  1,  1, 47, 24,  1, 52,  4, 51, 46, 30, 50,\n",
       "       49,  1, 66,  1, 71,  1, 26, 53, 73, 23, 15, 20,  1, 64, 48, 61, 37,\n",
       "       67, 17,  8, 68,  1,  1,  1, 42, 19, 58, 14,  1,  6, 55, 36,  1,  9,\n",
       "       31, 54, 41,  1,  1, 25, 27, 22,  1,  1, 57,  1, 28,  1, 13, 45, 11,\n",
       "       21,  1, 43, 69,  1, 63, 44, 33,  1,  1, 29, 18, 35,  1, 62,  7,  1,\n",
       "       72, 65,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_pipeline[1].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.644595Z",
     "start_time": "2021-05-12T01:00:46.634831Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_last30_GF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>home_last_10_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>home_Goalie_GSAx/60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>away_last_20_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>home_last_3_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>home_last_40_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>away_Goalie_GSAx/60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>home_Goalie_FenwickSV%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>home_last_40_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>away_last_30_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>away_last10_GA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>home_last20_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>away_last_30_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>home_last30_xGA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>home_last_5_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>home_last_3_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>away_last_20_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>home_last_5_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>away_last30_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>away_last20_GA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>away_last40_xGF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>home_Rating.A.Pre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home_last_40_GF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_last40_GA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>home_last_10_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_last_20_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>away_Rating.A.Pre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_last_30_FF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>home_last40_xGA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>home_last20_xGA_per_min_pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home_last20_GF_per_min_pp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>away_last_40_SH%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away_last_20_xGF%_5v5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_last30_xGF_per_min_pp</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>away_last_40_xGF%_5v5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>away_last_40_FF%_5v5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature  Ranking\n",
       "0     home_last30_GF_per_min_pp        1\n",
       "35        home_last_10_xGF%_5v5        1\n",
       "37          home_Goalie_GSAx/60        1\n",
       "39         away_last_20_FF%_5v5        1\n",
       "46          home_last_3_FF%_5v5        1\n",
       "55         home_last_40_FF%_5v5        1\n",
       "56          away_Goalie_GSAx/60        1\n",
       "57       home_Goalie_FenwickSV%        1\n",
       "62             home_last_40_SH%        1\n",
       "66             away_last_30_SH%        1\n",
       "71    away_last10_GA_per_min_pk        1\n",
       "72   home_last20_xGF_per_min_pp        1\n",
       "76        away_last_30_xGF%_5v5        1\n",
       "77   home_last30_xGA_per_min_pk        1\n",
       "79          home_last_5_FF%_5v5        1\n",
       "81         home_last_3_xGF%_5v5        1\n",
       "86             away_last_20_SH%        1\n",
       "89         home_last_5_xGF%_5v5        1\n",
       "93   away_last30_xGF_per_min_pp        1\n",
       "94    away_last20_GA_per_min_pk        1\n",
       "98   away_last40_xGF_per_min_pp        1\n",
       "101           home_Rating.A.Pre        1\n",
       "27         home_last_40_GF%_5v5        1\n",
       "24    away_last40_GA_per_min_pk        1\n",
       "104            home_last_10_SH%        1\n",
       "8              home_last_20_SH%        1\n",
       "11            away_Rating.A.Pre        1\n",
       "1          home_last_30_FF%_5v5        1\n",
       "23   home_last40_xGA_per_min_pk        1\n",
       "21   home_last20_xGA_per_min_pk        1\n",
       "18    home_last20_GF_per_min_pp        1\n",
       "10             away_last_40_SH%        1\n",
       "3         away_last_20_xGF%_5v5        1\n",
       "2    home_last30_xGF_per_min_pp        2\n",
       "6         away_last_40_xGF%_5v5        3\n",
       "29         away_last_40_FF%_5v5        4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_results = pd.DataFrame(list(zip(X_train.columns, rfecv_pipeline[1].ranking_)), columns = ['Feature', 'Ranking']).sort_values('Ranking')\n",
    "rfecv_results.head(rfecv_pipeline[1].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.649922Z",
     "start_time": "2021-05-12T01:00:46.646089Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_last30_GF_per_min_pp',\n",
       " 'home_last_10_xGF%_5v5',\n",
       " 'home_Goalie_GSAx/60',\n",
       " 'away_last_20_FF%_5v5',\n",
       " 'home_last_3_FF%_5v5',\n",
       " 'home_last_40_FF%_5v5',\n",
       " 'away_Goalie_GSAx/60',\n",
       " 'home_Goalie_FenwickSV%',\n",
       " 'home_last_40_SH%',\n",
       " 'away_last_30_SH%',\n",
       " 'away_last10_GA_per_min_pk',\n",
       " 'home_last20_xGF_per_min_pp',\n",
       " 'away_last_30_xGF%_5v5',\n",
       " 'home_last30_xGA_per_min_pk',\n",
       " 'home_last_5_FF%_5v5',\n",
       " 'home_last_3_xGF%_5v5',\n",
       " 'away_last_20_SH%',\n",
       " 'home_last_5_xGF%_5v5',\n",
       " 'away_last30_xGF_per_min_pp',\n",
       " 'away_last20_GA_per_min_pk',\n",
       " 'away_last40_xGF_per_min_pp',\n",
       " 'home_Rating.A.Pre',\n",
       " 'home_last_40_GF%_5v5',\n",
       " 'away_last40_GA_per_min_pk',\n",
       " 'home_last_10_SH%',\n",
       " 'home_last_20_SH%',\n",
       " 'away_Rating.A.Pre',\n",
       " 'home_last_30_FF%_5v5',\n",
       " 'home_last40_xGA_per_min_pk',\n",
       " 'home_last20_xGA_per_min_pk',\n",
       " 'home_last20_GF_per_min_pp',\n",
       " 'away_last_40_SH%',\n",
       " 'away_last_20_xGF%_5v5',\n",
       " 'home_last30_xGF_per_min_pp',\n",
       " 'away_last_40_xGF%_5v5',\n",
       " 'away_last_40_FF%_5v5']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = list(rfecv_results.iloc[:rfecv_pipeline[1].n_features_,0])\n",
    "rfecv_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.675607Z",
     "start_time": "2021-05-12T01:00:46.651291Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:46.681143Z",
     "start_time": "2021-05-12T01:00:46.677312Z"
    }
   },
   "outputs": [],
   "source": [
    "log_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('logisticregression', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "log_params = {'logisticregression__solver' : ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                'logisticregression__penalty': ['l1', 'l2'],\n",
    "                'logisticregression__C': [.01, 0.1, 10, 20, 100],\n",
    "                'logisticregression__class_weight': [None]}\n",
    "\n",
    "log_cv_all = GridSearchCV(log_rfecv_pipeline, param_grid=log_params, cv=5, scoring=scoring, refit = 'neg_log_loss',  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:50.206600Z",
     "start_time": "2021-05-12T01:00:46.682618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 10, 20, 100],\n",
       "                         'logisticregression__class_weight': [None],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_all.fit(X_train[rfecv_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:50.233260Z",
     "start_time": "2021-05-12T01:00:50.208494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.673249</td>\n",
       "      <td>-0.667799</td>\n",
       "      <td>-0.674011</td>\n",
       "      <td>-0.676105</td>\n",
       "      <td>-0.674852</td>\n",
       "      <td>-0.673203</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576011</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.583472</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.673250</td>\n",
       "      <td>-0.667800</td>\n",
       "      <td>-0.674017</td>\n",
       "      <td>-0.676107</td>\n",
       "      <td>-0.674854</td>\n",
       "      <td>-0.673206</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>2</td>\n",
       "      <td>0.576011</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.590782</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.583751</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>-0.673227</td>\n",
       "      <td>-0.667819</td>\n",
       "      <td>-0.673998</td>\n",
       "      <td>-0.676117</td>\n",
       "      <td>-0.674871</td>\n",
       "      <td>-0.673206</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574616</td>\n",
       "      <td>0.596932</td>\n",
       "      <td>0.593575</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.585148</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.676699</td>\n",
       "      <td>-0.667724</td>\n",
       "      <td>-0.673610</td>\n",
       "      <td>-0.674932</td>\n",
       "      <td>-0.673247</td>\n",
       "      <td>-0.673242</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.583197</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>-0.676699</td>\n",
       "      <td>-0.667725</td>\n",
       "      <td>-0.673613</td>\n",
       "      <td>-0.674930</td>\n",
       "      <td>-0.673248</td>\n",
       "      <td>-0.673243</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.583197</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.019798      0.000133         0.004045        0.000082   \n",
       "11       0.023398      0.000620         0.004155        0.000174   \n",
       "9        0.017963      0.000521         0.004251        0.000253   \n",
       "4        0.016625      0.001407         0.005046        0.000709   \n",
       "5        0.027423      0.009254         0.004710        0.000983   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "10                         0.1                                   None   \n",
       "11                         0.1                                   None   \n",
       "9                          0.1                                   None   \n",
       "4                         0.01                                   None   \n",
       "5                         0.01                                   None   \n",
       "\n",
       "   param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "10                                l2                            lbfgs   \n",
       "11                                l2                        newton-cg   \n",
       "9                                 l2                        liblinear   \n",
       "4                                 l2                            lbfgs   \n",
       "5                                 l2                        newton-cg   \n",
       "\n",
       "                                               params  \\\n",
       "10  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "\n",
       "    split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "10                 -0.673249                 -0.667799   \n",
       "11                 -0.673250                 -0.667800   \n",
       "9                  -0.673227                 -0.667819   \n",
       "4                  -0.676699                 -0.667724   \n",
       "5                  -0.676699                 -0.667725   \n",
       "\n",
       "    split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "10                 -0.674011                 -0.676105   \n",
       "11                 -0.674017                 -0.676107   \n",
       "9                  -0.673998                 -0.676117   \n",
       "4                  -0.673610                 -0.674932   \n",
       "5                  -0.673613                 -0.674930   \n",
       "\n",
       "    split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "10                 -0.674852               -0.673203               0.002863   \n",
       "11                 -0.674854               -0.673206               0.002864   \n",
       "9                  -0.674871               -0.673206               0.002860   \n",
       "4                  -0.673247               -0.673242               0.003013   \n",
       "5                  -0.673248               -0.673243               0.003012   \n",
       "\n",
       "    rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "10                       1              0.576011              0.594142   \n",
       "11                       2              0.576011              0.594142   \n",
       "9                        3              0.574616              0.596932   \n",
       "4                        4              0.564854              0.589958   \n",
       "5                        5              0.564854              0.589958   \n",
       "\n",
       "    split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "10              0.589385              0.583799              0.574022   \n",
       "11              0.590782              0.583799              0.574022   \n",
       "9               0.593575              0.583799              0.576816   \n",
       "4               0.608939              0.579609              0.572626   \n",
       "5               0.608939              0.579609              0.572626   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "10            0.583472           0.007667                  16  \n",
       "11            0.583751           0.007899                  15  \n",
       "9             0.585148           0.008855                   7  \n",
       "4             0.583197           0.015293                  17  \n",
       "5             0.583197           0.015293                  17  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_all_results = pd.DataFrame(log_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "log_all_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:50.264711Z",
     "start_time": "2021-05-12T01:00:50.234974Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:00:50.271336Z",
     "start_time": "2021-05-12T01:00:50.266457Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfecv_pipeline = Pipeline(steps=[('ss', StandardScaler()),\n",
    "                      ('ada', AdaBoostClassifier())])\n",
    "\n",
    "ada_params = {'ada__n_estimators': [25],\n",
    "         'ada__learning_rate': [ .1, 10],\n",
    "         'ada__base_estimator': [svm.SVC(probability=True , kernel='linear'), LogisticRegression(max_iter =10000, C=.01, penalty = 'l1', solver = 'liblinear')],}\n",
    "\n",
    "ada_cv_all = GridSearchCV(ada_rfecv_pipeline, param_grid=ada_params, cv=5, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:09:31.803482Z",
     "start_time": "2021-05-12T01:00:50.273482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__base_estimator': [SVC(kernel='linear',\n",
       "                                                     probability=True),\n",
       "                                                 LogisticRegression(C=0.01,\n",
       "                                                                    max_iter=10000,\n",
       "                                                                    penalty='l1',\n",
       "                                                                    solver='liblinear')],\n",
       "                         'ada__learning_rate': [0.1, 10],\n",
       "                         'ada__n_estimators': [25]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cv_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:09:31.827430Z",
     "start_time": "2021-05-12T01:09:31.804967Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ada__base_estimator</th>\n",
       "      <th>param_ada__learning_rate</th>\n",
       "      <th>param_ada__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>split3_test_neg_log_loss</th>\n",
       "      <th>split4_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.460288</td>\n",
       "      <td>0.056277</td>\n",
       "      <td>2.471431</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682305</td>\n",
       "      <td>-0.678201</td>\n",
       "      <td>-0.680686</td>\n",
       "      <td>-0.682025</td>\n",
       "      <td>-0.680141</td>\n",
       "      <td>-0.680672</td>\n",
       "      <td>1.475632e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.565642</td>\n",
       "      <td>0.557263</td>\n",
       "      <td>0.566158</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.537684</td>\n",
       "      <td>0.256272</td>\n",
       "      <td>2.540797</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', p...</td>\n",
       "      <td>-0.682582</td>\n",
       "      <td>-0.680568</td>\n",
       "      <td>-0.678514</td>\n",
       "      <td>-0.684473</td>\n",
       "      <td>-0.679927</td>\n",
       "      <td>-0.681213</td>\n",
       "      <td>2.090701e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.599721</td>\n",
       "      <td>0.604749</td>\n",
       "      <td>0.561453</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.580122</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085728</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084748</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'ada__base_estimator': LogisticRegression(C=0...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>8.599751e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456067</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      43.460288      0.056277         2.471431        0.005118   \n",
       "1      42.537684      0.256272         2.540797        0.029652   \n",
       "2       0.085728      0.000993         0.012222        0.000502   \n",
       "3       0.084748      0.000796         0.012553        0.000402   \n",
       "\n",
       "                           param_ada__base_estimator param_ada__learning_rate  \\\n",
       "0             SVC(kernel='linear', probability=True)                      0.1   \n",
       "1             SVC(kernel='linear', probability=True)                       10   \n",
       "2  LogisticRegression(C=0.01, max_iter=10000, pen...                      0.1   \n",
       "3  LogisticRegression(C=0.01, max_iter=10000, pen...                       10   \n",
       "\n",
       "  param_ada__n_estimators                                             params  \\\n",
       "0                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "1                      25  {'ada__base_estimator': SVC(kernel='linear', p...   \n",
       "2                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "3                      25  {'ada__base_estimator': LogisticRegression(C=0...   \n",
       "\n",
       "   split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "0                 -0.682305                 -0.678201   \n",
       "1                 -0.682582                 -0.680568   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split2_test_neg_log_loss  split3_test_neg_log_loss  \\\n",
       "0                 -0.680686                 -0.682025   \n",
       "1                 -0.678514                 -0.684473   \n",
       "2                 -0.693147                 -0.693147   \n",
       "3                 -0.693147                 -0.693147   \n",
       "\n",
       "   split4_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "0                 -0.680141               -0.680672           1.475632e-03   \n",
       "1                 -0.679927               -0.681213           2.090701e-03   \n",
       "2                 -0.693147               -0.693147           8.599751e-17   \n",
       "3                 -0.693147               -0.693147           8.599751e-17   \n",
       "\n",
       "   rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                       1              0.571827              0.581590   \n",
       "1                       2              0.564854              0.599721   \n",
       "2                       3              0.456067              0.456067   \n",
       "3                       3              0.456067              0.456067   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.554469              0.565642              0.557263   \n",
       "1              0.604749              0.561453              0.569832   \n",
       "2              0.456704              0.456704              0.455307   \n",
       "3              0.456704              0.456704              0.455307   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.566158           0.009862                   2  \n",
       "1            0.580122           0.018320                   1  \n",
       "2            0.456170           0.000517                   3  \n",
       "3            0.456170           0.000517                   3  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_all_results = pd.DataFrame(ada_cv_all.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "ada_all_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:09:31.853832Z",
     "start_time": "2021-05-12T01:09:31.829109Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021']['Home_Team_Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:09:31.858775Z",
     "start_time": "2021-05-12T01:09:31.855514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 36)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:09:31.868841Z",
     "start_time": "2021-05-12T01:09:31.860419Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam', activation='linear', neurons = 1, dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_dim=rfecv_pipeline[1].n_features_, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "param_grid = {'nn__epochs': [8,10, 15, 18],\n",
    "             'nn__optimizer' : ['Adam', 'RMSprop'], \n",
    "             'nn__activation' : ['hard_sigmoid', 'linear'],\n",
    "            'nn__neurons' : [12, 24, 36, 40],\n",
    "             'nn__weight_constraint': [1, 3],\n",
    "             'nn__dropout_rate' : [0.3, 0.6]}\n",
    "keras_model = scikit_learn.KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['B2B_Status']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "nn_all_pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                      ('nn', keras_model)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nn_all_cv = GridSearchCV(estimator=nn_all_pipeline, param_grid=param_grid, cv=3, scoring=scoring, refit='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.701612Z",
     "start_time": "2021-05-12T01:09:31.870431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('nn',\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8617bf57c0>)]),\n",
       "             param_grid={'nn__activation': ['hard_sigmoid', 'linear'],\n",
       "                         'nn__dropout_rate': [0.3, 0.6],\n",
       "                         'nn__epochs': [8, 10, 15, 18],\n",
       "                         'nn__neurons': [12, 24, 36, 40],\n",
       "                         'nn__optimizer': ['Adam'],\n",
       "                         'nn__weight_constraint': [1, 3]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'accuracy'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.723314Z",
     "start_time": "2021-05-12T01:15:49.703026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_nn__activation</th>\n",
       "      <th>param_nn__dropout_rate</th>\n",
       "      <th>param_nn__epochs</th>\n",
       "      <th>param_nn__neurons</th>\n",
       "      <th>param_nn__optimizer</th>\n",
       "      <th>param_nn__weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.905101</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.096793</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.673046</td>\n",
       "      <td>-0.668641</td>\n",
       "      <td>-0.679657</td>\n",
       "      <td>-0.673781</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.605528</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.579844</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.981413</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.097363</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671383</td>\n",
       "      <td>-0.669498</td>\n",
       "      <td>-0.680475</td>\n",
       "      <td>-0.673785</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>2</td>\n",
       "      <td>0.591290</td>\n",
       "      <td>0.606365</td>\n",
       "      <td>0.556114</td>\n",
       "      <td>0.584590</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.897445</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.671991</td>\n",
       "      <td>-0.668439</td>\n",
       "      <td>-0.681377</td>\n",
       "      <td>-0.673936</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>3</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.588777</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.574260</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.095831</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.673235</td>\n",
       "      <td>-0.669248</td>\n",
       "      <td>-0.679684</td>\n",
       "      <td>-0.674056</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>0.600503</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>0.583473</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.907361</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate...</td>\n",
       "      <td>-0.673419</td>\n",
       "      <td>-0.669362</td>\n",
       "      <td>-0.680445</td>\n",
       "      <td>-0.674408</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>5</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.597152</td>\n",
       "      <td>0.553601</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "82        0.905101      0.012086         0.096793        0.001195   \n",
       "88        0.981413      0.006571         0.097363        0.001749   \n",
       "114       0.897445      0.002981         0.095700        0.000832   \n",
       "76        0.724736      0.002487         0.095831        0.000297   \n",
       "116       0.907361      0.002384         0.095542        0.000227   \n",
       "\n",
       "    param_nn__activation param_nn__dropout_rate param_nn__epochs  \\\n",
       "82                linear                    0.3               15   \n",
       "88                linear                    0.3               18   \n",
       "114               linear                    0.6               15   \n",
       "76                linear                    0.3               10   \n",
       "116               linear                    0.6               15   \n",
       "\n",
       "    param_nn__neurons param_nn__optimizer param_nn__weight_constraint  \\\n",
       "82                 24                Adam                           1   \n",
       "88                 12                Adam                           1   \n",
       "114                24                Adam                           1   \n",
       "76                 36                Adam                           1   \n",
       "116                36                Adam                           1   \n",
       "\n",
       "                                                params  \\\n",
       "82   {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "88   {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "114  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "76   {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "116  {'nn__activation': 'linear', 'nn__dropout_rate...   \n",
       "\n",
       "     split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "82                  -0.673046                 -0.668641   \n",
       "88                  -0.671383                 -0.669498   \n",
       "114                 -0.671991                 -0.668439   \n",
       "76                  -0.673235                 -0.669248   \n",
       "116                 -0.673419                 -0.669362   \n",
       "\n",
       "     split2_test_neg_log_loss  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "82                  -0.679657               -0.673781               0.004527   \n",
       "88                  -0.680475               -0.673785               0.004793   \n",
       "114                 -0.681377               -0.673936               0.005458   \n",
       "76                  -0.679684               -0.674056               0.004300   \n",
       "116                 -0.680445               -0.674408               0.004578   \n",
       "\n",
       "     rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "82                        1              0.576214              0.605528   \n",
       "88                        2              0.591290              0.606365   \n",
       "114                       3              0.586265              0.588777   \n",
       "76                        4              0.582077              0.600503   \n",
       "116                       5              0.577889              0.597152   \n",
       "\n",
       "     split2_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "82               0.557789            0.579844           0.019657   \n",
       "88               0.556114            0.584590           0.021055   \n",
       "114              0.547739            0.574260           0.018782   \n",
       "76               0.567839            0.583473           0.013371   \n",
       "116              0.553601            0.576214           0.017819   \n",
       "\n",
       "     rank_test_accuracy  \n",
       "82                   54  \n",
       "88                    7  \n",
       "114                 114  \n",
       "76                   16  \n",
       "116                 102  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_all_results = pd.DataFrame(nn_all_cv.cv_results_).sort_values('mean_test_neg_log_loss', ascending=False)\n",
    "nn_all_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for the RFECV models did ok but were still worse than the 5 and 40 and 40 only feature models. Ada Boost in particular did not do well with the RFECV features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Models To Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will evaluate the best model iterations on the held out 2021 season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.727043Z",
     "start_time": "2021-05-12T01:15:49.724601Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {'Training Cross Validation Accuracy': {}, 'Training Cross Validation Log Loss': {}, 'Test Accuracy': {}, 'Test Log Loss':{}, 'Paramters':{}}\n",
    "accuracy_list = []\n",
    "log_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.767034Z",
     "start_time": "2021-05-12T01:15:49.728440Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, log_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, log_cv.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.805009Z",
     "start_time": "2021-05-12T01:15:49.768687Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "test_preds_40 = log_cv_40.predict(X_test)\n",
    "\n",
    "test_probs_40 = log_cv_40.predict_proba(X_test)\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_40))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:49.837000Z",
     "start_time": "2021-05-12T01:15:49.806577Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "test_preds_rfecv = log_cv_all.predict(X_test)\n",
    "\n",
    "test_probs_rfecv = log_cv_all.predict_proba(X_test)\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, test_preds_rfecv))\n",
    "log_loss_list.append(log_loss(y_test, test_probs_rfecv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:53.555730Z",
     "start_time": "2021-05-12T01:15:49.852772Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test,ada_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:56.637895Z",
     "start_time": "2021-05-12T01:15:53.564199Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, ada_cv_40.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, ada_cv_40.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:56.759571Z",
     "start_time": "2021-05-12T01:15:56.639513Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r_5_40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:56.884107Z",
     "start_time": "2021-05-12T01:15:56.760821Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,r40]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_40_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_40_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.002539Z",
     "start_time": "2021-05-12T01:15:56.885490Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[df['Season'] != '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_train = df[df['Season'] != '2020-2021'].dropna()['Home_Team_Won']\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,rfecv_columns]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_test, nn_all_cv.predict(X_test)))\n",
    "log_loss_list.append(log_loss(y_test, nn_all_cv.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.012632Z",
     "start_time": "2021-05-12T01:15:57.003868Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict['Test Accuracy'] = accuracy_list\n",
    "results_dict['Test Log Loss'] = log_loss_list\n",
    "models = ['5 and 40 Logistic Regression', \n",
    "          '40 Logistic Regression', \n",
    "          'rfecv Logistic Regression', \n",
    "          '5 and 40 AdaBoost', \n",
    "          '40 AdaBoost', \n",
    "          '5 and 40 Neural Network', \n",
    "          '40 Neural Network', \n",
    "          'rfecv Neural Network']\n",
    "results_dict['Training Cross Validation Accuracy'] = [log_results['mean_test_accuracy'][0], \n",
    "                               log_40_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               log_all_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               ada_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               ada_40_results.loc[:,'mean_test_accuracy'].iloc[0], \n",
    "                               nn_results.loc[:,'mean_test_accuracy'].iloc[0],\n",
    "                              nn_40_results.loc[:,'mean_test_accuracy'].iloc[0],\n",
    "                              nn_all_results.loc[:,'mean_test_accuracy'].iloc[0]]\n",
    "results_dict['Training Cross Validation Log Loss'] = [log_cv.best_score_*-1, \n",
    "                               log_cv_40.best_score_*-1, \n",
    "                               log_cv_all.best_score_*-1, \n",
    "                               ada_cv.best_score_*-1, \n",
    "                               ada_cv_40.best_score_*-1, \n",
    "                               nn_cv.best_score_*-1, \n",
    "                               nn_40_cv.best_score_*-1, \n",
    "                               nn_all_cv.best_score_*-1]\n",
    "\n",
    "results_dict['Paramters'] = [log_results.loc[:,'params'].iloc[0], \n",
    "                               log_40_results.loc[:,'params'].iloc[0], \n",
    "                               log_all_results.loc[:,'params'].iloc[0], \n",
    "                               ada_results.loc[:,'params'].iloc[0], \n",
    "                               ada_40_results.loc[:,'params'].iloc[0], \n",
    "                               nn_results.loc[:,'params'].iloc[0],\n",
    "                              nn_40_results.loc[:,'params'].iloc[0],\n",
    "                              nn_all_results.loc[:,'params'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.017185Z",
     "start_time": "2021-05-12T01:15:57.014079Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, index = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model which had the best training cross validation log loss and test log loss was the Neural Network on the rolling 40 game features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.029738Z",
     "start_time": "2021-05-12T01:15:57.018644Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Cross Validation Accuracy</th>\n",
       "      <th>Training Cross Validation Log Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Log Loss</th>\n",
       "      <th>Paramters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40 Neural Network</th>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.672635</td>\n",
       "      <td>0.602439</td>\n",
       "      <td>0.655534</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 Logistic Regression</th>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.674249</td>\n",
       "      <td>0.602439</td>\n",
       "      <td>0.656803</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 Neural Network</th>\n",
       "      <td>0.584310</td>\n",
       "      <td>0.673594</td>\n",
       "      <td>0.603659</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 18, 'nn__neurons': 24, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 AdaBoost</th>\n",
       "      <td>0.572311</td>\n",
       "      <td>0.675815</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.660548</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 0.01, 'ada__n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 Logistic Regression</th>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.675437</td>\n",
       "      <td>0.598780</td>\n",
       "      <td>0.661808</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv Neural Network</th>\n",
       "      <td>0.579844</td>\n",
       "      <td>0.673781</td>\n",
       "      <td>0.579268</td>\n",
       "      <td>0.664362</td>\n",
       "      <td>{'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 15, 'nn__neurons': 24, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv Logistic Regression</th>\n",
       "      <td>0.583472</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.580488</td>\n",
       "      <td>0.670223</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 and 40 AdaBoost</th>\n",
       "      <td>0.577608</td>\n",
       "      <td>0.679858</td>\n",
       "      <td>0.598780</td>\n",
       "      <td>0.671058</td>\n",
       "      <td>{'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 10, 'ada__n_estimators': 25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Training Cross Validation Accuracy  \\\n",
       "40 Neural Network                                       0.577331   \n",
       "40 Logistic Regression                                  0.578727   \n",
       "5 and 40 Neural Network                                 0.584310   \n",
       "40 AdaBoost                                             0.572311   \n",
       "5 and 40 Logistic Regression                            0.456170   \n",
       "rfecv Neural Network                                    0.579844   \n",
       "rfecv Logistic Regression                               0.583472   \n",
       "5 and 40 AdaBoost                                       0.577608   \n",
       "\n",
       "                              Training Cross Validation Log Loss  \\\n",
       "40 Neural Network                                       0.672635   \n",
       "40 Logistic Regression                                  0.674249   \n",
       "5 and 40 Neural Network                                 0.673594   \n",
       "40 AdaBoost                                             0.675815   \n",
       "5 and 40 Logistic Regression                            0.675437   \n",
       "rfecv Neural Network                                    0.673781   \n",
       "rfecv Logistic Regression                               0.673203   \n",
       "5 and 40 AdaBoost                                       0.679858   \n",
       "\n",
       "                              Test Accuracy  Test Log Loss  \\\n",
       "40 Neural Network                  0.602439       0.655534   \n",
       "40 Logistic Regression             0.602439       0.656803   \n",
       "5 and 40 Neural Network            0.603659       0.657981   \n",
       "40 AdaBoost                        0.614634       0.660548   \n",
       "5 and 40 Logistic Regression       0.598780       0.661808   \n",
       "rfecv Neural Network               0.579268       0.664362   \n",
       "rfecv Logistic Regression          0.580488       0.670223   \n",
       "5 and 40 AdaBoost                  0.598780       0.671058   \n",
       "\n",
       "                                                                                                                                                                              Paramters  \n",
       "40 Neural Network                    {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 10, 'nn__neurons': 36, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 3}  \n",
       "40 Logistic Regression        {'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}  \n",
       "5 and 40 Neural Network              {'nn__activation': 'linear', 'nn__dropout_rate': 0.6, 'nn__epochs': 18, 'nn__neurons': 24, 'nn__optimizer': 'RMSprop', 'nn__weight_constraint': 1}  \n",
       "40 AdaBoost                                                        {'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 0.01, 'ada__n_estimators': 25}  \n",
       "5 and 40 Logistic Regression     {'logisticregression__C': 0.001, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}  \n",
       "rfecv Neural Network                    {'nn__activation': 'linear', 'nn__dropout_rate': 0.3, 'nn__epochs': 15, 'nn__neurons': 24, 'nn__optimizer': 'Adam', 'nn__weight_constraint': 1}  \n",
       "rfecv Logistic Regression          {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}  \n",
       "5 and 40 AdaBoost                                                    {'ada__base_estimator': SVC(kernel='linear', probability=True), 'ada__learning_rate': 10, 'ada__n_estimators': 25}  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results_df.sort_values('Test Log Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see how my test results copare to some publicly published models per [hockey-statisics.com](https://hockey-statistics.com/2021/05/03/game-projections-january-13th-2021/). Log loss figures on the below chart is only for the 2021 season and up to 5/2/2021 which aligns fairly closely with my test dataset results, though my predictions go through 5/6/2021. My best model would come in 4th between BayesBet and Hockey-Statistics. This is encouraging and shows my model is competitive with other models out there. Still not as good as the Implied Odds which came from Bet365 and ComeOn per the webpage creator Lars Skytte.\n",
    "<img src=\"images/model_comparison.png\" alt=\"model_comparison\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will save the predictions and evaluate them against historical odds to see if my model could be profitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.125669Z",
     "start_time": "2021-05-12T01:15:57.031251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save predictions and probabilites for from best model\n",
    "X_test = df[df['Season'] == '2020-2021'].dropna().loc[:,r40]\n",
    "y_test = df[df['Season'] == '2020-2021'].dropna()['Home_Team_Won']\n",
    "\n",
    "pred_df = df[df['Season'] == '2020-2021'].dropna().loc[:,['game_id',\n",
    " 'date',\n",
    " 'venue',\n",
    " 'home_team',\n",
    " 'away_team',\n",
    " 'start_time',\n",
    " 'home_score',\n",
    " 'away_score',\n",
    " 'status',\n",
    " 'Home_Team_Won',\n",
    " 'Home_Team_Key',\n",
    " 'Away_Team_Key', 'home_Game_Number','away_Game_Number','home_goalie',\n",
    " 'home_Goalie_FenwickSV%',\n",
    " 'home_Goalie_GSAx/60',\n",
    " 'home_Goalie_HDCSV%',\n",
    " 'away_goalie',\n",
    " 'away_Goalie_FenwickSV%',\n",
    " 'away_Goalie_GSAx/60',\n",
    " 'away_Goalie_HDCSV%','home_last_40_FF%_5v5',\n",
    " 'home_last_40_GF%_5v5',\n",
    " 'home_last_40_xGF%_5v5',\n",
    " 'home_last_40_SH%',\n",
    " 'home_last40_pp_TOI_per_game',\n",
    " 'home_last40_xGF_per_min_pp',\n",
    " 'home_last40_GF_per_min_pp',\n",
    " 'home_last40_pk_TOI_per_game',\n",
    " 'home_last40_xGA_per_min_pk',\n",
    " 'home_last40_GA_per_min_pk','away_last_40_FF%_5v5',\n",
    " 'away_last_40_GF%_5v5',\n",
    " 'away_last_40_xGF%_5v5',\n",
    " 'away_last_40_SH%',\n",
    " 'away_last40_pp_TOI_per_game',\n",
    " 'away_last40_xGF_per_min_pp',\n",
    " 'away_last40_GF_per_min_pp',\n",
    " 'away_last40_pk_TOI_per_game',\n",
    " 'away_last40_xGA_per_min_pk',\n",
    " 'away_last40_GA_per_min_pk',\n",
    " 'home_Rating.A.Pre',\n",
    " 'away_Rating.A.Pre',\n",
    " 'B2B_Status']]\n",
    "\n",
    "preds = nn_40_cv.predict(X_test)\n",
    "probs = nn_40_cv.predict_proba(X_test)\n",
    "\n",
    "Predictions_2021 = pd.concat([pred_df, \n",
    "                             pd.DataFrame(preds, columns = ['Prediction'], index = y_test.index ),\n",
    "                             pd.DataFrame(probs, columns = ['Away Win Probability', 'Home Win Probability'], index = y_test.index)], \n",
    "                             axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:15:57.156914Z",
     "start_time": "2021-05-12T01:15:57.126929Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>start_time</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>status</th>\n",
       "      <th>Home_Team_Won</th>\n",
       "      <th>Home_Team_Key</th>\n",
       "      <th>Away_Team_Key</th>\n",
       "      <th>home_Game_Number</th>\n",
       "      <th>away_Game_Number</th>\n",
       "      <th>home_goalie</th>\n",
       "      <th>home_Goalie_FenwickSV%</th>\n",
       "      <th>home_Goalie_GSAx/60</th>\n",
       "      <th>home_Goalie_HDCSV%</th>\n",
       "      <th>away_goalie</th>\n",
       "      <th>away_Goalie_FenwickSV%</th>\n",
       "      <th>away_Goalie_GSAx/60</th>\n",
       "      <th>away_Goalie_HDCSV%</th>\n",
       "      <th>home_last_40_FF%_5v5</th>\n",
       "      <th>home_last_40_GF%_5v5</th>\n",
       "      <th>home_last_40_xGF%_5v5</th>\n",
       "      <th>home_last_40_SH%</th>\n",
       "      <th>home_last40_pp_TOI_per_game</th>\n",
       "      <th>home_last40_xGF_per_min_pp</th>\n",
       "      <th>home_last40_GF_per_min_pp</th>\n",
       "      <th>home_last40_pk_TOI_per_game</th>\n",
       "      <th>home_last40_xGA_per_min_pk</th>\n",
       "      <th>home_last40_GA_per_min_pk</th>\n",
       "      <th>away_last_40_FF%_5v5</th>\n",
       "      <th>away_last_40_GF%_5v5</th>\n",
       "      <th>away_last_40_xGF%_5v5</th>\n",
       "      <th>away_last_40_SH%</th>\n",
       "      <th>away_last40_pp_TOI_per_game</th>\n",
       "      <th>away_last40_xGF_per_min_pp</th>\n",
       "      <th>away_last40_GF_per_min_pp</th>\n",
       "      <th>away_last40_pk_TOI_per_game</th>\n",
       "      <th>away_last40_xGA_per_min_pk</th>\n",
       "      <th>away_last40_GA_per_min_pk</th>\n",
       "      <th>home_Rating.A.Pre</th>\n",
       "      <th>away_Rating.A.Pre</th>\n",
       "      <th>B2B_Status</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Away Win Probability</th>\n",
       "      <th>Home Win Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>2020020838</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>TD Garden</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NYR</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS_2021-05-06</td>\n",
       "      <td>NYR_2021-05-06</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Jeremy Swayman</td>\n",
       "      <td>0.935086</td>\n",
       "      <td>-0.255694</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>Igor Shesterkin</td>\n",
       "      <td>0.943293</td>\n",
       "      <td>0.221547</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>55.281007</td>\n",
       "      <td>54.929673</td>\n",
       "      <td>53.113745</td>\n",
       "      <td>7.448563</td>\n",
       "      <td>5.182500</td>\n",
       "      <td>0.087844</td>\n",
       "      <td>0.096479</td>\n",
       "      <td>5.401667</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>0.087936</td>\n",
       "      <td>48.264073</td>\n",
       "      <td>54.430227</td>\n",
       "      <td>48.777665</td>\n",
       "      <td>10.050150</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>0.135397</td>\n",
       "      <td>0.153974</td>\n",
       "      <td>4.960833</td>\n",
       "      <td>0.111876</td>\n",
       "      <td>0.100790</td>\n",
       "      <td>1569.72</td>\n",
       "      <td>1512.11</td>\n",
       "      <td>Away_only</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>0.603120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>2020020839</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Nassau Veterans Memorial Coliseum</td>\n",
       "      <td>NYI</td>\n",
       "      <td>N.J</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Final</td>\n",
       "      <td>0</td>\n",
       "      <td>NYI_2021-05-06</td>\n",
       "      <td>N.J_2021-05-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Semyon Varlamov</td>\n",
       "      <td>0.945489</td>\n",
       "      <td>0.090302</td>\n",
       "      <td>0.881020</td>\n",
       "      <td>Mackenzie Blackwood</td>\n",
       "      <td>0.929299</td>\n",
       "      <td>-0.399936</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>50.241772</td>\n",
       "      <td>57.867228</td>\n",
       "      <td>53.050836</td>\n",
       "      <td>8.805727</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>0.112976</td>\n",
       "      <td>0.093659</td>\n",
       "      <td>4.164167</td>\n",
       "      <td>0.102181</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>48.503229</td>\n",
       "      <td>41.919777</td>\n",
       "      <td>48.218609</td>\n",
       "      <td>7.979786</td>\n",
       "      <td>5.086667</td>\n",
       "      <td>0.092202</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>4.442500</td>\n",
       "      <td>0.115419</td>\n",
       "      <td>0.135059</td>\n",
       "      <td>1549.32</td>\n",
       "      <td>1439.38</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301967</td>\n",
       "      <td>0.698033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>2020020842</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>PPG Paints Arena</td>\n",
       "      <td>PIT</td>\n",
       "      <td>BUF</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT_2021-05-06</td>\n",
       "      <td>BUF_2021-05-06</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Tristan Jarry</td>\n",
       "      <td>0.929605</td>\n",
       "      <td>-0.427560</td>\n",
       "      <td>0.843672</td>\n",
       "      <td>Michael Houser</td>\n",
       "      <td>0.935086</td>\n",
       "      <td>-0.255694</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>50.360590</td>\n",
       "      <td>58.253252</td>\n",
       "      <td>49.798658</td>\n",
       "      <td>9.041652</td>\n",
       "      <td>4.222500</td>\n",
       "      <td>0.123860</td>\n",
       "      <td>0.171699</td>\n",
       "      <td>4.520833</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>0.121659</td>\n",
       "      <td>43.706600</td>\n",
       "      <td>39.713487</td>\n",
       "      <td>43.700006</td>\n",
       "      <td>7.311708</td>\n",
       "      <td>4.217917</td>\n",
       "      <td>0.076993</td>\n",
       "      <td>0.082979</td>\n",
       "      <td>4.502917</td>\n",
       "      <td>0.123698</td>\n",
       "      <td>0.127695</td>\n",
       "      <td>1556.67</td>\n",
       "      <td>1416.17</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280140</td>\n",
       "      <td>0.719860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>2020020847</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Scotiabank Arena</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MTL</td>\n",
       "      <td>2021-05-06 23:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Final</td>\n",
       "      <td>1</td>\n",
       "      <td>TOR_2021-05-06</td>\n",
       "      <td>MTL_2021-05-06</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Jack Campbell</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>-0.117228</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>Jake Allen</td>\n",
       "      <td>0.937289</td>\n",
       "      <td>-0.098128</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>52.425741</td>\n",
       "      <td>57.938580</td>\n",
       "      <td>57.199725</td>\n",
       "      <td>9.228362</td>\n",
       "      <td>4.385833</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>0.085503</td>\n",
       "      <td>3.714583</td>\n",
       "      <td>0.102703</td>\n",
       "      <td>0.134605</td>\n",
       "      <td>53.658068</td>\n",
       "      <td>46.852953</td>\n",
       "      <td>51.668374</td>\n",
       "      <td>6.754951</td>\n",
       "      <td>4.255417</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>4.325417</td>\n",
       "      <td>0.118775</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>1550.15</td>\n",
       "      <td>1485.59</td>\n",
       "      <td>Away_only</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344289</td>\n",
       "      <td>0.655711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>2020020593</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Rogers Place</td>\n",
       "      <td>EDM</td>\n",
       "      <td>VAN</td>\n",
       "      <td>2021-05-07 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Final</td>\n",
       "      <td>0</td>\n",
       "      <td>EDM_2021-05-06</td>\n",
       "      <td>VAN_2021-05-06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Mike Smith</td>\n",
       "      <td>0.943015</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>Thatcher Demko</td>\n",
       "      <td>0.933794</td>\n",
       "      <td>-0.096288</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>49.044109</td>\n",
       "      <td>53.663901</td>\n",
       "      <td>49.880668</td>\n",
       "      <td>9.351147</td>\n",
       "      <td>4.523333</td>\n",
       "      <td>0.128611</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>4.334167</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>46.485886</td>\n",
       "      <td>44.299738</td>\n",
       "      <td>45.089832</td>\n",
       "      <td>7.305675</td>\n",
       "      <td>4.430417</td>\n",
       "      <td>0.105464</td>\n",
       "      <td>0.112856</td>\n",
       "      <td>5.131667</td>\n",
       "      <td>0.111075</td>\n",
       "      <td>0.116921</td>\n",
       "      <td>1536.06</td>\n",
       "      <td>1462.38</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307734</td>\n",
       "      <td>0.692266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         game_id        date                              venue home_team  \\\n",
       "4442  2020020838  2021-05-06                          TD Garden       BOS   \n",
       "4443  2020020839  2021-05-06  Nassau Veterans Memorial Coliseum       NYI   \n",
       "4444  2020020842  2021-05-06                   PPG Paints Arena       PIT   \n",
       "4445  2020020847  2021-05-06                   Scotiabank Arena       TOR   \n",
       "4446  2020020593  2021-05-06                       Rogers Place       EDM   \n",
       "\n",
       "     away_team           start_time  home_score  away_score status  \\\n",
       "4442       NYR  2021-05-06 23:00:00           4           0  Final   \n",
       "4443       N.J  2021-05-06 23:00:00           1           2  Final   \n",
       "4444       BUF  2021-05-06 23:00:00           8           4  Final   \n",
       "4445       MTL  2021-05-06 23:00:00           5           2  Final   \n",
       "4446       VAN  2021-05-07 01:00:00           3           6  Final   \n",
       "\n",
       "      Home_Team_Won   Home_Team_Key   Away_Team_Key  home_Game_Number  \\\n",
       "4442              1  BOS_2021-05-06  NYR_2021-05-06              40.0   \n",
       "4443              0  NYI_2021-05-06  N.J_2021-05-06              43.0   \n",
       "4444              1  PIT_2021-05-06  BUF_2021-05-06              48.0   \n",
       "4445              1  TOR_2021-05-06  MTL_2021-05-06              42.0   \n",
       "4446              0  EDM_2021-05-06  VAN_2021-05-06              47.0   \n",
       "\n",
       "      away_Game_Number      home_goalie  home_Goalie_FenwickSV%  \\\n",
       "4442              38.0   Jeremy Swayman                0.935086   \n",
       "4443              46.0  Semyon Varlamov                0.945489   \n",
       "4444              49.0    Tristan Jarry                0.929605   \n",
       "4445              44.0    Jack Campbell                0.938931   \n",
       "4446              47.0       Mike Smith                0.943015   \n",
       "\n",
       "      home_Goalie_GSAx/60  home_Goalie_HDCSV%          away_goalie  \\\n",
       "4442            -0.255694            0.862060      Igor Shesterkin   \n",
       "4443             0.090302            0.881020  Mackenzie Blackwood   \n",
       "4444            -0.427560            0.843672       Michael Houser   \n",
       "4445            -0.117228            0.845000           Jake Allen   \n",
       "4446             0.055221            0.874687       Thatcher Demko   \n",
       "\n",
       "      away_Goalie_FenwickSV%  away_Goalie_GSAx/60  away_Goalie_HDCSV%  \\\n",
       "4442                0.943293             0.221547            0.893805   \n",
       "4443                0.929299            -0.399936            0.837209   \n",
       "4444                0.935086            -0.255694            0.862060   \n",
       "4445                0.937289            -0.098128            0.878049   \n",
       "4446                0.933794            -0.096288            0.854626   \n",
       "\n",
       "      home_last_40_FF%_5v5  home_last_40_GF%_5v5  home_last_40_xGF%_5v5  \\\n",
       "4442             55.281007             54.929673              53.113745   \n",
       "4443             50.241772             57.867228              53.050836   \n",
       "4444             50.360590             58.253252              49.798658   \n",
       "4445             52.425741             57.938580              57.199725   \n",
       "4446             49.044109             53.663901              49.880668   \n",
       "\n",
       "      home_last_40_SH%  home_last40_pp_TOI_per_game  \\\n",
       "4442          7.448563                     5.182500   \n",
       "4443          8.805727                     4.270833   \n",
       "4444          9.041652                     4.222500   \n",
       "4445          9.228362                     4.385833   \n",
       "4446          9.351147                     4.523333   \n",
       "\n",
       "      home_last40_xGF_per_min_pp  home_last40_GF_per_min_pp  \\\n",
       "4442                    0.087844                   0.096479   \n",
       "4443                    0.112976                   0.093659   \n",
       "4444                    0.123860                   0.171699   \n",
       "4445                    0.125119                   0.085503   \n",
       "4446                    0.128611                   0.171334   \n",
       "\n",
       "      home_last40_pk_TOI_per_game  home_last40_xGA_per_min_pk  \\\n",
       "4442                     5.401667                    0.084094   \n",
       "4443                     4.164167                    0.102181   \n",
       "4444                     4.520833                    0.095945   \n",
       "4445                     3.714583                    0.102703   \n",
       "4446                     4.334167                    0.116055   \n",
       "\n",
       "      home_last40_GA_per_min_pk  away_last_40_FF%_5v5  away_last_40_GF%_5v5  \\\n",
       "4442                   0.087936             48.264073             54.430227   \n",
       "4443                   0.090054             48.503229             41.919777   \n",
       "4444                   0.121659             43.706600             39.713487   \n",
       "4445                   0.134605             53.658068             46.852953   \n",
       "4446                   0.092290             46.485886             44.299738   \n",
       "\n",
       "      away_last_40_xGF%_5v5  away_last_40_SH%  away_last40_pp_TOI_per_game  \\\n",
       "4442              48.777665         10.050150                     5.033333   \n",
       "4443              48.218609          7.979786                     5.086667   \n",
       "4444              43.700006          7.311708                     4.217917   \n",
       "4445              51.668374          6.754951                     4.255417   \n",
       "4446              45.089832          7.305675                     4.430417   \n",
       "\n",
       "      away_last40_xGF_per_min_pp  away_last40_GF_per_min_pp  \\\n",
       "4442                    0.135397                   0.153974   \n",
       "4443                    0.092202                   0.078637   \n",
       "4444                    0.076993                   0.082979   \n",
       "4445                    0.085714                   0.111622   \n",
       "4446                    0.105464                   0.112856   \n",
       "\n",
       "      away_last40_pk_TOI_per_game  away_last40_xGA_per_min_pk  \\\n",
       "4442                     4.960833                    0.111876   \n",
       "4443                     4.442500                    0.115419   \n",
       "4444                     4.502917                    0.123698   \n",
       "4445                     4.325417                    0.118775   \n",
       "4446                     5.131667                    0.111075   \n",
       "\n",
       "      away_last40_GA_per_min_pk  home_Rating.A.Pre  away_Rating.A.Pre  \\\n",
       "4442                   0.100790            1569.72            1512.11   \n",
       "4443                   0.135059            1549.32            1439.38   \n",
       "4444                   0.127695            1556.67            1416.17   \n",
       "4445                   0.138715            1550.15            1485.59   \n",
       "4446                   0.116921            1536.06            1462.38   \n",
       "\n",
       "     B2B_Status  Prediction  Away Win Probability  Home Win Probability  \n",
       "4442  Away_only           1              0.396880              0.603120  \n",
       "4443    Neither           1              0.301967              0.698033  \n",
       "4444    Neither           1              0.280140              0.719860  \n",
       "4445  Away_only           1              0.344289              0.655711  \n",
       "4446    Neither           1              0.307734              0.692266  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:20:58.632890Z",
     "start_time": "2021-05-12T13:20:58.580268Z"
    }
   },
   "outputs": [],
   "source": [
    "Predictions_2021.to_csv('data/Predictions_2021b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To further improve the models I would like to take the following next steps\n",
    "\n",
    "- Implement voting classifier\n",
    "- Try linear weightings in rolling features\n",
    "- Build bottom up model using player statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
